{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2f9fe3884c104bc89567274418cc00f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_59f8f34f556f4a9591a51e19fbd1128c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4ddb0afc32784b7083671da814b4c07d",
              "IPY_MODEL_47107cfd319243d6a801050d83fa612d"
            ]
          }
        },
        "59f8f34f556f4a9591a51e19fbd1128c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ddb0afc32784b7083671da814b4c07d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_options_labels": [
              "3d",
              "action-localization",
              "action-recognition",
              "active-learning",
              "activity-recognition",
              "adversarial-attacks",
              "adversarial-defense",
              "adversarial-image-detection",
              "adversarial-learning",
              "adversarial-text",
              "angular",
              "animations",
              "annotation",
              "anomaly-detection",
              "arima",
              "artificial-general-intelligence",
              "attention",
              "audio-classification",
              "audio-generation",
              "audio-tagging",
              "autoencoders",
              "automl",
              "autonomous-vehicles",
              "aws",
              "azure",
              "backend",
              "bayesian-deep-learning",
              "bayesian-inference",
              "bidaf",
              "boundary-detection",
              "c",
              "c#",
              "c++",
              "caffe",
              "calibration",
              "camera-localization",
              "captioning",
              "causal-inference",
              "chainer",
              "character-embeddings",
              "chunking",
              "ci-cd",
              "classification",
              "clustering",
              "code-generation",
              "code-summarization",
              "collaborative-filtering",
              "collaborative-ranking",
              "colorization",
              "common-sense-reasoning",
              "computer-vision",
              "conditional-random-fields",
              "conditional-variational-autoencoders",
              "constituency-parsing",
              "contextualized-embeddings",
              "contour-detection",
              "contrastive-loss",
              "conversational-ai",
              "convolutional-neural-networks",
              "coreference-resolution",
              "coreml",
              "counterfactuals",
              "cropping",
              "cross-lingual",
              "crowd-counting",
              "css",
              "d3",
              "data-augmentation",
              "data-mining",
              "data-science",
              "data-summarization",
              "databases",
              "deblurring",
              "decision-making",
              "decision-trees",
              "deconvolution",
              "deep-learning",
              "deep-q-networks",
              "denoising",
              "density-estimation",
              "dependency-parsing",
              "depth-completion",
              "depth-estimation",
              "devops",
              "dialogue",
              "dictionary-learning",
              "dimensionality-reduction",
              "disease-prediction",
              "disparity-estimation",
              "distributed-training",
              "django",
              "dl4j",
              "dlib",
              "docker",
              "document-classification",
              "document-embeddings",
              "document-ranking",
              "domain-adaptation",
              "drug-discovery",
              "dynet",
              "edge-detection",
              "embeddings",
              "emotion-recognition",
              "enhancement",
              "entity-alignment",
              "entity-disambiguation",
              "entity-extraction",
              "entity-linking",
              "entity-resolution",
              "entity-typing",
              "expectation-maximization",
              "experiment-tracking",
              "exploratory-data-analysis",
              "face-detection",
              "face-generation",
              "face-reconstruction",
              "fake-news-detection",
              "fastai",
              "fastapi",
              "fasttext",
              "feature-engineering",
              "feature-importance",
              "feature-selection",
              "few-shot-learning",
              "fine-tuning",
              "flask",
              "forecasting",
              "fraud-detection",
              "frontend",
              "gated-recurrent-units",
              "gaussian-processes",
              "gaze-estimation",
              "generation",
              "generative-adversarial-networks",
              "geometric-deep-learning",
              "gesture-recognition",
              "git",
              "gluon",
              "go",
              "gpt",
              "gradient-boosting",
              "graph-classification",
              "graph-clustering",
              "graph-construction",
              "graph-convolutional-networks",
              "graph-embedding",
              "graph-neural-networks",
              "graph-representation-learning",
              "graph-similarity",
              "graphql",
              "graphs",
              "grasping",
              "h2o",
              "hand-pose-estimation",
              "haskell",
              "hidden-markov-models",
              "hierarchical-reinforcement-learning",
              "highway-networks",
              "html",
              "huggingface",
              "human-detection",
              "hyperparameter-optimization",
              "image-captioning",
              "image-categorization",
              "image-classification",
              "image-clustering",
              "image-compression",
              "image-enhancement",
              "image-generation",
              "image-imputation",
              "image-recognition",
              "image-reconstruction",
              "image-restoration",
              "image-similarity-search",
              "image-to-image-translation",
              "imitation-learning",
              "imputation",
              "inference",
              "information-extraction",
              "information-retrieval",
              "instance-segmentation",
              "integration-tests",
              "intent-classification",
              "intent-detection",
              "interpretability",
              "java",
              "javascript",
              "jax",
              "julia",
              "k-nearest-neighbors",
              "keras",
              "keyword-extraction",
              "keyword-spotting",
              "knowledge-base",
              "knowledge-base-question-answering",
              "knowledge-distillation",
              "knowledge-graphs",
              "kuberflow",
              "kubernetes",
              "language-identification",
              "language-modeling",
              "latent-dirichlet-allocation",
              "learning-rates",
              "lemmatization",
              "lexical-simplification",
              "linear-discriminant-analysis",
              "linear-regression",
              "linguistic-acceptability",
              "logistic-regression",
              "lstm",
              "machine-learning",
              "machine-translation",
              "matplotlib",
              "medical-imaging",
              "meta-learning",
              "metrics",
              "mlops",
              "model-compression",
              "model-management",
              "model-selection",
              "morphological-analysis",
              "morphological-inflection",
              "morphological-tagging",
              "mortality-prediction",
              "motion-capture",
              "motion-estimation",
              "motion-planning",
              "motion-segmentation",
              "multi-agent-reinforcement-learning",
              "multi-armed-bandits",
              "multi-modal",
              "multi-task-learning",
              "multilayer-perceptrons",
              "multilingual",
              "multinomial-regression",
              "music-generation",
              "mxnet",
              "naive-bayes",
              "named-entity-recognition",
              "natural-language-inference",
              "natural-language-processing",
              "natural-language-understanding",
              "navigation",
              "neural-networks",
              "node-classification",
              "node-js",
              "object-classification",
              "object-counting",
              "object-detection",
              "object-localization",
              "object-recognition",
              "object-reconstruction",
              "object-tracking",
              "one-shot-learning",
              "onnx",
              "open-refine",
              "optical-character-recognition",
              "optical-flow-estimation",
              "optimizer",
              "outlier-detection",
              "paddlepaddle",
              "paraphrase-identification",
              "part-of-speech-tagging",
              "passage-re-ranking",
              "phenotyping",
              "php",
              "phrase-grounding",
              "point-cloud-generation",
              "policy-gradient-methods",
              "pose-estimation",
              "pose-tracking",
              "preprocessing",
              "pretraining",
              "principal-component-analysis",
              "privacy",
              "production",
              "pruning",
              "python",
              "pytorch",
              "q-learning",
              "quantization",
              "quantum-machine-learning",
              "quasi-recurrent-neural-networks",
              "question-answering",
              "question-generation",
              "question-similarity",
              "r",
              "random-forests",
              "react",
              "reading-comprehension",
              "recommendation-systems",
              "recurrent-neural-networks",
              "recursive-neural-networks",
              "regression",
              "reinforcement-learning",
              "relation-classification",
              "relation-extraction",
              "relational-reasoning",
              "representation-learning",
              "residual-networks",
              "robotics",
              "ruby",
              "saas",
              "safe-exploration",
              "sarcasm-detection",
              "scala",
              "scene-classification",
              "scene-generation",
              "scikit-learn",
              "search",
              "segmentation",
              "self-attention",
              "self-supervised-learning",
              "semantic-composition",
              "semantic-parsing",
              "semantic-role-labeling",
              "semantic-segmentation",
              "semi-supervised-learning",
              "sentence-embeddings",
              "sentiment-analysis",
              "sequence-to-sequence",
              "siamese-networks",
              "similarity-search",
              "slot-filling",
              "sonnet",
              "spacy",
              "spark",
              "spatial-temporal-cnn",
              "speaker-diarization",
              "speaker-identification",
              "speaker-separation",
              "speaker-verification",
              "speech",
              "speech-enhancement",
              "speech-recognition",
              "speech-separation",
              "speech-synthesis",
              "spoken-dialogue-systems",
              "sql",
              "stance-detection",
              "stata",
              "stereo-matching",
              "stochastic-optimization",
              "streaming-data",
              "streamlit",
              "style-transfer",
              "subjectivity-analysis",
              "super-resolution",
              "support-vector-machines",
              "surveillance",
              "survival-analysis",
              "swift",
              "systems-design",
              "tabular",
              "temporal-cnn",
              "tensor-networks",
              "tensorflow",
              "tensorflow-js",
              "tensorflow-lite",
              "text-attribute-transfer",
              "text-classification",
              "text-generation",
              "text-matching",
              "text-similarity",
              "text-simplification",
              "text-summarization",
              "text-to-speech-synthesis",
              "theano",
              "time-series",
              "time-series-classification",
              "time-series-clustering",
              "time-series-forecasting",
              "time-series-prediction",
              "tokenization",
              "topic-modeling",
              "torch",
              "transfer-learning",
              "transformers",
              "unit-tests",
              "unsupervised-learning",
              "variational-autoencoders",
              "video-captioning",
              "video-classification",
              "video-question-answering",
              "video-semantic-segmentation",
              "video-summarization",
              "visual-navigation",
              "visual-odometry",
              "visual-question-answering",
              "visual-reasoning",
              "visual-tracking",
              "visualization",
              "wandb",
              "word-alignment",
              "word-embeddings",
              "word-sense-disambiguation",
              "word-sense-induction",
              "xgboost",
              "xlnet",
              "zero-shot-learning"
            ],
            "_view_name": "DropdownView",
            "style": "IPY_MODEL_f94adc79c0a44a898c0ec067fbd533ce",
            "_dom_classes": [],
            "description": "tag",
            "_model_name": "DropdownModel",
            "index": 283,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a75abdcebd6847399644e9e00ee6be0b"
          }
        },
        "47107cfd319243d6a801050d83fa612d": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "{\n",
                  "  \"aliases\": [\n",
                  "    \"qa\"\n",
                  "  ],\n",
                  "  \"parents\": [\n",
                  "    \"natural-language-processing\"\n",
                  "  ]\n",
                  "}\n"
                ]
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_ee5e97ac9c2148dc81e30810df0402fe",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "f94adc79c0a44a898c0ec067fbd533ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a75abdcebd6847399644e9e00ee6be0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee5e97ac9c2148dc81e30810df0402fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "789355740ea2444aae73af1f78b0dedc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_29d2c314905d43ea915a50939b3c3e3e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_20867b4167104806a979de215ee30268",
              "IPY_MODEL_ab67b7406a5d480890a6a257fd634bc1"
            ]
          }
        },
        "29d2c314905d43ea915a50939b3c3e3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20867b4167104806a979de215ee30268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "IntSliderView",
            "style": "IPY_MODEL_975cbf9616ac41ac9f95f2b99e3e0e3f",
            "_dom_classes": [],
            "description": "min_tag_freq",
            "step": 1,
            "_model_name": "IntSliderModel",
            "orientation": "horizontal",
            "max": 424,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 30,
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "min": 0,
            "continuous_update": true,
            "readout_format": "d",
            "description_tooltip": null,
            "readout": true,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_716dabd8bf9b4528b5698e4880155079"
          }
        },
        "ab67b7406a5d480890a6a257fd634bc1": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Most popular tags:\n",
                  " [('natural-language-processing', 424), ('computer-vision', 388), ('pytorch', 258), ('tensorflow', 213), ('transformers', 196)]\n",
                  "\n",
                  "Tags that just made the cut:\n",
                  " [('flask', 34), ('time-series', 34), ('node-classification', 33), ('question-answering', 32), ('pretraining', 30)]\n",
                  "\n",
                  "Tags that just missed the cut:\n",
                  " [('fastai', 29), ('graph-classification', 29), ('model-compression', 29), ('recurrent-neural-networks', 28), ('adversarial-learning', 28)]\n"
                ]
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_06915226f8354c45a8b38ba69fef3cbc",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "975cbf9616ac41ac9f95f2b99e3e0e3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "handle_color": null,
            "_model_name": "SliderStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "716dabd8bf9b4528b5698e4880155079": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06915226f8354c45a8b38ba69fef3cbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a552cef4d20842d29902fb4df1186ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8769fc374a7b4ef5aa1fa4f2d82ed0c2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bccadb7258404cd78da77facec7fbc87",
              "IPY_MODEL_b328112aeb3141e3b2eb7df737a6ed63",
              "IPY_MODEL_0cbd36d304894b959754e29dc647ee66"
            ]
          }
        },
        "8769fc374a7b4ef5aa1fa4f2d82ed0c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bccadb7258404cd78da77facec7fbc87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "CheckboxView",
            "style": "IPY_MODEL_10e24451af714953b29b849c92aa42ac",
            "_dom_classes": [],
            "description": "lower",
            "_model_name": "CheckboxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": true,
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "indent": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_478259d819b34563958b8ef99257c313"
          }
        },
        "b328112aeb3141e3b2eb7df737a6ed63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "CheckboxView",
            "style": "IPY_MODEL_db8693b17a9c417c8b85926a4d5366fb",
            "_dom_classes": [],
            "description": "stem",
            "_model_name": "CheckboxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": false,
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "indent": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_378dce2ab6354dac907783e1e9c3d4ce"
          }
        },
        "0cbd36d304894b959754e29dc647ee66": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "conditional image generation using variational autoencoders gans\n"
                ]
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_a1647abeaad348e687a10eccb43c67fc",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "10e24451af714953b29b849c92aa42ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "478259d819b34563958b8ef99257c313": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db8693b17a9c417c8b85926a4d5366fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "378dce2ab6354dac907783e1e9c3d4ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1647abeaad348e687a10eccb43c67fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ip6vwM3PdtNe",
        "outputId": "7cf595c9-3243-41ca-9bb2-1516c8fc6465"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep  2 00:31:04 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1ljPNNhNOWU"
      },
      "source": [
        "from collections import Counter, OrderedDict\n",
        "import ipywidgets as widgets\n",
        "import itertools\n",
        "import json\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yDORimDNRaR",
        "outputId": "50db1e8f-ca72-4a82-e275-e766186761ad"
      },
      "source": [
        "# Load projects\n",
        "url = \"https://raw.githubusercontent.com/GokuMohandas/MadeWithML/main/datasets/projects.json\"\n",
        "projects = json.loads(urlopen(url).read())\n",
        "print (json.dumps(projects[-305], indent=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": 2106,\n",
            "  \"created_on\": \"2020-08-08 15:06:18\",\n",
            "  \"title\": \"Fast NST for Videos (+ person segmentation) \\ud83c\\udfa5 + \\u26a1\\ud83d\\udcbb + \\ud83c\\udfa8 = \\u2764\\ufe0f\",\n",
            "  \"description\": \"Create NST videos and pick separate styles for the person in the video and for the background.\",\n",
            "  \"tags\": [\n",
            "    \"code\",\n",
            "    \"tutorial\",\n",
            "    \"video\",\n",
            "    \"computer-vision\",\n",
            "    \"style-transfer\",\n",
            "    \"neural-style-transfer\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "Yky6ZbvHNYMp",
        "outputId": "97b9356b-f9b4-4598-f752-705b2ae2b246"
      },
      "source": [
        "# Create dataframe\n",
        "df = pd.DataFrame(projects)\n",
        "print (f\"{len(df)} projects\")\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2032 projects\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>created_on</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2020-02-17 06:30:41</td>\n",
              "      <td>Machine Learning Basics</td>\n",
              "      <td>A practical set of notebooks on machine learni...</td>\n",
              "      <td>[code, tutorial, keras, pytorch, tensorflow, d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2020-02-17 06:41:45</td>\n",
              "      <td>Deep Learning with Electronic Health Record (E...</td>\n",
              "      <td>A comprehensive look at recent machine learnin...</td>\n",
              "      <td>[article, tutorial, deep-learning, health, ehr]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2020-02-20 06:07:59</td>\n",
              "      <td>Automatic Parking Management using computer vi...</td>\n",
              "      <td>Detecting empty and parked spaces in car parki...</td>\n",
              "      <td>[code, tutorial, video, python, machine-learni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2020-02-20 06:21:57</td>\n",
              "      <td>Easy street parking using region proposal netw...</td>\n",
              "      <td>Get a text on your phone whenever a nearby par...</td>\n",
              "      <td>[code, tutorial, python, pytorch, machine-lear...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2020-02-20 06:29:18</td>\n",
              "      <td>Deep Learning based parking management system ...</td>\n",
              "      <td>Fastai provides easy to use wrappers to quickl...</td>\n",
              "      <td>[code, tutorial, fastai, deep-learning, parkin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                               tags\n",
              "0   1  ...  [code, tutorial, keras, pytorch, tensorflow, d...\n",
              "1   2  ...    [article, tutorial, deep-learning, health, ehr]\n",
              "2   3  ...  [code, tutorial, video, python, machine-learni...\n",
              "3   4  ...  [code, tutorial, python, pytorch, machine-lear...\n",
              "4   5  ...  [code, tutorial, fastai, deep-learning, parkin...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXgvuBLwNaQQ",
        "outputId": "af81f6c4-28ea-41d8-c25c-e9728a757ffb"
      },
      "source": [
        "# Load tags (Auxilary dataset)\n",
        "# this dataset has the aliases for our tags, and has parent-child relationships to suggest relevant parent tags\n",
        "url = \"https://raw.githubusercontent.com/GokuMohandas/MadeWithML/main/datasets/tags.json\"\n",
        "tags = json.loads(urlopen(url).read())\n",
        "tags_dict = {}\n",
        "for item in tags:\n",
        "    key = item.pop(\"tag\")\n",
        "    tags_dict[key] = item\n",
        "print (f\"{len(tags_dict)} tags\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400 tags\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183,
          "referenced_widgets": [
            "2f9fe3884c104bc89567274418cc00f6",
            "59f8f34f556f4a9591a51e19fbd1128c",
            "4ddb0afc32784b7083671da814b4c07d",
            "47107cfd319243d6a801050d83fa612d",
            "f94adc79c0a44a898c0ec067fbd533ce",
            "a75abdcebd6847399644e9e00ee6be0b",
            "ee5e97ac9c2148dc81e30810df0402fe"
          ]
        },
        "id": "V2mxXCkXP_sh",
        "outputId": "060db65b-e351-404c-ef7e-597b15034af7"
      },
      "source": [
        "@widgets.interact(tag=list(tags_dict.keys()))\n",
        "def display_tag_details(tag='question-answering'):\n",
        "    print (json.dumps(tags_dict[tag], indent=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f9fe3884c104bc89567274418cc00f6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "interactive(children=(Dropdown(description='tag', index=283, options=('3d', 'action-localization', 'action-rec"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynWp0ek9QBOf",
        "outputId": "b1be31a1-3ab6-4a00-9447-bb909f2eca17"
      },
      "source": [
        "!pip install snorkel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: snorkel in /usr/local/lib/python3.7/dist-packages (0.9.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.33.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (4.62.0)\n",
            "Requirement already satisfied: tensorboard<2.0.0,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn<0.22.0,>=0.20.2 in /usr/local/lib/python3.7/dist-packages (from snorkel) (0.21.3)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.4.1)\n",
            "Requirement already satisfied: pandas<2.0.0,>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.1.5)\n",
            "Requirement already satisfied: munkres>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.1.4)\n",
            "Requirement already satisfied: torch<2.0.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.9.0+cu102)\n",
            "Requirement already satisfied: networkx<2.4,>=2.2 in /usr/local/lib/python3.7/dist-packages (from snorkel) (2.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx<2.4,>=2.2->snorkel) (4.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=0.25.0->snorkel) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=0.25.0->snorkel) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas<2.0.0,>=0.25.0->snorkel) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.22.0,>=0.20.2->snorkel) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (0.37.0)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (1.39.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.0.0,>=1.14.0->snorkel) (4.6.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0.0,>=1.2.0->snorkel) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.0.0,>=1.14.0->snorkel) (3.5.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCJPcs6RQC4h"
      },
      "source": [
        "from snorkel.labeling import labeling_function\n",
        "\n",
        "@labeling_function()\n",
        "def contains_tensorflow(text):\n",
        "    condition = any(tag in text.lower() for tag in (\"tensorflow\", \"tf\"))\n",
        "    return \"tensorflow\" if condition else None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ijtZ4WWQFMK"
      },
      "source": [
        "# Input\n",
        "df['text'] = df.title + \" \" + df.description"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "zAlANCUeQHJC",
        "outputId": "7dc2f052-6874-4262-c9f3-c8e58380b385"
      },
      "source": [
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>created_on</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>tags</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2020-02-17 06:30:41</td>\n",
              "      <td>Machine Learning Basics</td>\n",
              "      <td>A practical set of notebooks on machine learni...</td>\n",
              "      <td>[code, tutorial, keras, pytorch, tensorflow, d...</td>\n",
              "      <td>Machine Learning Basics A practical set of not...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2020-02-17 06:41:45</td>\n",
              "      <td>Deep Learning with Electronic Health Record (E...</td>\n",
              "      <td>A comprehensive look at recent machine learnin...</td>\n",
              "      <td>[article, tutorial, deep-learning, health, ehr]</td>\n",
              "      <td>Deep Learning with Electronic Health Record (E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2020-02-20 06:07:59</td>\n",
              "      <td>Automatic Parking Management using computer vi...</td>\n",
              "      <td>Detecting empty and parked spaces in car parki...</td>\n",
              "      <td>[code, tutorial, video, python, machine-learni...</td>\n",
              "      <td>Automatic Parking Management using computer vi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2020-02-20 06:21:57</td>\n",
              "      <td>Easy street parking using region proposal netw...</td>\n",
              "      <td>Get a text on your phone whenever a nearby par...</td>\n",
              "      <td>[code, tutorial, python, pytorch, machine-lear...</td>\n",
              "      <td>Easy street parking using region proposal netw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2020-02-20 06:29:18</td>\n",
              "      <td>Deep Learning based parking management system ...</td>\n",
              "      <td>Fastai provides easy to use wrappers to quickl...</td>\n",
              "      <td>[code, tutorial, fastai, deep-learning, parkin...</td>\n",
              "      <td>Deep Learning based parking management system ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                               text\n",
              "0   1  ...  Machine Learning Basics A practical set of not...\n",
              "1   2  ...  Deep Learning with Electronic Health Record (E...\n",
              "2   3  ...  Automatic Parking Management using computer vi...\n",
              "3   4  ...  Easy street parking using region proposal netw...\n",
              "4   5  ...  Deep Learning based parking management system ...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALzwh_yVQIZ5"
      },
      "source": [
        "# filtering\n",
        "def filter(l, include=[], exclude=[]):\n",
        "    \"\"\"Filter a list using inclusion and exclusion lists of items.\"\"\"\n",
        "    filtered = [item for item in l if item in include and item not in exclude]\n",
        "    return filtered"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp0pGWtcQKHy"
      },
      "source": [
        "# Inclusion/exclusion criteria for tags\n",
        "include = list(tags_dict.keys())\n",
        "exclude = ['machine-learning', 'deep-learning',  'data-science',\n",
        "           'neural-networks', 'python', 'r', 'visualization']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0-9QvWYQLgx"
      },
      "source": [
        "# Filter tags for each project\n",
        "df.tags = df.tags.apply(filter, include=include, exclude=exclude)\n",
        "tags = Counter(itertools.chain.from_iterable(df.tags.values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183,
          "referenced_widgets": [
            "789355740ea2444aae73af1f78b0dedc",
            "29d2c314905d43ea915a50939b3c3e3e",
            "20867b4167104806a979de215ee30268",
            "ab67b7406a5d480890a6a257fd634bc1",
            "975cbf9616ac41ac9f95f2b99e3e0e3f",
            "716dabd8bf9b4528b5698e4880155079",
            "06915226f8354c45a8b38ba69fef3cbc"
          ]
        },
        "id": "bf9nGzuzQM4a",
        "outputId": "af668462-f986-4145-95d3-433b6d8767bb"
      },
      "source": [
        "@widgets.interact(min_tag_freq=(0, tags.most_common()[0][1]))\n",
        "def separate_tags_by_freq(min_tag_freq=30):\n",
        "    tags_above_freq = Counter(tag for tag in tags.elements()\n",
        "                                    if tags[tag] >= min_tag_freq)\n",
        "    tags_below_freq = Counter(tag for tag in tags.elements()\n",
        "                                    if tags[tag] < min_tag_freq)\n",
        "    print (\"Most popular tags:\\n\", tags_above_freq.most_common(5))\n",
        "    print (\"\\nTags that just made the cut:\\n\", tags_above_freq.most_common()[-5:])\n",
        "    print (\"\\nTags that just missed the cut:\\n\", tags_below_freq.most_common(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "789355740ea2444aae73af1f78b0dedc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=30, description='min_tag_freq', max=424), Output()), _dom_classes=('widg"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e594lKpSQO-a"
      },
      "source": [
        "# Filter tags that have fewer than <min_tag_freq> occurances\n",
        "min_tag_freq = 30\n",
        "tags_above_freq = Counter(tag for tag in tags.elements()\n",
        "                          if tags[tag] >= min_tag_freq)\n",
        "df.tags = df.tags.apply(filter, include=list(tags_above_freq.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8wbKCqzQQyJ",
        "outputId": "08f2c44b-f5da-4fb3-b746-dc4a648b6606"
      },
      "source": [
        "# Remove projects with no more remaining relevant tags\n",
        "df = df[df.tags.map(len) > 0]\n",
        "print (f\"{len(df)} projects\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1444 projects\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2TSL5dnQSEh"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tRvBlutQTVq",
        "outputId": "e666ee26-54b4-4a19-cce0-ce27d5cf99f7"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "STOPWORDS = stopwords.words('english')\n",
        "porter = PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45JsGX4KQU0w"
      },
      "source": [
        "def preprocess(text, lower=True, stem=False, \n",
        "               filters=\"[!\\\"'#$%&()*\\+,-./:;<=>?@\\\\\\[\\]^_`{|}~]\", \n",
        "               stopwords=STOPWORDS):\n",
        "    \"\"\"Conditional preprocessing on our text unique to our task.\"\"\"\n",
        "    # Lower\n",
        "    if lower: \n",
        "        text = text.lower()\n",
        "\n",
        "    # Remove stopwords\n",
        "    pattern = re.compile(r'\\b(' + r'|'.join(stopwords) + r')\\b\\s*')\n",
        "    text = pattern.sub('', text)\n",
        "\n",
        "    # Spacing and filters\n",
        "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\n",
        "    text = re.sub(filters, r\"\", text)\n",
        "    text = re.sub('[^A-Za-z0-9]+', ' ', text) # remove non alphanumeric chars\n",
        "    text = re.sub(' +', ' ', text)  # remove multiple spaces\n",
        "    text = text.strip()\n",
        "\n",
        "    # Remove links\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Stemming\n",
        "    if stem:\n",
        "        text = \" \".join([porter.stem(word) for word in text.split(' ')])\n",
        "\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "a552cef4d20842d29902fb4df1186ed7",
            "8769fc374a7b4ef5aa1fa4f2d82ed0c2",
            "bccadb7258404cd78da77facec7fbc87",
            "b328112aeb3141e3b2eb7df737a6ed63",
            "0cbd36d304894b959754e29dc647ee66",
            "10e24451af714953b29b849c92aa42ac",
            "478259d819b34563958b8ef99257c313",
            "db8693b17a9c417c8b85926a4d5366fb",
            "378dce2ab6354dac907783e1e9c3d4ce",
            "a1647abeaad348e687a10eccb43c67fc"
          ]
        },
        "id": "n8FJOlShQWmQ",
        "outputId": "a2d18b0d-0a15-4734-a719-9f8a3f08945e"
      },
      "source": [
        "@widgets.interact(lower=True, stem=False)\n",
        "def display_preprocessed_text(lower, stem):\n",
        "    text = \"Conditional image generation using Variational Autoencoders and GANs.\"\n",
        "    preprocessed_text = preprocess(text=text, lower=lower, stem=stem)\n",
        "    print (preprocessed_text)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a552cef4d20842d29902fb4df1186ed7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "interactive(children=(Checkbox(value=True, description='lower'), Checkbox(value=False, description='stem'), Ou"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X558Trr9QYRn",
        "outputId": "fb68ce3b-aba5-4f06-fb39-a9301fe6eb75"
      },
      "source": [
        "# Apply to dataframe\n",
        "original_df = df.copy()\n",
        "df.text = df.text.apply(preprocess, lower=True, stem=False)\n",
        "print (f\"{original_df.text.values[0]}\\n{df.text.values[0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Machine Learning Basics A practical set of notebooks on machine learning basics, implemented in both TF2.0 + Keras and PyTorch.\n",
            "machine learning basics practical set notebooks machine learning basics implemented tf2 0 keras pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWbulo9vQZ_H"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "sns.set_theme()\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUDCBl4fQbWQ"
      },
      "source": [
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7lD9bbVQfzo"
      },
      "source": [
        "# Set seeds for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgAGIGNyQhPk"
      },
      "source": [
        "# Shuffle\n",
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SXUpnrBQij5"
      },
      "source": [
        "# Get data\n",
        "X = df.text.to_numpy()\n",
        "y = df.tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvsgqOXoQkTY"
      },
      "source": [
        "class LabelEncoder(object):\n",
        "    \"\"\"Label encoder for tag labels.\"\"\"\n",
        "    def __init__(self, class_to_index={}):\n",
        "        self.class_to_index = class_to_index\n",
        "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
        "        self.classes = list(self.class_to_index.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.class_to_index)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<LabelEncoder(num_classes={len(self)})>\"\n",
        "\n",
        "    def fit(self, y):\n",
        "        classes = np.unique(list(itertools.chain.from_iterable(y)))\n",
        "        for i, class_ in enumerate(classes):\n",
        "            self.class_to_index[class_] = i\n",
        "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
        "        self.classes = list(self.class_to_index.keys())\n",
        "        return self\n",
        "\n",
        "    def encode(self, y):\n",
        "        y_one_hot = np.zeros((len(y), len(self.class_to_index)), dtype=int)\n",
        "        for i, item in enumerate(y):\n",
        "            for class_ in item:\n",
        "                y_one_hot[i][self.class_to_index[class_]] = 1\n",
        "        return y_one_hot\n",
        "\n",
        "    def decode(self, y):\n",
        "        classes = []\n",
        "        for i, item in enumerate(y):\n",
        "            indices = np.where(item == 1)[0]\n",
        "            classes.append([self.index_to_class[index] for index in indices])\n",
        "        return classes\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, 'w') as fp:\n",
        "            contents = {'class_to_index': self.class_to_index}\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, 'r') as fp:\n",
        "            kwargs = json.load(fp=fp)\n",
        "        return cls(**kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKQlYbhlQmDB"
      },
      "source": [
        "# Encode\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y)\n",
        "num_classes = len(label_encoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaHtQ22iQnsx",
        "outputId": "1eaf4e5f-cc72-4ed0-dd9d-48324b1af72b"
      },
      "source": [
        "label_encoder.class_to_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention': 0,\n",
              " 'autoencoders': 1,\n",
              " 'computer-vision': 2,\n",
              " 'convolutional-neural-networks': 3,\n",
              " 'data-augmentation': 4,\n",
              " 'embeddings': 5,\n",
              " 'flask': 6,\n",
              " 'generative-adversarial-networks': 7,\n",
              " 'graph-neural-networks': 8,\n",
              " 'graphs': 9,\n",
              " 'huggingface': 10,\n",
              " 'image-classification': 11,\n",
              " 'interpretability': 12,\n",
              " 'keras': 13,\n",
              " 'language-modeling': 14,\n",
              " 'natural-language-processing': 15,\n",
              " 'node-classification': 16,\n",
              " 'object-detection': 17,\n",
              " 'pretraining': 18,\n",
              " 'production': 19,\n",
              " 'pytorch': 20,\n",
              " 'question-answering': 21,\n",
              " 'regression': 22,\n",
              " 'reinforcement-learning': 23,\n",
              " 'representation-learning': 24,\n",
              " 'scikit-learn': 25,\n",
              " 'segmentation': 26,\n",
              " 'self-supervised-learning': 27,\n",
              " 'tensorflow': 28,\n",
              " 'tensorflow-js': 29,\n",
              " 'time-series': 30,\n",
              " 'transfer-learning': 31,\n",
              " 'transformers': 32,\n",
              " 'unsupervised-learning': 33,\n",
              " 'wandb': 34}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IssYos6QQpup",
        "outputId": "c36d1801-0b7b-4a18-e301-60d615f0ffb3"
      },
      "source": [
        "# Sample\n",
        "label_encoder.encode([[\"attention\", \"data-augmentation\"]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShY6pfdwQr1X",
        "outputId": "5ade9833-3751-47b9-f3a8-ac939fd2fd1d"
      },
      "source": [
        "# Encode all our labels\n",
        "y = label_encoder.encode(y)\n",
        "print (y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1444, 35)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJnqa6jHQtXo",
        "outputId": "0f2126a5-d69c-4858-b724-691d7a62dbea"
      },
      "source": [
        "!pip install scikit-multilearn==0.2.0 -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn_jCdEfQu4x"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from skmultilearn.model_selection.measures import get_combination_wise_output_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnASk-WWQwg4"
      },
      "source": [
        "# Split sizes\n",
        "train_size = 0.7\n",
        "val_size = 0.15\n",
        "test_size = 0.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWbMRFeUQzUx"
      },
      "source": [
        "# Split (train)\n",
        "X_train, X_, y_train, y_ = train_test_split(X, y, train_size=train_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHAqUArsQ0zv"
      },
      "source": [
        "# Split (test)\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_, y_, train_size=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb20Kwo1Q2IJ",
        "outputId": "65fa9fce-a8bd-4c7d-bce1-2cba1b075808"
      },
      "source": [
        "print(f\"train: {len(X_train)} ({len(X_train)/len(X):.2f})\\n\"\n",
        "      f\"val: {len(X_val)} ({len(X_val)/len(X):.2f})\\n\"\n",
        "      f\"test: {len(X_test)} ({len(X_test)/len(X):.2f})\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 1010 (0.70)\n",
            "val: 217 (0.15)\n",
            "test: 217 (0.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFKafl0pQ3vY",
        "outputId": "0ad9a619-43be-48af-de04-59ec6fc2afb8"
      },
      "source": [
        "# Get counts for each class\n",
        "counts = {}\n",
        "counts['train_counts'] = Counter(str(combination) for row in get_combination_wise_output_matrix(\n",
        "    y_train, order=1) for combination in row)\n",
        "counts['val_counts'] = Counter(str(combination) for row in get_combination_wise_output_matrix(\n",
        "    y_val, order=1) for combination in row)\n",
        "counts['test_counts'] = Counter(str(combination) for row in get_combination_wise_output_matrix(\n",
        "    y_test, order=1) for combination in row)\n",
        "\n",
        "counts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_counts': Counter({'(0,)': 15,\n",
              "          '(1,)': 8,\n",
              "          '(10,)': 7,\n",
              "          '(11,)': 8,\n",
              "          '(12,)': 9,\n",
              "          '(13,)': 12,\n",
              "          '(14,)': 6,\n",
              "          '(15,)': 66,\n",
              "          '(16,)': 5,\n",
              "          '(17,)': 11,\n",
              "          '(18,)': 3,\n",
              "          '(19,)': 5,\n",
              "          '(2,)': 60,\n",
              "          '(20,)': 41,\n",
              "          '(21,)': 4,\n",
              "          '(22,)': 2,\n",
              "          '(23,)': 10,\n",
              "          '(24,)': 10,\n",
              "          '(25,)': 11,\n",
              "          '(26,)': 10,\n",
              "          '(27,)': 2,\n",
              "          '(28,)': 26,\n",
              "          '(29,)': 6,\n",
              "          '(3,)': 19,\n",
              "          '(30,)': 4,\n",
              "          '(31,)': 5,\n",
              "          '(32,)': 24,\n",
              "          '(33,)': 4,\n",
              "          '(34,)': 5,\n",
              "          '(4,)': 3,\n",
              "          '(5,)': 8,\n",
              "          '(6,)': 7,\n",
              "          '(7,)': 11,\n",
              "          '(8,)': 11,\n",
              "          '(9,)': 15}),\n",
              " 'train_counts': Counter({'(0,)': 79,\n",
              "          '(1,)': 28,\n",
              "          '(10,)': 45,\n",
              "          '(11,)': 32,\n",
              "          '(12,)': 40,\n",
              "          '(13,)': 66,\n",
              "          '(14,)': 35,\n",
              "          '(15,)': 289,\n",
              "          '(16,)': 24,\n",
              "          '(17,)': 46,\n",
              "          '(18,)': 24,\n",
              "          '(19,)': 40,\n",
              "          '(2,)': 271,\n",
              "          '(20,)': 184,\n",
              "          '(21,)': 23,\n",
              "          '(22,)': 42,\n",
              "          '(23,)': 39,\n",
              "          '(24,)': 41,\n",
              "          '(25,)': 43,\n",
              "          '(26,)': 33,\n",
              "          '(27,)': 30,\n",
              "          '(28,)': 158,\n",
              "          '(29,)': 30,\n",
              "          '(3,)': 69,\n",
              "          '(30,)': 25,\n",
              "          '(31,)': 32,\n",
              "          '(32,)': 134,\n",
              "          '(33,)': 29,\n",
              "          '(34,)': 28,\n",
              "          '(4,)': 30,\n",
              "          '(5,)': 58,\n",
              "          '(6,)': 20,\n",
              "          '(7,)': 49,\n",
              "          '(8,)': 35,\n",
              "          '(9,)': 54}),\n",
              " 'val_counts': Counter({'(0,)': 26,\n",
              "          '(1,)': 5,\n",
              "          '(10,)': 12,\n",
              "          '(11,)': 11,\n",
              "          '(12,)': 6,\n",
              "          '(13,)': 15,\n",
              "          '(14,)': 10,\n",
              "          '(15,)': 69,\n",
              "          '(16,)': 4,\n",
              "          '(17,)': 12,\n",
              "          '(18,)': 3,\n",
              "          '(19,)': 6,\n",
              "          '(2,)': 57,\n",
              "          '(20,)': 33,\n",
              "          '(21,)': 5,\n",
              "          '(22,)': 5,\n",
              "          '(23,)': 10,\n",
              "          '(24,)': 6,\n",
              "          '(25,)': 6,\n",
              "          '(26,)': 5,\n",
              "          '(27,)': 8,\n",
              "          '(28,)': 29,\n",
              "          '(29,)': 4,\n",
              "          '(3,)': 18,\n",
              "          '(30,)': 5,\n",
              "          '(31,)': 9,\n",
              "          '(32,)': 38,\n",
              "          '(33,)': 6,\n",
              "          '(34,)': 6,\n",
              "          '(4,)': 8,\n",
              "          '(5,)': 9,\n",
              "          '(6,)': 7,\n",
              "          '(7,)': 13,\n",
              "          '(8,)': 5,\n",
              "          '(9,)': 9})}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "k0SbhNTcQ5Y5",
        "outputId": "00de27ff-3139-462a-8e25-5c0ba0bc2d91"
      },
      "source": [
        "# View distributions\n",
        "pd.DataFrame({\n",
        "    \"train\": counts[\"train_counts\"],\n",
        "    \"val\": counts[\"val_counts\"],\n",
        "    \"test\": counts[\"test_counts\"]\n",
        "}).T.fillna(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>(2,)</th>\n",
              "      <th>(26,)</th>\n",
              "      <th>(15,)</th>\n",
              "      <th>(5,)</th>\n",
              "      <th>(20,)</th>\n",
              "      <th>(32,)</th>\n",
              "      <th>(0,)</th>\n",
              "      <th>(28,)</th>\n",
              "      <th>(27,)</th>\n",
              "      <th>(17,)</th>\n",
              "      <th>(25,)</th>\n",
              "      <th>(1,)</th>\n",
              "      <th>(34,)</th>\n",
              "      <th>(3,)</th>\n",
              "      <th>(31,)</th>\n",
              "      <th>(11,)</th>\n",
              "      <th>(19,)</th>\n",
              "      <th>(10,)</th>\n",
              "      <th>(18,)</th>\n",
              "      <th>(13,)</th>\n",
              "      <th>(16,)</th>\n",
              "      <th>(9,)</th>\n",
              "      <th>(21,)</th>\n",
              "      <th>(6,)</th>\n",
              "      <th>(23,)</th>\n",
              "      <th>(33,)</th>\n",
              "      <th>(14,)</th>\n",
              "      <th>(29,)</th>\n",
              "      <th>(22,)</th>\n",
              "      <th>(30,)</th>\n",
              "      <th>(4,)</th>\n",
              "      <th>(24,)</th>\n",
              "      <th>(12,)</th>\n",
              "      <th>(8,)</th>\n",
              "      <th>(7,)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>271</td>\n",
              "      <td>33</td>\n",
              "      <td>289</td>\n",
              "      <td>58</td>\n",
              "      <td>184</td>\n",
              "      <td>134</td>\n",
              "      <td>79</td>\n",
              "      <td>158</td>\n",
              "      <td>30</td>\n",
              "      <td>46</td>\n",
              "      <td>43</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>69</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "      <td>45</td>\n",
              "      <td>24</td>\n",
              "      <td>66</td>\n",
              "      <td>24</td>\n",
              "      <td>54</td>\n",
              "      <td>23</td>\n",
              "      <td>20</td>\n",
              "      <td>39</td>\n",
              "      <td>29</td>\n",
              "      <td>35</td>\n",
              "      <td>30</td>\n",
              "      <td>42</td>\n",
              "      <td>25</td>\n",
              "      <td>30</td>\n",
              "      <td>41</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>57</td>\n",
              "      <td>5</td>\n",
              "      <td>69</td>\n",
              "      <td>9</td>\n",
              "      <td>33</td>\n",
              "      <td>38</td>\n",
              "      <td>26</td>\n",
              "      <td>29</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>60</td>\n",
              "      <td>10</td>\n",
              "      <td>66</td>\n",
              "      <td>8</td>\n",
              "      <td>41</td>\n",
              "      <td>24</td>\n",
              "      <td>15</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>19</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       (2,)  (26,)  (15,)  (5,)  (20,)  ...  (4,)  (24,)  (12,)  (8,)  (7,)\n",
              "train   271     33    289    58    184  ...    30     41     40    35    49\n",
              "val      57      5     69     9     33  ...     8      6      6     5    13\n",
              "test     60     10     66     8     41  ...     3     10      9    11    11\n",
              "\n",
              "[3 rows x 35 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHHUFkNmQ8vp"
      },
      "source": [
        "# Adjust counts across splits\n",
        "for k in counts[\"val_counts\"].keys():\n",
        "    counts[\"val_counts\"][k] = int(counts[\"val_counts\"][k] * \\\n",
        "        (train_size/val_size))\n",
        "for k in counts[\"test_counts\"].keys():\n",
        "    counts[\"test_counts\"][k] = int(counts[\"test_counts\"][k] * \\\n",
        "        (train_size/test_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "YLce5K9ZQ-lB",
        "outputId": "34cfcb60-32f9-4b1d-e3f1-1a56569b04d3"
      },
      "source": [
        "dist_df = pd.DataFrame({\n",
        "    \"train\": counts[\"train_counts\"],\n",
        "    \"val\": counts[\"val_counts\"],\n",
        "    \"test\": counts[\"test_counts\"]\n",
        "}).T.fillna(0)\n",
        "dist_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>(2,)</th>\n",
              "      <th>(26,)</th>\n",
              "      <th>(15,)</th>\n",
              "      <th>(5,)</th>\n",
              "      <th>(20,)</th>\n",
              "      <th>(32,)</th>\n",
              "      <th>(0,)</th>\n",
              "      <th>(28,)</th>\n",
              "      <th>(27,)</th>\n",
              "      <th>(17,)</th>\n",
              "      <th>(25,)</th>\n",
              "      <th>(1,)</th>\n",
              "      <th>(34,)</th>\n",
              "      <th>(3,)</th>\n",
              "      <th>(31,)</th>\n",
              "      <th>(11,)</th>\n",
              "      <th>(19,)</th>\n",
              "      <th>(10,)</th>\n",
              "      <th>(18,)</th>\n",
              "      <th>(13,)</th>\n",
              "      <th>(16,)</th>\n",
              "      <th>(9,)</th>\n",
              "      <th>(21,)</th>\n",
              "      <th>(6,)</th>\n",
              "      <th>(23,)</th>\n",
              "      <th>(33,)</th>\n",
              "      <th>(14,)</th>\n",
              "      <th>(29,)</th>\n",
              "      <th>(22,)</th>\n",
              "      <th>(30,)</th>\n",
              "      <th>(4,)</th>\n",
              "      <th>(24,)</th>\n",
              "      <th>(12,)</th>\n",
              "      <th>(8,)</th>\n",
              "      <th>(7,)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>271</td>\n",
              "      <td>33</td>\n",
              "      <td>289</td>\n",
              "      <td>58</td>\n",
              "      <td>184</td>\n",
              "      <td>134</td>\n",
              "      <td>79</td>\n",
              "      <td>158</td>\n",
              "      <td>30</td>\n",
              "      <td>46</td>\n",
              "      <td>43</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>69</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "      <td>45</td>\n",
              "      <td>24</td>\n",
              "      <td>66</td>\n",
              "      <td>24</td>\n",
              "      <td>54</td>\n",
              "      <td>23</td>\n",
              "      <td>20</td>\n",
              "      <td>39</td>\n",
              "      <td>29</td>\n",
              "      <td>35</td>\n",
              "      <td>30</td>\n",
              "      <td>42</td>\n",
              "      <td>25</td>\n",
              "      <td>30</td>\n",
              "      <td>41</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>266</td>\n",
              "      <td>23</td>\n",
              "      <td>322</td>\n",
              "      <td>42</td>\n",
              "      <td>154</td>\n",
              "      <td>177</td>\n",
              "      <td>121</td>\n",
              "      <td>135</td>\n",
              "      <td>37</td>\n",
              "      <td>56</td>\n",
              "      <td>28</td>\n",
              "      <td>23</td>\n",
              "      <td>28</td>\n",
              "      <td>84</td>\n",
              "      <td>42</td>\n",
              "      <td>51</td>\n",
              "      <td>28</td>\n",
              "      <td>56</td>\n",
              "      <td>14</td>\n",
              "      <td>70</td>\n",
              "      <td>18</td>\n",
              "      <td>42</td>\n",
              "      <td>23</td>\n",
              "      <td>32</td>\n",
              "      <td>46</td>\n",
              "      <td>28</td>\n",
              "      <td>46</td>\n",
              "      <td>18</td>\n",
              "      <td>23</td>\n",
              "      <td>23</td>\n",
              "      <td>37</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>23</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>280</td>\n",
              "      <td>46</td>\n",
              "      <td>308</td>\n",
              "      <td>37</td>\n",
              "      <td>191</td>\n",
              "      <td>112</td>\n",
              "      <td>70</td>\n",
              "      <td>121</td>\n",
              "      <td>9</td>\n",
              "      <td>51</td>\n",
              "      <td>51</td>\n",
              "      <td>37</td>\n",
              "      <td>23</td>\n",
              "      <td>88</td>\n",
              "      <td>23</td>\n",
              "      <td>37</td>\n",
              "      <td>23</td>\n",
              "      <td>32</td>\n",
              "      <td>14</td>\n",
              "      <td>56</td>\n",
              "      <td>23</td>\n",
              "      <td>70</td>\n",
              "      <td>18</td>\n",
              "      <td>32</td>\n",
              "      <td>46</td>\n",
              "      <td>18</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>14</td>\n",
              "      <td>46</td>\n",
              "      <td>42</td>\n",
              "      <td>51</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       (2,)  (26,)  (15,)  (5,)  (20,)  ...  (4,)  (24,)  (12,)  (8,)  (7,)\n",
              "train   271     33    289    58    184  ...    30     41     40    35    49\n",
              "val     266     23    322    42    154  ...    37     28     28    23    60\n",
              "test    280     46    308    37    191  ...    14     46     42    51    51\n",
              "\n",
              "[3 rows x 35 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ1sUSVuQ_05",
        "outputId": "36a42861-9725-4295-c1bc-475ba8dd447a"
      },
      "source": [
        "# Standard deviation\n",
        "np.mean(np.std(dist_df.to_numpy(), axis=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.644273732900697"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1jirhlHRBlo"
      },
      "source": [
        "from skmultilearn.model_selection import IterativeStratification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmcvKDDiRDH4"
      },
      "source": [
        "def iterative_train_test_split(X, y, train_size):\n",
        "    \"\"\"Custom iterative train test split which\n",
        "    'maintains balanced representation with respect\n",
        "    to order-th label combinations.'\n",
        "    \"\"\"\n",
        "    stratifier = IterativeStratification(\n",
        "        n_splits=2, order=1, sample_distribution_per_fold=[1.0-train_size, train_size, ])\n",
        "    train_indices, test_indices = next(stratifier.split(X, y))\n",
        "    X_train, y_train = X[train_indices], y[train_indices]\n",
        "    X_test, y_test = X[test_indices], y[test_indices]\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQVRR2AoREpY"
      },
      "source": [
        "# Get data\n",
        "X = df.text.to_numpy()\n",
        "y = df.tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZAjCN3TRF7g"
      },
      "source": [
        "# Binarize y\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y)\n",
        "y = label_encoder.encode(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkcN_9-CRHtA"
      },
      "source": [
        "# Split\n",
        "X_train, X_, y_train, y_ = iterative_train_test_split(\n",
        "    X, y, train_size=train_size)\n",
        "X_val, X_test, y_val, y_test = iterative_train_test_split(\n",
        "    X_, y_, train_size=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3ans3HvRJIw",
        "outputId": "c1622868-3dfa-443a-b618-31a308a4671d"
      },
      "source": [
        "print(f\"train: {len(X_train)} ({len(X_train)/len(X):.2f})\\n\"\n",
        "      f\"val: {len(X_val)} ({len(X_val)/len(X):.2f})\\n\"\n",
        "      f\"test: {len(X_test)} ({len(X_test)/len(X):.2f})\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 1023 (0.71)\n",
            "val: 218 (0.15)\n",
            "test: 203 (0.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QpQ36g0RLbA"
      },
      "source": [
        "# Get counts for each class\n",
        "counts = {}\n",
        "counts[\"train_counts\"] = Counter(str(combination) for row in get_combination_wise_output_matrix(\n",
        "    y_train, order=1) for combination in row)\n",
        "counts[\"val_counts\"] = Counter(str(combination) for row in get_combination_wise_output_matrix(\n",
        "    y_val, order=1) for combination in row)\n",
        "counts[\"test_counts\"] = Counter(str(combination) for row in get_combination_wise_output_matrix(\n",
        "    y_test, order=1) for combination in row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBgyNf8KRNLA"
      },
      "source": [
        "# Adjust counts across splits\n",
        "for k in counts[\"val_counts\"].keys():\n",
        "    counts[\"val_counts\"][k] = int(counts[\"val_counts\"][k] * \\\n",
        "        (train_size/val_size))\n",
        "for k in counts[\"test_counts\"].keys():\n",
        "    counts[\"test_counts\"][k] = int(counts[\"test_counts\"][k] * \\\n",
        "        (train_size/test_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "XDn7jSpoROwQ",
        "outputId": "a3743f3b-cc2d-4156-c223-83956b550682"
      },
      "source": [
        "# View distributions\n",
        "pd.DataFrame({\n",
        "    \"train\": counts[\"train_counts\"],\n",
        "    \"val\": counts[\"val_counts\"],\n",
        "    \"test\": counts[\"test_counts\"]\n",
        "}).T.fillna(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>(15,)</th>\n",
              "      <th>(7,)</th>\n",
              "      <th>(2,)</th>\n",
              "      <th>(1,)</th>\n",
              "      <th>(20,)</th>\n",
              "      <th>(4,)</th>\n",
              "      <th>(8,)</th>\n",
              "      <th>(9,)</th>\n",
              "      <th>(0,)</th>\n",
              "      <th>(32,)</th>\n",
              "      <th>(31,)</th>\n",
              "      <th>(5,)</th>\n",
              "      <th>(14,)</th>\n",
              "      <th>(13,)</th>\n",
              "      <th>(28,)</th>\n",
              "      <th>(27,)</th>\n",
              "      <th>(33,)</th>\n",
              "      <th>(19,)</th>\n",
              "      <th>(29,)</th>\n",
              "      <th>(3,)</th>\n",
              "      <th>(11,)</th>\n",
              "      <th>(17,)</th>\n",
              "      <th>(18,)</th>\n",
              "      <th>(25,)</th>\n",
              "      <th>(30,)</th>\n",
              "      <th>(23,)</th>\n",
              "      <th>(12,)</th>\n",
              "      <th>(10,)</th>\n",
              "      <th>(21,)</th>\n",
              "      <th>(34,)</th>\n",
              "      <th>(22,)</th>\n",
              "      <th>(26,)</th>\n",
              "      <th>(6,)</th>\n",
              "      <th>(24,)</th>\n",
              "      <th>(16,)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>297</td>\n",
              "      <td>51</td>\n",
              "      <td>272</td>\n",
              "      <td>29</td>\n",
              "      <td>181</td>\n",
              "      <td>29</td>\n",
              "      <td>36</td>\n",
              "      <td>55</td>\n",
              "      <td>84</td>\n",
              "      <td>142</td>\n",
              "      <td>31</td>\n",
              "      <td>52</td>\n",
              "      <td>42</td>\n",
              "      <td>65</td>\n",
              "      <td>149</td>\n",
              "      <td>28</td>\n",
              "      <td>27</td>\n",
              "      <td>36</td>\n",
              "      <td>28</td>\n",
              "      <td>74</td>\n",
              "      <td>37</td>\n",
              "      <td>51</td>\n",
              "      <td>26</td>\n",
              "      <td>42</td>\n",
              "      <td>24</td>\n",
              "      <td>41</td>\n",
              "      <td>38</td>\n",
              "      <td>49</td>\n",
              "      <td>27</td>\n",
              "      <td>28</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "      <td>24</td>\n",
              "      <td>42</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>298</td>\n",
              "      <td>46</td>\n",
              "      <td>270</td>\n",
              "      <td>37</td>\n",
              "      <td>177</td>\n",
              "      <td>28</td>\n",
              "      <td>46</td>\n",
              "      <td>56</td>\n",
              "      <td>60</td>\n",
              "      <td>121</td>\n",
              "      <td>60</td>\n",
              "      <td>56</td>\n",
              "      <td>23</td>\n",
              "      <td>56</td>\n",
              "      <td>149</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>32</td>\n",
              "      <td>28</td>\n",
              "      <td>74</td>\n",
              "      <td>28</td>\n",
              "      <td>51</td>\n",
              "      <td>9</td>\n",
              "      <td>42</td>\n",
              "      <td>23</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>37</td>\n",
              "      <td>14</td>\n",
              "      <td>28</td>\n",
              "      <td>32</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>23</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>294</td>\n",
              "      <td>56</td>\n",
              "      <td>270</td>\n",
              "      <td>18</td>\n",
              "      <td>182</td>\n",
              "      <td>28</td>\n",
              "      <td>23</td>\n",
              "      <td>51</td>\n",
              "      <td>107</td>\n",
              "      <td>130</td>\n",
              "      <td>9</td>\n",
              "      <td>51</td>\n",
              "      <td>18</td>\n",
              "      <td>74</td>\n",
              "      <td>149</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>37</td>\n",
              "      <td>28</td>\n",
              "      <td>74</td>\n",
              "      <td>37</td>\n",
              "      <td>32</td>\n",
              "      <td>9</td>\n",
              "      <td>42</td>\n",
              "      <td>23</td>\n",
              "      <td>42</td>\n",
              "      <td>37</td>\n",
              "      <td>32</td>\n",
              "      <td>9</td>\n",
              "      <td>23</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>18</td>\n",
              "      <td>46</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       (15,)  (7,)  (2,)  (1,)  (20,)  ...  (22,)  (26,)  (6,)  (24,)  (16,)\n",
              "train    297    51   272    29    181  ...     34     34    24     42     24\n",
              "val      298    46   270    37    177  ...     32     28    28     23      9\n",
              "test     294    56   270    18    182  ...     37     37    18     46     32\n",
              "\n",
              "[3 rows x 35 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RTW61X2RQPH"
      },
      "source": [
        "dist_df = pd.DataFrame({\n",
        "    \"train\": counts[\"train_counts\"],\n",
        "    \"val\": counts[\"val_counts\"],\n",
        "    \"test\": counts[\"test_counts\"]\n",
        "}).T.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZa8gvOcRR_w",
        "outputId": "9e9f586e-118a-418f-b41c-7a43123666e2"
      },
      "source": [
        "# Standard deviation\n",
        "np.mean(np.std(dist_df.to_numpy(), axis=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.878424991639657"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukJF0rTpRTUA"
      },
      "source": [
        "# Split DataFrames\n",
        "train_df = pd.DataFrame({\"text\": X_train, \"tags\": label_encoder.decode(y_train)})\n",
        "val_df = pd.DataFrame({\"text\": X_val, \"tags\": label_encoder.decode(y_val)})\n",
        "test_df = pd.DataFrame({\"text\": X_test, \"tags\": label_encoder.decode(y_test)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "P8pRPj3bRVK4",
        "outputId": "32a3b63f-9786-411d-a9ed-348b19ad545b"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>medacy medical text mining information extract...</td>\n",
              "      <td>[natural-language-processing]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pytorch tutorial deep learning researchers rep...</td>\n",
              "      <td>[autoencoders, computer-vision, generative-adv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>deltapy tabular data augmentation feature engi...</td>\n",
              "      <td>[data-augmentation]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>graph convolution structured documents convert...</td>\n",
              "      <td>[computer-vision, graph-neural-networks, graphs]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>illustrated bert elmo co nlp cracked transfer ...</td>\n",
              "      <td>[attention, embeddings, language-modeling, nat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                                               tags\n",
              "0  medacy medical text mining information extract...                      [natural-language-processing]\n",
              "1  pytorch tutorial deep learning researchers rep...  [autoencoders, computer-vision, generative-adv...\n",
              "2  deltapy tabular data augmentation feature engi...                                [data-augmentation]\n",
              "3  graph convolution structured documents convert...   [computer-vision, graph-neural-networks, graphs]\n",
              "4  illustrated bert elmo co nlp cracked transfer ...  [attention, embeddings, language-modeling, nat..."
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ygBJZR0RWbA",
        "outputId": "9cca7474-f99e-447a-f185-2ff1a3be0a89"
      },
      "source": [
        "!python -m pip install --upgrade pip\n",
        "!pip install nlpaug==1.1.0 transformers==3.0.2 -q\n",
        "!pip install snorkel==0.9.6 -q --use-feature=2020-resolver"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.2.4)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001b[0m\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYDpnp96RYRI"
      },
      "source": [
        "import nlpaug.augmenter.word as naw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsMiJjdVRakP"
      },
      "source": [
        "# Load tokenizer and transformers\n",
        "substituion = naw.ContextualWordEmbsAug(model_path=\"distilbert-base-uncased\", action=\"substitute\")\n",
        "insertion = naw.ContextualWordEmbsAug(model_path=\"distilbert-base-uncased\", action=\"insert\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj60hHtYRcO5"
      },
      "source": [
        "text = \"Conditional image generation using Variational Autoencoders and GANs.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk0BjjUqRdvn",
        "outputId": "3ab343b9-ee80-4204-c4b3-eddbebe4f607"
      },
      "source": [
        "augmentated_text = substituion.augment(text)\n",
        "print(augmentated_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "supports binary encoding using variational encoding and gans.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDTjZQ0RRfOA",
        "outputId": "aef0ff58-fe9e-43dd-8e23-210d7d949dfe"
      },
      "source": [
        "# Insertions\n",
        "augmentated_text = insertion.augment(text)\n",
        "print(augmentated_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "performs conditional sequential image generation algorithms using dynamic variational autoencoders and gans.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roKoknlLRgh9"
      },
      "source": [
        "import inflect\n",
        "from snorkel.augmentation import transformation_function\n",
        "inflect = inflect.engine()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBYhapK9RidQ",
        "outputId": "7e417699-c29b-418b-c261-102bec931644"
      },
      "source": [
        "# Inflect\n",
        "print (inflect.singular_noun(\"graphs\"))\n",
        "print (inflect.singular_noun(\"graph\"))\n",
        "print (inflect.plural_noun(\"graph\"))\n",
        "print (inflect.plural_noun(\"graphs\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "graph\n",
            "False\n",
            "graphs\n",
            "graphss\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgg4HHVbRkb-"
      },
      "source": [
        "def replace_dash(x):\n",
        "    return x.replace(\"-\", \" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6xCE0dpRmzP"
      },
      "source": [
        "flat_tags_dict = {}\n",
        "for tag, info in tags_dict.items():\n",
        "    tag = tag.replace(\"-\", \" \")\n",
        "    aliases = list(map(replace_dash, info[\"aliases\"]))\n",
        "    if len(aliases):\n",
        "        flat_tags_dict[tag] = aliases\n",
        "    for alias in aliases:\n",
        "        _aliases = aliases + [tag]\n",
        "        _aliases.remove(alias)\n",
        "        flat_tags_dict[alias] = _aliases"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQesQMsBRoZQ"
      },
      "source": [
        "# Tags that could be singular or plural\n",
        "can_be_singular = [\n",
        "    'animations',\n",
        "    'cartoons',\n",
        "    'autoencoders',\n",
        "    'conditional random fields',\n",
        "    'convolutional neural networks',\n",
        "    'databases',\n",
        "    'deep q networks',\n",
        "    'gated recurrent units',\n",
        "    'gaussian processes',\n",
        "    'generative adversarial networks',\n",
        "    'graph convolutional networks',\n",
        "    'graph neural networks',\n",
        "    'k nearest neighbors',\n",
        "    'learning rates',\n",
        "    'multilayer perceptrons',\n",
        "    'outliers',\n",
        "    'pos',\n",
        "    'quasi recurrent neural networks',\n",
        "    'recommendation systems',\n",
        "    'recurrent neural networks',\n",
        "    'streaming data',\n",
        "    'data streams',\n",
        "    'support vector machines',\n",
        "    'variational autoencoders']\n",
        "can_be_plural = [\n",
        "    'annotation',\n",
        "    'data annotation',\n",
        "    'continuous integration',\n",
        "    'continuous deployment',\n",
        "    'crf',\n",
        "    'conversational ai',\n",
        "    'chatbot',\n",
        "    'cnn',\n",
        "    'db',\n",
        "    'dqn',\n",
        "    'expectation maximization',\n",
        "    'fine tuning',\n",
        "    'finetuning',\n",
        "    'finetune',\n",
        "    'gru',\n",
        "    'gan',\n",
        "    'gcn',\n",
        "    'gnn',\n",
        "    'hyperparameter optimization',\n",
        "    'hyperparameter tuning',\n",
        "    'image generation',\n",
        "    'inference',\n",
        "    'prediction',\n",
        "    'knn',\n",
        "    'knowledge base',\n",
        "    'language modeling',\n",
        "    'latent dirichlet allocation',\n",
        "    'lstm',\n",
        "    'machine translation',\n",
        "    'model compression',\n",
        "    'compression',\n",
        "    'perceptron',\n",
        "    'mlp',\n",
        "    'optical character recognition',\n",
        "    'outlier detection',\n",
        "    'pos tagging',\n",
        "    'pca',\n",
        "    'qrnn',\n",
        "    'rnn',\n",
        "    'segmentation',\n",
        "    'image segmentation',\n",
        "    'spatial temporal cnn',\n",
        "    'data streaming',\n",
        "    'svm',\n",
        "    'tabular',\n",
        "    'temporal cnn',\n",
        "    'tcnn',\n",
        "    'vae',\n",
        "    'vqa',\n",
        "    'visualization',\n",
        "    'data visualization']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "368cQvtPRqJf"
      },
      "source": [
        "# Add to flattened dict\n",
        "for tag in can_be_singular:\n",
        "    flat_tags_dict[inflect.singular_noun(tag)] = flat_tags_dict[tag]\n",
        "for tag in can_be_plural:\n",
        "    flat_tags_dict[inflect.plural_noun(tag)] = flat_tags_dict[tag]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymd7RaFGRsK3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol1Xflxy5ZBM",
        "outputId": "b4796f5f-e1eb-487e-d83d-9ac6dc730bd3"
      },
      "source": [
        "print (flat_tags_dict[\"gan\"])\n",
        "print (flat_tags_dict[\"gans\"])\n",
        "print (flat_tags_dict[\"generative adversarial network\"])\n",
        "print (flat_tags_dict[\"generative adversarial networks\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['generative adversarial networks']\n",
            "['generative adversarial networks']\n",
            "['gan']\n",
            "['gan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkYC0vL6RvTv"
      },
      "source": [
        "def find_word(word, text):\n",
        "    word = word.replace(\"+\", \"\\+\")\n",
        "    pattern = re.compile(fr\"\\b({word})\\b\", flags=re.IGNORECASE)\n",
        "    return pattern.search(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_YS6N4NRxZo"
      },
      "source": [
        "@transformation_function()\n",
        "def swap_aliases(x):\n",
        "    \"\"\" Swap ML keywords with their aliases\"\"\"\n",
        "    # Find all matches\n",
        "    matches = []\n",
        "    for i, tag in enumerate(flat_tags_dict):\n",
        "        match = find_word(tag, x.text)\n",
        "        if match:\n",
        "            matches.append(match)\n",
        "    \n",
        "    # Swap a random match with a random alias\n",
        "    if len(matches):\n",
        "        match = random.choice(matches)\n",
        "        tag = x.text[match.start():match.end()]\n",
        "        x.text = f\"{x.text[:match.start()]}{random.choice(flat_tags_dict[tag])}{x.text[match.end():]}\"\n",
        "    \n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDYB1WfCRy9Y",
        "outputId": "39dbcf51-3036-4bb8-f2a2-bcc98d367a40"
      },
      "source": [
        "# Swap\n",
        "for i in range(3):\n",
        "    sample_df = pd.DataFrame([{\"text\": \"a survey of reinforcement learning for nlp tasks.\"}])\n",
        "    sample_df.text = sample_df.text.apply(preprocess, lower=True, stem=False)\n",
        "    print (swap_aliases(sample_df.iloc[0]).text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "survey reinforcement learning nlproc tasks\n",
            "survey rl nlp tasks\n",
            "survey rl nlp tasks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3GxwRbnR0rX",
        "outputId": "db6b8a55-9c54-41de-8259-9e0873f95fda"
      },
      "source": [
        "# Undesired behavior (needs contextual insight)\n",
        "for i in range(3):\n",
        "    sample_df = pd.DataFrame([{\"text\": \"Autogenerate your CV to apply for jobs using NLP.\"}])\n",
        "    sample_df.text = sample_df.text.apply(preprocess, lower=True, stem=False)\n",
        "    print (swap_aliases(sample_df.iloc[0]).text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "autogenerate vision apply jobs using nlp\n",
            "autogenerate cv apply jobs using natural language processing\n",
            "autogenerate cv apply jobs using nlproc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTKeObqGR2KQ"
      },
      "source": [
        "from snorkel.augmentation import ApplyOnePolicy, PandasTFApplier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "hfznS_KbR4EX",
        "outputId": "9e8a2f96-14d5-4281-943a-5eb20278516a"
      },
      "source": [
        "# Transformation function (TF) policy\n",
        "policy = ApplyOnePolicy(n_per_original=5, keep_original=True)\n",
        "tf_applier = PandasTFApplier([swap_aliases], policy)\n",
        "train_df_augmented = tf_applier.apply(train_df)\n",
        "train_df_augmented.drop_duplicates(subset=[\"text\"], inplace=True)\n",
        "train_df_augmented.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 1023/1023 [00:15<00:00, 65.66it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>medacy medical text mining information extract...</td>\n",
              "      <td>[natural-language-processing]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pytorch tutorial deep learning researchers rep...</td>\n",
              "      <td>[autoencoders, computer-vision, generative-adv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pytorch tutorial dl researchers repository pro...</td>\n",
              "      <td>[autoencoders, computer-vision, generative-adv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>deltapy tabular data augmentation feature engi...</td>\n",
              "      <td>[data-augmentation]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>deltapy table augmentation feature engineering</td>\n",
              "      <td>[data-augmentation]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                                               tags\n",
              "0  medacy medical text mining information extract...                      [natural-language-processing]\n",
              "1  pytorch tutorial deep learning researchers rep...  [autoencoders, computer-vision, generative-adv...\n",
              "1  pytorch tutorial dl researchers repository pro...  [autoencoders, computer-vision, generative-adv...\n",
              "2  deltapy tabular data augmentation feature engi...                                [data-augmentation]\n",
              "2     deltapy table augmentation feature engineering                                [data-augmentation]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRnGSuosR5hH",
        "outputId": "97b89da2-be9e-4133-e6c5-c299c79ba0ec"
      },
      "source": [
        "len(train_df), len(train_df_augmented)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1023, 2037)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq8GBOwVR9rh"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC_bO5d2R-Mg"
      },
      "source": [
        "def set_seeds(seed=1234):\n",
        "    \"\"\"Set seed for reproducibility\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWFPwaXVSAR5"
      },
      "source": [
        "def get_data_splits(df, train_size=0.7):\n",
        "    X = df.text.to_numpy()\n",
        "    y = df.tags\n",
        "\n",
        "    # Binarize y\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(y)\n",
        "    y = label_encoder.encode(y)\n",
        "\n",
        "    # Split\n",
        "    X_train, X_, y_train, y_ = iterative_train_test_split(X, y, train_size=train_size)\n",
        "\n",
        "    X_val, X_test, y_val, y_test = iterative_train_test_split(X_, y_, train_size=0.5)\n",
        "\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test, label_encoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmzrTjz2SCfO"
      },
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, model, device, loss_fn=None, optimizer=None, scheduler=None):\n",
        "\n",
        "        # set params\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "    def train_step(self, dataloader):\n",
        "        \"\"\"Train step\"\"\"\n",
        "        self.model.train()\n",
        "        loss = 0.0\n",
        "\n",
        "        for i, batch in enumerate(dataloader):\n",
        "            batch = [item.to(self.device) for item in batch]\n",
        "            inputs, targets = batch[:-1], batch[-1]\n",
        "            self.optimizer.zero_grad()\n",
        "            z = self.model(inputs)\n",
        "            J = self.loss_fn(z, targets)\n",
        "            J.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            loss += (J.detach().item() - loss) / (i+1)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def eval_step(self, dataloader):\n",
        "        \"\"\"Validation step\"\"\"\n",
        "        self.model.eval()\n",
        "        loss = 0.0\n",
        "        y_trues, y_probs = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "                batch = [item.to(self.device) for item in batch]\n",
        "                inputs, y_true = batch[:-1], batch[-1]\n",
        "\n",
        "                z = self.model(inputs)\n",
        "                J = self.loss_fn(z, y_true).item()\n",
        "\n",
        "                loss += (J-loss) / (i+1)\n",
        "\n",
        "                y_prob = torch.sigmoid(z).cpu().numpy()\n",
        "                y_probs.extend(y_prob)\n",
        "                y_trues.extend(y_true.cpu().numpy())\n",
        "\n",
        "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
        "\n",
        "    def predict_step(self, dataloader):\n",
        "        \"\"\"prediction step\"\"\"\n",
        "        self.model.eval()\n",
        "        y_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "                inputs, targets = batch[:-1], batch[-1]\n",
        "                y_prob = self.model(inputs)\n",
        "\n",
        "                y_probs.extend(y_prob)\n",
        "\n",
        "            return np.vstack(y_probs)\n",
        "\n",
        "    def train(self, num_epochs, patience, train_dataloader, val_dataloader):\n",
        "        best_val_loss = np.inf\n",
        "        for epoch in range(num_epochs):\n",
        "            train_loss = self.train_step(dataloader=train_dataloader)\n",
        "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
        "\n",
        "            self.scheduler.step(val_loss)\n",
        "\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = self.model\n",
        "                _patience = patience\n",
        "\n",
        "            else:\n",
        "                _patience -= 1\n",
        "\n",
        "            if not _patience:\n",
        "                print(\"Stopping Early\")\n",
        "                break\n",
        "\n",
        "            print(\n",
        "                f\"Epoch: {epoch+1} | \"\n",
        "                f\"train_loss: {train_loss:.5f}, \"\n",
        "                f\"val_loss: {val_loss:.5f}, \"\n",
        "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
        "                f\"_patience: {_patience}\"\n",
        "            )\n",
        "            \n",
        "        return best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnzMMfaWSD3m"
      },
      "source": [
        "set_seeds()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxz8jPbHSFqA"
      },
      "source": [
        "preprocessed_df = df.copy()\n",
        "preprocessed_df.text = preprocessed_df.text.apply(preprocess, lower=True)\n",
        "X_train, X_val, X_test, y_train, y_val, y_test, label_encoder = get_data_splits(preprocessed_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxxUy24sSHVn",
        "outputId": "7322a04e-46f6-40d4-d550-e59658a93095"
      },
      "source": [
        "print(label_encoder)\n",
        "print(label_encoder.classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<LabelEncoder(num_classes=35)>\n",
            "['attention', 'autoencoders', 'computer-vision', 'convolutional-neural-networks', 'data-augmentation', 'embeddings', 'flask', 'generative-adversarial-networks', 'graph-neural-networks', 'graphs', 'huggingface', 'image-classification', 'interpretability', 'keras', 'language-modeling', 'natural-language-processing', 'node-classification', 'object-detection', 'pretraining', 'production', 'pytorch', 'question-answering', 'regression', 'reinforcement-learning', 'representation-learning', 'scikit-learn', 'segmentation', 'self-supervised-learning', 'tensorflow', 'tensorflow-js', 'time-series', 'transfer-learning', 'transformers', 'unsupervised-learning', 'wandb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oti2QsbASJNf"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuR1meq4SPLg"
      },
      "source": [
        "set_seeds()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuI44LAqSQiY"
      },
      "source": [
        "processed_df = df.copy()\n",
        "processed_df.text = processed_df.text.apply(preprocess, lower=True)\n",
        "X_train, X_val, X_test, y_train, y_val, y_test, label_encoder = get_data_splits(processed_df)\n",
        "X_test_raw = X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BKNDFj8SRyn"
      },
      "source": [
        "# Split DataFrames\n",
        "train_df = pd.DataFrame({\"text\": X_train, \"tags\": label_encoder.decode(y_train)})\n",
        "val_df = pd.DataFrame({\"text\": X_val, \"tags\": label_encoder.decode(y_val)})\n",
        "test_df = pd.DataFrame({\"text\": X_test, \"tags\": label_encoder.decode(y_test)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSfjD9n9STVI",
        "outputId": "b5785367-a50b-48a7-c153-4bfca794e1c4"
      },
      "source": [
        "# Set device\n",
        "cuda = True\n",
        "device = torch.device(\"cuda\" if (\n",
        "    torch.cuda.is_available() and cuda) else \"cpu\")\n",
        "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
        "if device.type == \"cuda\":\n",
        "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
        "print (device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E56yekzdSUk2"
      },
      "source": [
        "class Tokenizer(object):\n",
        "    def __init__(self, char_level, num_tokens=None, pad_token=\"<PAD\", \n",
        "                 oov_token=\"<UNK>\", token_to_index=None):\n",
        "        self.char_level = char_level\n",
        "        self.separator = '' if self.char_level else ' '\n",
        "        if num_tokens: num_tokens -= 2\n",
        "        self.num_tokens = num_tokens\n",
        "        self.pad_token = pad_token\n",
        "        self.oov_token = oov_token\n",
        "        if not token_to_index:\n",
        "            token_to_index = {pad_token: 0, oov_token: 1}\n",
        "        self.token_to_index = token_to_index\n",
        "        self.index_to_token = {v:k for k, v in self.token_to_index.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_to_index)\n",
        "    \n",
        "    def __str__(self):\n",
        "        return f\"<Tokenizer(num_tokens={len(self)})>\"\n",
        "\n",
        "    def fit_on_texts(self, texts):\n",
        "        if not self.char_level:\n",
        "            texts = [text.split(' ') for text in texts]\n",
        "        all_tokens = [token for text in texts for token in text]\n",
        "        counts = Counter(all_tokens).most_common(self.num_tokens)\n",
        "        self.min_token_freq = counts[-1][1]\n",
        "        for token, count in counts:\n",
        "            index = len(self)\n",
        "            self.token_to_index[token] = index\n",
        "            self.index_to_token[index] = token\n",
        "        return self\n",
        "\n",
        "    def texts_to_sequences(self, texts):\n",
        "        sequences = []\n",
        "        for text in texts:\n",
        "            if not self.char_level:\n",
        "                text = text.split(\" \")\n",
        "            sequence = []\n",
        "            for token in text:\n",
        "                sequence.append(self.token_to_index.get(\n",
        "                    token, self.token_to_index[self.oov_token]\n",
        "                ))\n",
        "            sequences.append(np.array(sequence))\n",
        "\n",
        "        return sequences\n",
        "\n",
        "    def sequences_to_texts(self, sequences):\n",
        "        texts = []\n",
        "        for sequence in sequences:\n",
        "            text =  []\n",
        "            for index in sequence:\n",
        "                text.append(self.index_to_token.get(\n",
        "                    index, self.oov_token\n",
        "                ))\n",
        "            texts.append(self.separator.join([token for token in text]))\n",
        "        return texts\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, 'w') as fp:\n",
        "            contents = {\n",
        "                \"char_level\": self.char_level,\n",
        "                \"oov_token\": self.oov_token,\n",
        "                \"token_to_index\": self.token_to_index\n",
        "            }\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, \"r\") as  fp:\n",
        "            kwargs = json.load(fp=fp)\n",
        "        return cls(**kwargs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rd69dt2MSWyX",
        "outputId": "be440302-05af-4b8a-ca52-bea4cb72a509"
      },
      "source": [
        "# tokenize\n",
        "char_level = True\n",
        "tokenizer = Tokenizer(char_level=char_level)\n",
        "tokenizer.fit_on_texts(texts=X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Tokenizer at 0x7fad0150ae90>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xYz6gqcSYaB",
        "outputId": "4040ced5-3973-42f0-b025-0a728ddc2089"
      },
      "source": [
        "vocab_size = len(tokenizer)\n",
        "\n",
        "print(tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Tokenizer(num_tokens=39)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLN1q2u1SaB5",
        "outputId": "6ebf85d8-fadf-4d6e-add1-414b9518473d"
      },
      "source": [
        "# Convert texts to sequences of indices\n",
        "X_train = np.array(tokenizer.texts_to_sequences(X_train))\n",
        "X_val = np.array(tokenizer.texts_to_sequences(X_val))\n",
        "X_test = np.array(tokenizer.texts_to_sequences(X_test))\n",
        "preprocessed_text = tokenizer.sequences_to_texts([X_train[0]])[0]\n",
        "print (\"Text to indices:\\n\"\n",
        "    f\"  (preprocessed)  {preprocessed_text}\\n\"\n",
        "    f\"  (tokenized)  {X_train[0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text to indices:\n",
            "  (preprocessed)  medacy medical text mining information extraction spacy\n",
            "  (tokenized)  [16  3 14  7 12 21  2 16  3 14  4 12  7 11  2  6  3 25  6  2 16  4  5  4\n",
            "  5 15  2  4  5 19 10  8 16  7  6  4 10  5  2  3 25  6  8  7 12  6  4 10\n",
            "  5  2  9 13  7 12 21]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxQWPDaRSxfS"
      },
      "source": [
        "all_tags = list(itertools.chain.from_iterable(df.tags.values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNBK9hnKSc3R",
        "outputId": "d570e59a-20b0-405d-b999-e4caae11bdca"
      },
      "source": [
        "# Class weights\n",
        "counts = np.bincount([label_encoder.class_to_index[class_] for class_ in all_tags])\n",
        "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
        "print (f\"class counts: {counts},\\nclass weights: {class_weights}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class counts: [120  41 388 106  41  75  34  73  51  78  64  51  55  93  51 424  33  69\n",
            "  30  51 258  32  49  59  57  60  48  40 213  40  34  46 196  39  39],\n",
            "class weights: {0: 0.008333333333333333, 1: 0.024390243902439025, 2: 0.002577319587628866, 3: 0.009433962264150943, 4: 0.024390243902439025, 5: 0.013333333333333334, 6: 0.029411764705882353, 7: 0.0136986301369863, 8: 0.0196078431372549, 9: 0.01282051282051282, 10: 0.015625, 11: 0.0196078431372549, 12: 0.01818181818181818, 13: 0.010752688172043012, 14: 0.0196078431372549, 15: 0.0023584905660377358, 16: 0.030303030303030304, 17: 0.014492753623188406, 18: 0.03333333333333333, 19: 0.0196078431372549, 20: 0.003875968992248062, 21: 0.03125, 22: 0.02040816326530612, 23: 0.01694915254237288, 24: 0.017543859649122806, 25: 0.016666666666666666, 26: 0.020833333333333332, 27: 0.025, 28: 0.004694835680751174, 29: 0.025, 30: 0.029411764705882353, 31: 0.021739130434782608, 32: 0.00510204081632653, 33: 0.02564102564102564, 34: 0.02564102564102564}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUcKDhf8Semf"
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCJ6HlMCS-ZJ"
      },
      "source": [
        "def pad_sequences(sequences, max_seq_len=0):\n",
        "    \"\"\"Pad sequences to max length in sequence.\"\"\"\n",
        "    max_seq_len = max(max_seq_len, max(len(sequence) for sequence in sequences))\n",
        "    padded_sequences = np.zeros((len(sequences), max_seq_len))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        padded_sequences[i][:len(sequence)] = sequence\n",
        "    return padded_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEbaQHpLS_9T"
      },
      "source": [
        "class CNNTextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, max_filter_size):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.max_filter_size = max_filter_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Dataset(N={len(self)})>\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X = self.X[index]\n",
        "        y = self.y[index]\n",
        "        return [X, y]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        batch = np.array(batch, dtype=object)\n",
        "        X = batch[:, 0]\n",
        "        y = np.stack(batch[:, 1], axis=0)\n",
        "\n",
        "        # pad inputs\n",
        "        X = pad_sequences(sequences=X, max_seq_len=self.max_filter_size)\n",
        "\n",
        "        X = torch.LongTensor(X.astype(np.int32))\n",
        "        y = torch.FloatTensor(y.astype(np.int32))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            dataset=self,\n",
        "            batch_size=batch_size,\n",
        "            collate_fn=self.collate_fn,\n",
        "            shuffle=shuffle,\n",
        "            drop_last=drop_last,\n",
        "            pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaq_g2TSTBka",
        "outputId": "f8cc6e57-65b4-462f-f4e1-bd337da661f7"
      },
      "source": [
        "# Create datasets\n",
        "filter_sizes = list(range(1, 11))\n",
        "train_dataset = CNNTextDataset(\n",
        "    X=X_train, y=y_train, max_filter_size=max(filter_sizes))\n",
        "val_dataset = CNNTextDataset(\n",
        "    X=X_val, y=y_val, max_filter_size=max(filter_sizes))\n",
        "test_dataset = CNNTextDataset(\n",
        "    X=X_test, y=y_test, max_filter_size=max(filter_sizes))\n",
        "print (\"Data splits:\\n\"\n",
        "    f\"  Train dataset:{train_dataset.__str__()}\\n\"\n",
        "    f\"  Val dataset: {val_dataset.__str__()}\\n\"\n",
        "    f\"  Test dataset: {test_dataset.__str__()}\\n\"\n",
        "    \"Sample point:\\n\"\n",
        "    f\"  X: {train_dataset[0][0]}\\n\"\n",
        "    f\"  y: {train_dataset[0][1]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data splits:\n",
            "  Train dataset:<Dataset(N=1023)>\n",
            "  Val dataset: <Dataset(N=205)>\n",
            "  Test dataset: <Dataset(N=216)>\n",
            "Sample point:\n",
            "  X: [16  3 14  7 12 21  2 16  3 14  4 12  7 11  2  6  3 25  6  2 16  4  5  4\n",
            "  5 15  2  4  5 19 10  8 16  7  6  4 10  5  2  3 25  6  8  7 12  6  4 10\n",
            "  5  2  9 13  7 12 21]\n",
            "  y: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E_9dvyYTDHC",
        "outputId": "d2620ebf-adab-4181-982a-ebc72cfb0587"
      },
      "source": [
        "# Create dataloaders\n",
        "batch_size = 64\n",
        "train_dataloader = train_dataset.create_dataloader(\n",
        "    batch_size=batch_size)\n",
        "val_dataloader = val_dataset.create_dataloader(\n",
        "    batch_size=batch_size)\n",
        "test_dataloader = test_dataset.create_dataloader(\n",
        "    batch_size=batch_size)\n",
        "batch_X, batch_y = next(iter(train_dataloader))\n",
        "print (\"Sample batch:\\n\"\n",
        "    f\"  X: {list(batch_X.size())}\\n\"\n",
        "    f\"  y: {list(batch_y.size())}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample batch:\n",
            "  X: [64, 185]\n",
            "  y: [64, 35]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCHFv8h8TE-R"
      },
      "source": [
        "embedding_dim = 128\n",
        "num_filters = 128\n",
        "hidden_dim = 128\n",
        "dropout_p = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGxoYRCeTG1p"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, vocab_size, num_filters, filter_sizes, \n",
        "                 hidden_dim, dropout_p, num_classes, padding_idx=0):\n",
        "        super(CNN, self).__init__()\n",
        "        self.embeddings = nn.Embedding(\n",
        "            embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
        "            padding_idx=padding_idx\n",
        "        )\n",
        "\n",
        "        self.filter_sizes = filter_sizes\n",
        "        self.conv = nn.ModuleList(\n",
        "            [nn.Conv1d(in_channels=embedding_dim,\n",
        "                       out_channels=num_filters,\n",
        "                       kernel_size=f) for f in filter_sizes])\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc1 = nn.Linear(num_filters*len(filter_sizes), hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, inputs, channel_first=False):\n",
        "        x_in, = inputs\n",
        "        x_in = self.embeddings(x_in)\n",
        "        if not channel_first:\n",
        "            x_in = x_in.transpose(1, 2) # (N, channels, seq_length)\n",
        "        z = []\n",
        "        max_seq_len = x_in.shape[2]\n",
        "        for i, f in enumerate(self.filter_sizes):\n",
        "            # SAME padding\n",
        "            padding_left = int(\n",
        "                (self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2)\n",
        "            padding_right = int(math.ceil(\n",
        "                (self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2))\n",
        "            \n",
        "            _z = self.conv[i](F.pad(x_in, (padding_left, padding_right)))\n",
        "\n",
        "            _z = F.max_pool1d(_z, _z.size(2)).squeeze(2)\n",
        "            z.append(_z)\n",
        "\n",
        "        # concat\n",
        "        z = torch.cat(z, 1)\n",
        "\n",
        "        # FC\n",
        "        z = self.fc1(z)\n",
        "        z = self.dropout(z)\n",
        "        z = self.fc2(z)\n",
        "\n",
        "        return z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDWrgYlxTIOR",
        "outputId": "7190451a-84fa-45fb-f3b0-a0a449fac7ac"
      },
      "source": [
        "model = CNN(\n",
        "    embedding_dim=embedding_dim, vocab_size=vocab_size,\n",
        "    num_filters=num_filters, filter_sizes=filter_sizes,\n",
        "    hidden_dim=hidden_dim, dropout_p=dropout_p,\n",
        "    num_classes=num_classes\n",
        ")\n",
        "model = model.to(device)\n",
        "print(model.named_parameters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Module.named_parameters of CNN(\n",
            "  (embeddings): Embedding(39, 128, padding_idx=0)\n",
            "  (conv): ModuleList(\n",
            "    (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
            "    (1): Conv1d(128, 128, kernel_size=(2,), stride=(1,))\n",
            "    (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
            "    (3): Conv1d(128, 128, kernel_size=(4,), stride=(1,))\n",
            "    (4): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
            "    (5): Conv1d(128, 128, kernel_size=(6,), stride=(1,))\n",
            "    (6): Conv1d(128, 128, kernel_size=(7,), stride=(1,))\n",
            "    (7): Conv1d(128, 128, kernel_size=(8,), stride=(1,))\n",
            "    (8): Conv1d(128, 128, kernel_size=(9,), stride=(1,))\n",
            "    (9): Conv1d(128, 128, kernel_size=(10,), stride=(1,))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=1280, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=35, bias=True)\n",
            ")>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vL80KyrTKDh"
      },
      "source": [
        "# Arguments\n",
        "lr = 2e-4\n",
        "num_epochs = 200\n",
        "patience = 10\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRl5txZ6TL65"
      },
      "source": [
        "# Define loss\n",
        "class_weights_tensor = torch.Tensor(np.array(list(class_weights.values())))\n",
        "loss_fn = nn.BCEWithLogitsLoss(weight=class_weights_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djJeD1q2TNR6"
      },
      "source": [
        "# Define optimizer & scheduler\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"min\", factor=0.1, patience=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrQVSjJbTOpR"
      },
      "source": [
        "# Trainer module\n",
        "trainer = Trainer(\n",
        "    model=model, device=device, loss_fn=loss_fn,\n",
        "    optimizer=optimizer, scheduler=scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq50gftBTRmp"
      },
      "source": [
        "from pathlib import Path\n",
        "from sklearn.metrics import precision_recall_curve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCWpxatzcue5"
      },
      "source": [
        "# Determining the best threshold\n",
        "def find_best_threshold(y_true, y_prob):\n",
        "    \"\"\"Find the best threshold for maximum F1.\"\"\"\n",
        "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_prob)\n",
        "    f1s = (2 * precisions * recalls) / (precisions + recalls)\n",
        "    return thresholds[np.argmax(f1s)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-WrgWJ3cvCq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvRKmWmLTVH_",
        "outputId": "a6375252-ddcc-40d0-9086-3d8c3d9a5239"
      },
      "source": [
        "!pip install mlflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.7/dist-packages (1.20.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (7.1.2)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.4.22)\n",
            "Requirement already satisfied: alembic<=1.4.1 in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.4.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from mlflow) (5.4.1)\n",
            "Requirement already satisfied: docker>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (5.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.1.5)\n",
            "Requirement already satisfied: protobuf>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (3.17.3)\n",
            "Requirement already satisfied: querystring-parser in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.2.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.3.0)\n",
            "Requirement already satisfied: gunicorn in /usr/local/lib/python3.7/dist-packages (from mlflow) (20.1.0)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.4.1)\n",
            "Requirement already satisfied: gitpython>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (3.1.18)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.3)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (4.6.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from mlflow) (2018.9)\n",
            "Requirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.7/dist-packages (from mlflow) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mlflow) (21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.19.5)\n",
            "Requirement already satisfied: prometheus-flask-exporter in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.18.2)\n",
            "Requirement already satisfied: databricks-cli>=0.8.7 in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.15.0)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.1.4)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic<=1.4.1->mlflow) (1.1.5)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.7/dist-packages (from alembic<=1.4.1->mlflow) (1.0.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic<=1.4.1->mlflow) (2.8.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (0.8.9)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (1.15.0)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from docker>=4.0.0->mlflow) (1.2.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow) (3.7.4.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow) (4.0.7)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow) (4.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata!=4.7.0,>=3.7.0->mlflow) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (1.24.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow) (1.1.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask->mlflow) (2.0.1)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn->mlflow) (57.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mlflow) (2.4.7)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow) (0.11.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeNfZJ_vTgEM"
      },
      "source": [
        "from argparse import Namespace\n",
        "import mlflow\n",
        "from pathlib import Path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PzUuyD0Tm0s",
        "outputId": "c3ddb16e-54c8-4183-8b12-e1a7831bf4ac"
      },
      "source": [
        "!pip install pyngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-5.1.0.tar.gz (745 kB)\n",
            "\u001b[?25l\r\u001b[K     |                               | 10 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |                               | 20 kB 17.2 MB/s eta 0:00:01\r\u001b[K     |                              | 30 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |                              | 40 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |                             | 51 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                             | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |                             | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |                            | 81 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |                            | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |                           | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                           | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                          | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                          | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                         | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                         | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                         | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                        | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                        | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                       | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                       | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                      | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                      | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                     | 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                     | 245 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                     | 256 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                    | 266 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                    | 276 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                   | 286 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                   | 296 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                  | 307 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                  | 317 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                  | 327 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                 | 337 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                 | 348 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                | 358 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                | 368 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |               | 378 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |               | 389 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |              | 399 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |              | 409 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |              | 419 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |             | 430 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |             | 440 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |            | 450 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |            | 460 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |           | 471 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |           | 481 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |           | 491 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |          | 501 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |          | 512 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |         | 522 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |         | 532 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |        | 542 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |        | 552 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |       | 563 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |       | 573 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |       | 583 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |      | 593 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |      | 604 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |     | 614 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |     | 624 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |    | 634 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |    | 645 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |   | 655 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |   | 665 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |   | 675 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |  | 686 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |  | 696 kB 5.0 MB/s eta 0:00:01\r\u001b[K     | | 706 kB 5.0 MB/s eta 0:00:01\r\u001b[K     | | 716 kB 5.0 MB/s eta 0:00:01\r\u001b[K     || 727 kB 5.0 MB/s eta 0:00:01\r\u001b[K     || 737 kB 5.0 MB/s eta 0:00:01\r\u001b[K     || 745 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (5.4.1)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.1.0-py3-none-any.whl size=19006 sha256=13b6fd010c16fdd893c1cbdb033116b0d07ab017282414878d6b293efbb7d4e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/e6/af/ccf6598ecefecd44104069371795cb9b3afbcd16987f6ccfb3\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-5.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXH9YpsVTrXR"
      },
      "source": [
        "# Specify arguments\n",
        "args = Namespace(\n",
        "    char_level=True,\n",
        "    filter_sizes=list(range(1, 11)),\n",
        "    batch_size=128,\n",
        "    embedding_dim=128, \n",
        "    num_filters=128,\n",
        "    hidden_dim=128, \n",
        "    dropout_p=0.5,\n",
        "    lr=2e-4,\n",
        "    num_epochs=200,\n",
        "    patience=10,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Rm-F0UlUMUQ"
      },
      "source": [
        "# Set tracking URI\n",
        "MODEL_REGISTRY = Path(\"experiments\")\n",
        "Path(MODEL_REGISTRY).mkdir(exist_ok=True) # create experiments dir\n",
        "mlflow.set_tracking_uri(\"file://\" + str(MODEL_REGISTRY.absolute()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBMahDmBUN7X",
        "outputId": "da50343e-4aeb-427c-f6e0-b8a8a64d41c2"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "experiments  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Nx8TZlCUP2x"
      },
      "source": [
        "# Trainer (modified for experiment tracking)\n",
        "class Trainer(object):\n",
        "    def __init__(self, model, device, loss_fn=None, \n",
        "                 optimizer=None, scheduler=None):\n",
        "\n",
        "        # Set params\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "    def train_step(self, dataloader):\n",
        "        \"\"\"Train step.\"\"\"\n",
        "        # Set model to train mode\n",
        "        self.model.train()\n",
        "        loss = 0.0\n",
        "\n",
        "        # Iterate over train batches\n",
        "        for i, batch in enumerate(dataloader):\n",
        "            # Step\n",
        "            batch = [item.to(self.device) for item in batch]\n",
        "            inputs, targets = batch[:-1], batch[-1]\n",
        "            self.optimizer.zero_grad()  # Reset gradients\n",
        "            z = self.model(inputs)  # Forward pass\n",
        "            J = self.loss_fn(z, targets)  # Define loss\n",
        "            J.backward()  # Backward pass\n",
        "            self.optimizer.step()  # Update weights\n",
        "\n",
        "            # Cumulative Metrics\n",
        "            loss += (J.detach().item() - loss) / (i + 1)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def eval_step(self, dataloader):\n",
        "        \"\"\"Validation or test step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        loss = 0.0\n",
        "        y_trues, y_probs = [], []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Step\n",
        "                batch = [item.to(self.device) for item in batch]  # Set device\n",
        "                inputs, y_true = batch[:-1], batch[-1]\n",
        "                z = self.model(inputs)  # Forward pass\n",
        "                J = self.loss_fn(z, y_true).item()\n",
        "\n",
        "                # Cumulative Metrics\n",
        "                loss += (J - loss) / (i + 1)\n",
        "\n",
        "                # Store outputs\n",
        "                y_prob = torch.sigmoid(z).cpu().numpy()\n",
        "                y_probs.extend(y_prob)\n",
        "                y_trues.extend(y_true.cpu().numpy())\n",
        "\n",
        "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
        "\n",
        "    def predict_step(self, dataloader):\n",
        "        \"\"\"Prediction step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        y_probs = []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Forward pass w/ inputs\n",
        "                inputs, targets = batch[:-1], batch[-1]\n",
        "                y_prob = self.model(inputs)\n",
        "\n",
        "                # Store outputs\n",
        "                y_probs.extend(y_prob)\n",
        "\n",
        "        return np.vstack(y_probs)\n",
        "    \n",
        "    def train(self, num_epochs, patience, train_dataloader, val_dataloader):\n",
        "        best_val_loss = np.inf\n",
        "        for epoch in range(num_epochs):\n",
        "            # Steps\n",
        "            train_loss = self.train_step(dataloader=train_dataloader)\n",
        "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
        "            self.scheduler.step(val_loss)\n",
        "\n",
        "            # Early stopping\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = self.model\n",
        "                _patience = patience  # reset _patience\n",
        "            else:\n",
        "                _patience -= 1\n",
        "            if not _patience:  # 0\n",
        "                print(\"Stopping early!\")\n",
        "                break\n",
        "\n",
        "            # Tracking\n",
        "            mlflow.log_metrics(\n",
        "                {\"train_loss\": train_loss, \"val_loss\": val_loss}, step=epoch\n",
        "            )\n",
        "\n",
        "            # Logging\n",
        "            print(\n",
        "                f\"Epoch: {epoch+1} | \"\n",
        "                f\"train_loss: {train_loss:.5f}, \"\n",
        "                f\"val_loss: {val_loss:.5f}, \"\n",
        "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
        "                f\"_patience: {_patience}\"\n",
        "            )\n",
        "\n",
        "        return best_model, best_val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VxY7nykURrn"
      },
      "source": [
        "def train_cnn(args, df):\n",
        "    \"\"\"Train a CNN using specific arguments.\"\"\"\n",
        "\n",
        "    # Set seeds\n",
        "    set_seeds()\n",
        "\n",
        "    # Get data splits\n",
        "    preprocessed_df = df.copy()\n",
        "    preprocessed_df.text = preprocessed_df.text.apply(preprocess, lower=True)\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test, label_encoder = get_data_splits(preprocessed_df)\n",
        "    num_classes = len(label_encoder)\n",
        "\n",
        "    # Set device\n",
        "    cuda = True\n",
        "    device = torch.device(\"cuda\" if (\n",
        "        torch.cuda.is_available() and cuda) else \"cpu\")\n",
        "    torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
        "    if device.type == \"cuda\":\n",
        "        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
        "\n",
        "    # Tokenize\n",
        "    tokenizer = Tokenizer(char_level=args.char_level)\n",
        "    tokenizer.fit_on_texts(texts=X_train)\n",
        "    vocab_size = len(tokenizer)\n",
        "\n",
        "    # Convert texts to sequences of indices\n",
        "    X_train = np.array(tokenizer.texts_to_sequences(X_train))\n",
        "    X_val = np.array(tokenizer.texts_to_sequences(X_val))\n",
        "    X_test = np.array(tokenizer.texts_to_sequences(X_test))\n",
        "\n",
        "    # Class weights\n",
        "    counts = np.bincount([label_encoder.class_to_index[class_] for class_ in all_tags])\n",
        "    class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = CNNTextDataset(\n",
        "        X=X_train, y=y_train, max_filter_size=max(args.filter_sizes))\n",
        "    val_dataset = CNNTextDataset(\n",
        "        X=X_val, y=y_val, max_filter_size=max(args.filter_sizes))\n",
        "    test_dataset = CNNTextDataset(\n",
        "        X=X_test, y=y_test, max_filter_size=max(args.filter_sizes))\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_dataloader = train_dataset.create_dataloader(\n",
        "        batch_size=args.batch_size)\n",
        "    val_dataloader = val_dataset.create_dataloader(\n",
        "        batch_size=args.batch_size)\n",
        "    test_dataloader = test_dataset.create_dataloader(\n",
        "        batch_size=args.batch_size)\n",
        "\n",
        "    # Initialize model\n",
        "    model = CNN(\n",
        "        embedding_dim=args.embedding_dim, vocab_size=vocab_size,\n",
        "        num_filters=args.num_filters, filter_sizes=args.filter_sizes,\n",
        "        hidden_dim=args.hidden_dim, dropout_p=args.dropout_p,\n",
        "        num_classes=num_classes)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Define loss\n",
        "    class_weights_tensor = torch.Tensor(np.array(list(class_weights.values())))\n",
        "    loss_fn = nn.BCEWithLogitsLoss(weight=class_weights_tensor)\n",
        "\n",
        "    # Define optimizer & scheduler\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode=\"min\", factor=0.1, patience=5)\n",
        "\n",
        "    # Trainer module\n",
        "    trainer = Trainer(\n",
        "        model=model, device=device, loss_fn=loss_fn, \n",
        "        optimizer=optimizer, scheduler=scheduler)\n",
        "\n",
        "    # Train\n",
        "    best_model, best_val_loss = trainer.train(\n",
        "        args.num_epochs, args.patience, train_dataloader, val_dataloader)\n",
        "\n",
        "    # Best threshold for f1\n",
        "    train_loss, y_true, y_prob = trainer.eval_step(dataloader=train_dataloader)\n",
        "    precisions, recalls, thresholds = precision_recall_curve(y_true.ravel(), y_prob.ravel())\n",
        "    threshold = find_best_threshold(y_true.ravel(), y_prob.ravel())\n",
        "\n",
        "    # Determine predictions using threshold\n",
        "    test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "    y_pred = np.array([np.where(prob >= threshold, 1, 0) for prob in y_prob])\n",
        "\n",
        "    # Evaluate (simple)\n",
        "    metrics = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
        "    performance = {\"precision\": metrics[0], \"recall\": metrics[1], \"f1\": metrics[2]}\n",
        "\n",
        "    return {\n",
        "        \"args\": args,\n",
        "        \"tokenizer\": tokenizer,\n",
        "        \"label_encoder\": label_encoder,\n",
        "        \"model\": best_model,\n",
        "        \"performance\": performance,\n",
        "        \"best_val_loss\": best_val_loss,\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-9ayD0BUTy_"
      },
      "source": [
        "import tempfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F3tD29fUoHi",
        "outputId": "ec0a21f6-9c07-4bb6-a8a2-f7ce0ab30e02"
      },
      "source": [
        "# Set experiment\n",
        "mlflow.set_experiment(experiment_name=\"baselines\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: 'baselines' does not exist. Creating a new experiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIugXNiKUqC3"
      },
      "source": [
        "def save_dict(d, filepath):\n",
        "    \"\"\"Save dict to a json file.\"\"\"\n",
        "    with open(filepath, \"w\") as fp:\n",
        "        json.dump(d, indent=2, sort_keys=False, fp=fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGHbg-4cUsJA",
        "outputId": "31ee4bf4-e906-4eb6-a640-b239775328bf"
      },
      "source": [
        "# Tracking\n",
        "with mlflow.start_run(run_name=\"cnn\") as run:\n",
        "\n",
        "    # Train & evaluate\n",
        "    artifacts = train_cnn(args=args, df=df)    \n",
        "    \n",
        "    # Log key metrics\n",
        "    mlflow.log_metrics({\"precision\": artifacts[\"performance\"][\"precision\"]})\n",
        "    mlflow.log_metrics({\"recall\": artifacts[\"performance\"][\"recall\"]})\n",
        "    mlflow.log_metrics({\"f1\": artifacts[\"performance\"][\"f1\"]})\n",
        "\n",
        "    # Log artifacts\n",
        "    with tempfile.TemporaryDirectory() as dp:\n",
        "        artifacts[\"tokenizer\"].save(Path(dp, \"tokenizer.json\"))\n",
        "        artifacts[\"label_encoder\"].save(Path(dp, \"label_encoder.json\"))\n",
        "        torch.save(artifacts[\"model\"].state_dict(), Path(dp, \"model.pt\"))\n",
        "        save_dict(artifacts[\"performance\"], Path(dp, \"performance.json\"))\n",
        "        mlflow.log_artifacts(dp)\n",
        "\n",
        "    # Log parameters\n",
        "    mlflow.log_params(vars(artifacts[\"args\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00680, val_loss: 0.00303, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00393, val_loss: 0.00327, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 3 | train_loss: 0.00403, val_loss: 0.00329, lr: 2.00E-04, _patience: 8\n",
            "Epoch: 4 | train_loss: 0.00373, val_loss: 0.00299, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00348, val_loss: 0.00283, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00332, val_loss: 0.00280, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00322, val_loss: 0.00277, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00318, val_loss: 0.00276, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00306, val_loss: 0.00272, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00298, val_loss: 0.00268, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00290, val_loss: 0.00265, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00282, val_loss: 0.00262, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00277, val_loss: 0.00257, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00268, val_loss: 0.00252, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00263, val_loss: 0.00248, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00255, val_loss: 0.00243, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00250, val_loss: 0.00238, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00242, val_loss: 0.00233, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00234, val_loss: 0.00228, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00227, val_loss: 0.00224, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00220, val_loss: 0.00219, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00213, val_loss: 0.00216, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00206, val_loss: 0.00210, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00200, val_loss: 0.00208, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00196, val_loss: 0.00204, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00189, val_loss: 0.00200, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00182, val_loss: 0.00200, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00176, val_loss: 0.00194, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00175, val_loss: 0.00193, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00171, val_loss: 0.00192, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00166, val_loss: 0.00187, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 32 | train_loss: 0.00161, val_loss: 0.00187, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 33 | train_loss: 0.00157, val_loss: 0.00182, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 34 | train_loss: 0.00155, val_loss: 0.00183, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 35 | train_loss: 0.00148, val_loss: 0.00178, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 36 | train_loss: 0.00144, val_loss: 0.00179, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 37 | train_loss: 0.00144, val_loss: 0.00181, lr: 2.00E-04, _patience: 8\n",
            "Epoch: 38 | train_loss: 0.00142, val_loss: 0.00174, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 39 | train_loss: 0.00136, val_loss: 0.00176, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 40 | train_loss: 0.00130, val_loss: 0.00176, lr: 2.00E-04, _patience: 8\n",
            "Epoch: 41 | train_loss: 0.00129, val_loss: 0.00172, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 42 | train_loss: 0.00126, val_loss: 0.00172, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 43 | train_loss: 0.00122, val_loss: 0.00173, lr: 2.00E-04, _patience: 8\n",
            "Epoch: 44 | train_loss: 0.00119, val_loss: 0.00172, lr: 2.00E-04, _patience: 7\n",
            "Epoch: 45 | train_loss: 0.00115, val_loss: 0.00170, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 46 | train_loss: 0.00114, val_loss: 0.00168, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 47 | train_loss: 0.00113, val_loss: 0.00168, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 48 | train_loss: 0.00109, val_loss: 0.00169, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 49 | train_loss: 0.00106, val_loss: 0.00167, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 50 | train_loss: 0.00102, val_loss: 0.00167, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 51 | train_loss: 0.00100, val_loss: 0.00166, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 52 | train_loss: 0.00097, val_loss: 0.00167, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 53 | train_loss: 0.00096, val_loss: 0.00164, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 54 | train_loss: 0.00093, val_loss: 0.00169, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 55 | train_loss: 0.00090, val_loss: 0.00171, lr: 2.00E-04, _patience: 8\n",
            "Epoch: 56 | train_loss: 0.00088, val_loss: 0.00172, lr: 2.00E-04, _patience: 7\n",
            "Epoch: 57 | train_loss: 0.00089, val_loss: 0.00167, lr: 2.00E-04, _patience: 6\n",
            "Epoch: 58 | train_loss: 0.00085, val_loss: 0.00165, lr: 2.00E-04, _patience: 5\n",
            "Epoch: 59 | train_loss: 0.00083, val_loss: 0.00167, lr: 2.00E-05, _patience: 4\n",
            "Epoch: 60 | train_loss: 0.00080, val_loss: 0.00166, lr: 2.00E-05, _patience: 3\n",
            "Epoch: 61 | train_loss: 0.00081, val_loss: 0.00164, lr: 2.00E-05, _patience: 2\n",
            "Epoch: 62 | train_loss: 0.00079, val_loss: 0.00164, lr: 2.00E-05, _patience: 10\n",
            "Epoch: 63 | train_loss: 0.00078, val_loss: 0.00163, lr: 2.00E-05, _patience: 10\n",
            "Epoch: 64 | train_loss: 0.00076, val_loss: 0.00163, lr: 2.00E-05, _patience: 9\n",
            "Epoch: 65 | train_loss: 0.00076, val_loss: 0.00165, lr: 2.00E-05, _patience: 8\n",
            "Epoch: 66 | train_loss: 0.00079, val_loss: 0.00164, lr: 2.00E-05, _patience: 7\n",
            "Epoch: 67 | train_loss: 0.00079, val_loss: 0.00163, lr: 2.00E-05, _patience: 6\n",
            "Epoch: 68 | train_loss: 0.00077, val_loss: 0.00163, lr: 2.00E-05, _patience: 5\n",
            "Epoch: 69 | train_loss: 0.00075, val_loss: 0.00165, lr: 2.00E-06, _patience: 4\n",
            "Epoch: 70 | train_loss: 0.00078, val_loss: 0.00165, lr: 2.00E-06, _patience: 3\n",
            "Epoch: 71 | train_loss: 0.00075, val_loss: 0.00165, lr: 2.00E-06, _patience: 2\n",
            "Epoch: 72 | train_loss: 0.00077, val_loss: 0.00164, lr: 2.00E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qt660yfWSJh"
      },
      "source": [
        "from pyngrok import ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vhsd7elRcTuC",
        "outputId": "a71b5e07-7574-475c-dfcf-d084f2ada796"
      },
      "source": [
        "# https://stackoverflow.com/questions/61615818/setting-up-mlflow-on-google-colab\n",
        "get_ipython().system_raw(\"mlflow server -h 0.0.0.0 -p 5000 --backend-store-uri $PWD/experiments/ &\")\n",
        "ngrok.kill()\n",
        "ngrok.set_auth_token(\"\")\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLflow Tracking UI: https://c69d-34-133-105-254.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHYAxTxjj8b9"
      },
      "source": [
        "def load_dict(filepath):\n",
        "    \"\"\"Load a dict from a json file.\"\"\"\n",
        "    with open(filepath, \"r\") as fp:\n",
        "        d = json.load(fp)\n",
        "    return d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiBq87q6pO-7",
        "outputId": "cc97829e-8ad6-477b-9c5f-03f1284dc733"
      },
      "source": [
        "# Load all runs from experiment\n",
        "experiment_id = mlflow.get_experiment_by_name(\"baselines\").experiment_id\n",
        "all_runs = mlflow.search_runs(experiment_ids=experiment_id, order_by=[\"metrics.best_val_loss ASC\"])\n",
        "print (all_runs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                             run_id  ... tags.mlflow.runName\n",
            "0  1fe720a77cb14964b10c83bb0fdc5498  ...                 cnn\n",
            "1  f5353ce0c8ff405d88e0159a9b92a6f4  ...                 cnn\n",
            "\n",
            "[2 rows x 25 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkwLQtAqpTab"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "best_run_id = all_runs.iloc[0].run_id\n",
        "best_run = mlflow.get_run(run_id=best_run_id)\n",
        "client = mlflow.tracking.MlflowClient()\n",
        "\n",
        "with tempfile.TemporaryDirectory() as dp:\n",
        "    client.download_artifacts(run_id=best_run_id, path=\"\", dst_path=dp)\n",
        "    tokenizer = Tokenizer.load(fp=Path(dp, \"tokenizer.json\"))\n",
        "    label_encoder = LabelEncoder.load(fp=Path(dp, \"label_encoder.json\"))\n",
        "    model_state = torch.load(Path(dp, \"model.pt\"), map_location=device)\n",
        "    performance = load_dict(filepath=Path(dp, \"performance.json\"))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_JwCEW3MD4o",
        "outputId": "9ed8d207-bfb2-4086-cac7-1f2115c5bb6a"
      },
      "source": [
        "print (json.dumps(performance, indent=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"precision\": 0.7454592687466495,\n",
            "  \"recall\": 0.5875831485587583,\n",
            "  \"f1\": 0.6362426249188632\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTix_52VM63S",
        "outputId": "24af8068-ff3a-4c16-d77e-b70158ef9d62"
      },
      "source": [
        "# load artifacts\n",
        "device = torch.device(\"cpu\")\n",
        "model = CNN(\n",
        "    embedding_dim=args.embedding_dim, vocab_size=len(tokenizer),\n",
        "    num_filters=args.num_filters, filter_sizes=args.filter_sizes,\n",
        "    hidden_dim=args.hidden_dim, dropout_p=args.dropout_p,\n",
        "    num_classes=len(label_encoder)\n",
        ")\n",
        "model.load_state_dict(model_state)\n",
        "model.to(device)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (embeddings): Embedding(39, 128, padding_idx=0)\n",
              "  (conv): ModuleList(\n",
              "    (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
              "    (1): Conv1d(128, 128, kernel_size=(2,), stride=(1,))\n",
              "    (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
              "    (3): Conv1d(128, 128, kernel_size=(4,), stride=(1,))\n",
              "    (4): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
              "    (5): Conv1d(128, 128, kernel_size=(6,), stride=(1,))\n",
              "    (6): Conv1d(128, 128, kernel_size=(7,), stride=(1,))\n",
              "    (7): Conv1d(128, 128, kernel_size=(8,), stride=(1,))\n",
              "    (8): Conv1d(128, 128, kernel_size=(9,), stride=(1,))\n",
              "    (9): Conv1d(128, 128, kernel_size=(10,), stride=(1,))\n",
              "  )\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc1): Linear(in_features=1280, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=35, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p31jcfvgNnyF"
      },
      "source": [
        "trainer = Trainer(model=model, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNYmYvmmNyFT"
      },
      "source": [
        "# Dataloader\n",
        "text = \"Transfer learning with BERT for self-supervised learning\"\n",
        "X = np.array(tokenizer.texts_to_sequences([preprocess(text)]))\n",
        "y_filler = label_encoder.encode([np.array([label_encoder.classes[0]]*len(X))])\n",
        "dataset = CNNTextDataset(\n",
        "    X=X, y=y_filler, max_filter_size=max(filter_sizes))\n",
        "dataloader = dataset.create_dataloader(\n",
        "    batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCnwMGvSOA85"
      },
      "source": [
        "# manual threshold\n",
        "threshold = 0.29"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZIGwkT5N6VL",
        "outputId": "786ff76f-7853-48a4-fe74-9c44742b9dc3"
      },
      "source": [
        "# Inference\n",
        "y_prob = trainer.predict_step(dataloader)\n",
        "y_pred = np.array([np.where(prob >= threshold, 1, 0) for prob in y_prob])\n",
        "label_encoder.decode(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['natural-language-processing',\n",
              "  'self-supervised-learning',\n",
              "  'transfer-learning',\n",
              "  'transformers']]"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyVX0zqzN9wM"
      },
      "source": [
        "## Optimzation with Optuna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqia8WV_7qKe",
        "outputId": "283d8f69-1831-4599-c1a6-781ee9aad20d"
      },
      "source": [
        "!pip install optuna==2.4.0 numpyencoder==0.3.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna==2.4.0\n",
            "  Downloading optuna-2.4.0-py3-none-any.whl (282 kB)\n",
            "\u001b[K     || 282 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting numpyencoder==0.3.0\n",
            "  Downloading numpyencoder-0.3.0-py3-none-any.whl (3.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna==2.4.0) (1.19.5)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna==2.4.0) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna==2.4.0) (4.62.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna==2.4.0) (1.4.22)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.9.0-py3-none-any.whl (80 kB)\n",
            "\u001b[K     || 80 kB 12.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna==2.4.0) (21.0)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna==2.4.0) (1.4.1)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.4.1-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from optuna==2.4.0) (1.0.1)\n",
            "Collecting cmaes>=0.6.0\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna==2.4.0) (2.4.7)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna==2.4.0) (4.6.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna==2.4.0) (1.1.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna==2.4.0) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna==2.4.0) (2.8.2)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.7/dist-packages (from alembic->optuna==2.4.0) (1.0.4)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.6.0-py2.py3-none-any.whl (111 kB)\n",
            "\u001b[K     || 111 kB 72.2 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.1.2-py3-none-any.whl (141 kB)\n",
            "\u001b[K     || 141 kB 60.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.4.0) (2.1.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.4.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     || 49 kB 8.1 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.4.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.4.0) (5.4.1)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.4.0) (21.2.0)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.4.0) (3.7.4.3)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.4.0) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna==2.4.0) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna==2.4.0) (2.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna==2.4.0) (1.15.0)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=4f48effede8506b9263b26de297ff5a0c98150cb13c721fde750d5662e4e7ca8\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, colorama, stevedore, cmd2, autopage, colorlog, cmaes, cliff, optuna, numpyencoder\n",
            "Successfully installed autopage-0.4.0 cliff-3.9.0 cmaes-0.8.2 cmd2-2.1.2 colorama-0.4.4 colorlog-6.4.1 numpyencoder-0.3.0 optuna-2.4.0 pbr-5.6.0 pyperclip-1.8.2 stevedore-3.4.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x88Fmch47r9k"
      },
      "source": [
        "import optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttxz0QUZ7viV"
      },
      "source": [
        "from argparse import Namespace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBQcJKK67ztb"
      },
      "source": [
        "# arguments\n",
        "args = Namespace(\n",
        "    char_level=True,\n",
        "    filter_sizes=list(range(1,11)),\n",
        "    batch_size=64,\n",
        "    embedding_dim=128,\n",
        "    num_filters=128,\n",
        "    hidden_dim=128,\n",
        "    dropout_p=0.5,\n",
        "    lr=2e-4,\n",
        "    num_epochs=100,\n",
        "    patience=10\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQQHvw-Y8K-9"
      },
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, model, device, loss_fn=None, optimizer=None, \n",
        "                 scheduler=None, trial=None):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.trial = trial\n",
        "\n",
        "    def train_step(self, dataloader):\n",
        "        self.model.train()\n",
        "        loss = 0.0\n",
        "\n",
        "        for i, batch in enumerate(dataloader):\n",
        "            batch = [item.to(self.device) for item in batch]\n",
        "            inputs, targets = batch[:-1], batch[-1]\n",
        "            self.optimizer.zero_grad()\n",
        "            z = self.model(inputs)\n",
        "            J = self.loss_fn(z, targets)\n",
        "            J.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            loss += (J.detach().item() - loss) / (i+1)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def eval_step(self, dataloader):\n",
        "        self.model.eval()\n",
        "        loss = 0.0\n",
        "        y_trues, y_probs = [], []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Step\n",
        "                batch = [item.to(self.device) for item in batch]  # Set device\n",
        "                inputs, y_true = batch[:-1], batch[-1]\n",
        "                z = self.model(inputs)  # Forward pass\n",
        "                J = self.loss_fn(z, y_true).item()\n",
        "\n",
        "                # Cumulative Metrics\n",
        "                loss += (J - loss) / (i + 1)\n",
        "\n",
        "                # Store outputs\n",
        "                y_prob = torch.sigmoid(z).cpu().numpy()\n",
        "                y_probs.extend(y_prob)\n",
        "                y_trues.extend(y_true.cpu().numpy())\n",
        "\n",
        "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
        "\n",
        "    def predict_step(self, dataloader):\n",
        "        \"\"\"Prediction step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        y_probs = []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Forward pass w/ inputs\n",
        "                inputs, targets = batch[:-1], batch[-1]\n",
        "                z = self.model(inputs)\n",
        "\n",
        "                # Store outputs\n",
        "                y_prob = torch.sigmoid(z).cpu().numpy()\n",
        "                y_probs.extend(y_prob)\n",
        "\n",
        "        return np.vstack(y_probs)\n",
        "\n",
        "    def train(self, num_epochs, patience, train_dataloader, val_dataloader, \n",
        "              tolerance=1e-5):\n",
        "        best_val_loss = np.inf\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            train_loss = self.train_step(dataloader=train_dataloader)\n",
        "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
        "            self.scheduler.step(val_loss)\n",
        "\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = self.model\n",
        "                _patience = patience\n",
        "            else:\n",
        "                _patience -= 1\n",
        "\n",
        "            if not _patience:\n",
        "                print(\"Stopping Early!\")\n",
        "                break\n",
        "\n",
        "            print(\n",
        "                f\"Epoch: {epoch+1} | \"\n",
        "                f\"train_loss: {train_loss:.5f}, \"\n",
        "                f\"val_loss: {val_loss:.5f}, \"\n",
        "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
        "                f\"_patience: {_patience}\"\n",
        "            )\n",
        "\n",
        "            # Pruning based on intermediate value\n",
        "            self.trial.report(val_loss, epoch)\n",
        "            if self.trial.should_prune():\n",
        "                raise optuna.TrialPruned()\n",
        "\n",
        "        return best_model, best_val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcI3MxwQ-1Q2"
      },
      "source": [
        "def train_cnn(args, df, trial=None):\n",
        "    set_seeds()\n",
        "\n",
        "    preprocessed_df = df.copy()\n",
        "    preprocessed_df.text = preprocessed_df.text.apply(preprocess, lower=True)\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test, label_encoder = get_data_splits(preprocessed_df)\n",
        "    num_classes = len(label_encoder)\n",
        "\n",
        "    cuda = True\n",
        "    device = torch.device(\"cuda\" if (\n",
        "        torch.cuda.is_available() and cuda) else \"cpu\")\n",
        "    torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
        "    if device.type == \"cuda\":\n",
        "        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
        "\n",
        "     # Tokenize\n",
        "    tokenizer = Tokenizer(char_level=args.char_level)\n",
        "    tokenizer.fit_on_texts(texts=X_train)\n",
        "    vocab_size = len(tokenizer)\n",
        "\n",
        "    # Convert texts to sequences of indices\n",
        "    X_train = np.array(tokenizer.texts_to_sequences(X_train))\n",
        "    X_val = np.array(tokenizer.texts_to_sequences(X_val))\n",
        "    X_test = np.array(tokenizer.texts_to_sequences(X_test))\n",
        "\n",
        "    # Class weights\n",
        "    train_tags = list(itertools.chain.from_iterable(train_df.tags.values))\n",
        "    counts = np.bincount([label_encoder.class_to_index[class_] for class_ in train_tags])\n",
        "    class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = CNNTextDataset(\n",
        "        X=X_train, y=y_train, max_filter_size=max(args.filter_sizes))\n",
        "    val_dataset = CNNTextDataset(\n",
        "        X=X_val, y=y_val, max_filter_size=max(args.filter_sizes))\n",
        "    test_dataset = CNNTextDataset(\n",
        "        X=X_test, y=y_test, max_filter_size=max(args.filter_sizes))\n",
        "    \n",
        "    # Create dataloaders\n",
        "    train_dataloader = train_dataset.create_dataloader(\n",
        "        batch_size=args.batch_size)\n",
        "    val_dataloader = val_dataset.create_dataloader(\n",
        "        batch_size=args.batch_size)\n",
        "    test_dataloader = test_dataset.create_dataloader(\n",
        "        batch_size=args.batch_size)\n",
        "\n",
        "    # Initialize model\n",
        "    model = CNN(\n",
        "        embedding_dim=args.embedding_dim, vocab_size=vocab_size,\n",
        "        num_filters=args.num_filters, filter_sizes=args.filter_sizes,\n",
        "        hidden_dim=args.hidden_dim, dropout_p=args.dropout_p,\n",
        "        num_classes=num_classes)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Define loss\n",
        "    class_weights_tensor = torch.Tensor(np.array(list(class_weights.values())))\n",
        "    loss_fn = nn.BCEWithLogitsLoss(weight=class_weights_tensor)\n",
        "\n",
        "    # Define optimizer & scheduler\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.1, patience=5)\n",
        "    \n",
        "    # Trainer module\n",
        "    trainer = Trainer(\n",
        "        model=model, device=device, loss_fn=loss_fn, \n",
        "        optimizer=optimizer, scheduler=scheduler, trial=trial)\n",
        "    \n",
        "    # Train\n",
        "    best_model, best_val_loss = trainer.train(\n",
        "        args.num_epochs, args.patience, train_dataloader, val_dataloader)\n",
        "    \n",
        "    # Best threshold for f1\n",
        "    train_loss, y_true, y_prob = trainer.eval_step(dataloader=train_dataloader)\n",
        "    precisions, recalls, thresholds = precision_recall_curve(y_true.ravel(), y_prob.ravel())\n",
        "    threshold = find_best_threshold(y_true.ravel(), y_prob.ravel())\n",
        "\n",
        "    # Determine predictions using threshold\n",
        "    test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "    y_pred = np.array([np.where(prob >= threshold, 1, 0) for prob in y_prob])\n",
        "\n",
        "    # Evaluate (simple)\n",
        "    metrics = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
        "    performance = {\"precision\": metrics[0], \"recall\": metrics[1], \"f1\": metrics[2]}\n",
        "\n",
        "    return {\n",
        "        \"args\": args,\n",
        "        \"tokenizer\": tokenizer,\n",
        "        \"label_encoder\": label_encoder,\n",
        "        \"model\": best_model,\n",
        "        \"performance\": performance,\n",
        "        \"best_val_loss\": best_val_loss,\n",
        "        \"threshold\": threshold,\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCnulDUwAkWg"
      },
      "source": [
        "def objective(trial, args):\n",
        "    \"\"\" Consume a trial and set of arguments and produce the metric to optimize\"\"\"\n",
        "\n",
        "    # params to tune\n",
        "    args.embedding_dim = trial.suggest_int(\"embedding_dim\", 128, 512)\n",
        "    args.num_filters = trial.suggest_int(\"num_filters\", 128, 512)\n",
        "    args.hidden_dim = trial.suggest_int(\"hidden_dim\", 128, 512)\n",
        "    args.dropout_p = trial.suggest_uniform(\"dropout_p\", 0.3, 0.8)\n",
        "    args.lr = trial.suggest_loguniform(\"lr\", 5e-5, 5e-4)\n",
        "\n",
        "    # train and evaluate\n",
        "    artifacts = train_cnn(args=args, df=df, trial=trial)\n",
        "\n",
        "    # additional attributes\n",
        "    trial.set_user_attr(\"precision\", artifacts[\"performance\"][\"precision\"])\n",
        "    trial.set_user_attr(\"recall\", artifacts[\"performance\"][\"recall\"])\n",
        "    trial.set_user_attr(\"f1\", artifacts[\"performance\"][\"f1\"])\n",
        "    trial.set_user_attr(\"threshold\", artifacts[\"threshold\"])\n",
        "\n",
        "    return artifacts[\"performance\"][\"f1\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z35ervIBB6F9"
      },
      "source": [
        "from numpyencoder import NumpyEncoder\n",
        "from optuna.integration.mlflow import MLflowCallback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQY6wcwYCS5f"
      },
      "source": [
        "NUM_TRIALS = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQep5g1WCsMs",
        "outputId": "4cc6cd6f-5e70-438e-9710-54b62a8023a0"
      },
      "source": [
        "# optimize\n",
        "pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5)\n",
        "study = optuna.create_study(study_name=\"optimization_1\", direction=\"maximize\", pruner=pruner)\n",
        "mlflow_callback = MLflowCallback(\n",
        "    tracking_uri=mlflow.get_tracking_uri(), metric_name=\"f1\"\n",
        ")\n",
        "study.optimize(\n",
        "    lambda trial: objective(trial, args),\n",
        "    n_trials=NUM_TRIALS,\n",
        "    callbacks=[mlflow_callback]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:17:28,571]\u001b[0m A new study created in memory with name: optimization_1\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00891, val_loss: 0.00436, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00507, val_loss: 0.00456, lr: 7.24E-05, _patience: 9\n",
            "Epoch: 3 | train_loss: 0.00494, val_loss: 0.00430, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00463, val_loss: 0.00414, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00449, val_loss: 0.00408, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00438, val_loss: 0.00405, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00427, val_loss: 0.00400, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00415, val_loss: 0.00394, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00405, val_loss: 0.00387, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00393, val_loss: 0.00381, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00385, val_loss: 0.00375, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00374, val_loss: 0.00367, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00363, val_loss: 0.00359, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00356, val_loss: 0.00352, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00349, val_loss: 0.00345, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00334, val_loss: 0.00336, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00328, val_loss: 0.00328, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00317, val_loss: 0.00320, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00305, val_loss: 0.00313, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00300, val_loss: 0.00307, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00285, val_loss: 0.00299, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00279, val_loss: 0.00293, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00267, val_loss: 0.00288, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00265, val_loss: 0.00281, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00255, val_loss: 0.00277, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00248, val_loss: 0.00271, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00243, val_loss: 0.00266, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00236, val_loss: 0.00265, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00235, val_loss: 0.00257, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00219, val_loss: 0.00256, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00221, val_loss: 0.00253, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 32 | train_loss: 0.00210, val_loss: 0.00254, lr: 7.24E-05, _patience: 9\n",
            "Epoch: 33 | train_loss: 0.00201, val_loss: 0.00245, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 34 | train_loss: 0.00200, val_loss: 0.00242, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 35 | train_loss: 0.00195, val_loss: 0.00241, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 36 | train_loss: 0.00191, val_loss: 0.00240, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 37 | train_loss: 0.00180, val_loss: 0.00237, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 38 | train_loss: 0.00178, val_loss: 0.00235, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 39 | train_loss: 0.00172, val_loss: 0.00235, lr: 7.24E-05, _patience: 9\n",
            "Epoch: 40 | train_loss: 0.00169, val_loss: 0.00235, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 41 | train_loss: 0.00167, val_loss: 0.00231, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 42 | train_loss: 0.00167, val_loss: 0.00230, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 43 | train_loss: 0.00164, val_loss: 0.00227, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 44 | train_loss: 0.00155, val_loss: 0.00226, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 45 | train_loss: 0.00153, val_loss: 0.00225, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 46 | train_loss: 0.00151, val_loss: 0.00223, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 47 | train_loss: 0.00145, val_loss: 0.00223, lr: 7.24E-05, _patience: 9\n",
            "Epoch: 48 | train_loss: 0.00142, val_loss: 0.00222, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 49 | train_loss: 0.00136, val_loss: 0.00224, lr: 7.24E-05, _patience: 9\n",
            "Epoch: 50 | train_loss: 0.00134, val_loss: 0.00222, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 51 | train_loss: 0.00131, val_loss: 0.00219, lr: 7.24E-05, _patience: 10\n",
            "Epoch: 52 | train_loss: 0.00128, val_loss: 0.00220, lr: 7.24E-05, _patience: 9\n",
            "Epoch: 53 | train_loss: 0.00123, val_loss: 0.00220, lr: 7.24E-05, _patience: 8\n",
            "Epoch: 54 | train_loss: 0.00121, val_loss: 0.00223, lr: 7.24E-05, _patience: 7\n",
            "Epoch: 55 | train_loss: 0.00116, val_loss: 0.00220, lr: 7.24E-05, _patience: 6\n",
            "Epoch: 56 | train_loss: 0.00116, val_loss: 0.00221, lr: 7.24E-05, _patience: 5\n",
            "Epoch: 57 | train_loss: 0.00111, val_loss: 0.00220, lr: 7.24E-06, _patience: 4\n",
            "Epoch: 58 | train_loss: 0.00109, val_loss: 0.00219, lr: 7.24E-06, _patience: 3\n",
            "Epoch: 59 | train_loss: 0.00107, val_loss: 0.00219, lr: 7.24E-06, _patience: 2\n",
            "Epoch: 60 | train_loss: 0.00108, val_loss: 0.00216, lr: 7.24E-06, _patience: 10\n",
            "Epoch: 61 | train_loss: 0.00107, val_loss: 0.00217, lr: 7.24E-06, _patience: 9\n",
            "Epoch: 62 | train_loss: 0.00103, val_loss: 0.00217, lr: 7.24E-06, _patience: 8\n",
            "Epoch: 63 | train_loss: 0.00106, val_loss: 0.00216, lr: 7.24E-06, _patience: 7\n",
            "Epoch: 64 | train_loss: 0.00105, val_loss: 0.00218, lr: 7.24E-06, _patience: 6\n",
            "Epoch: 65 | train_loss: 0.00102, val_loss: 0.00215, lr: 7.24E-06, _patience: 10\n",
            "Epoch: 66 | train_loss: 0.00105, val_loss: 0.00218, lr: 7.24E-06, _patience: 9\n",
            "Epoch: 67 | train_loss: 0.00106, val_loss: 0.00216, lr: 7.24E-06, _patience: 8\n",
            "Epoch: 68 | train_loss: 0.00104, val_loss: 0.00215, lr: 7.24E-06, _patience: 10\n",
            "Epoch: 69 | train_loss: 0.00104, val_loss: 0.00218, lr: 7.24E-06, _patience: 9\n",
            "Epoch: 70 | train_loss: 0.00104, val_loss: 0.00217, lr: 7.24E-06, _patience: 8\n",
            "Epoch: 71 | train_loss: 0.00102, val_loss: 0.00216, lr: 7.24E-06, _patience: 7\n",
            "Epoch: 72 | train_loss: 0.00101, val_loss: 0.00218, lr: 7.24E-06, _patience: 6\n",
            "Epoch: 73 | train_loss: 0.00100, val_loss: 0.00217, lr: 7.24E-06, _patience: 5\n",
            "Epoch: 74 | train_loss: 0.00102, val_loss: 0.00217, lr: 7.24E-07, _patience: 4\n",
            "Epoch: 75 | train_loss: 0.00101, val_loss: 0.00217, lr: 7.24E-07, _patience: 3\n",
            "Epoch: 76 | train_loss: 0.00101, val_loss: 0.00217, lr: 7.24E-07, _patience: 2\n",
            "Epoch: 77 | train_loss: 0.00100, val_loss: 0.00217, lr: 7.24E-07, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:19:13,294]\u001b[0m Trial 0 finished with value: 0.6609949866000874 and parameters: {'embedding_dim': 216, 'num_filters': 180, 'hidden_dim': 256, 'dropout_p': 0.5789252763161006, 'lr': 7.239503094923748e-05}. Best is trial 0 with value: 0.6609949866000874.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: 'optimization_1' does not exist. Creating a new experiment\n",
            "Epoch: 1 | train_loss: 0.00761, val_loss: 0.00582, lr: 1.94E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00501, val_loss: 0.00405, lr: 1.94E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00413, val_loss: 0.00388, lr: 1.94E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00369, val_loss: 0.00357, lr: 1.94E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00334, val_loss: 0.00326, lr: 1.94E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00298, val_loss: 0.00299, lr: 1.94E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00264, val_loss: 0.00280, lr: 1.94E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00237, val_loss: 0.00267, lr: 1.94E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00216, val_loss: 0.00255, lr: 1.94E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00195, val_loss: 0.00247, lr: 1.94E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00181, val_loss: 0.00241, lr: 1.94E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00162, val_loss: 0.00243, lr: 1.94E-04, _patience: 9\n",
            "Epoch: 13 | train_loss: 0.00152, val_loss: 0.00237, lr: 1.94E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00137, val_loss: 0.00228, lr: 1.94E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00127, val_loss: 0.00223, lr: 1.94E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00113, val_loss: 0.00222, lr: 1.94E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00106, val_loss: 0.00220, lr: 1.94E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00093, val_loss: 0.00218, lr: 1.94E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00084, val_loss: 0.00223, lr: 1.94E-04, _patience: 9\n",
            "Epoch: 20 | train_loss: 0.00078, val_loss: 0.00227, lr: 1.94E-04, _patience: 8\n",
            "Epoch: 21 | train_loss: 0.00070, val_loss: 0.00224, lr: 1.94E-04, _patience: 7\n",
            "Epoch: 22 | train_loss: 0.00061, val_loss: 0.00227, lr: 1.94E-04, _patience: 6\n",
            "Epoch: 23 | train_loss: 0.00058, val_loss: 0.00229, lr: 1.94E-04, _patience: 5\n",
            "Epoch: 24 | train_loss: 0.00055, val_loss: 0.00237, lr: 1.94E-05, _patience: 4\n",
            "Epoch: 25 | train_loss: 0.00050, val_loss: 0.00229, lr: 1.94E-05, _patience: 3\n",
            "Epoch: 26 | train_loss: 0.00044, val_loss: 0.00230, lr: 1.94E-05, _patience: 2\n",
            "Epoch: 27 | train_loss: 0.00041, val_loss: 0.00228, lr: 1.94E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:20:30,698]\u001b[0m Trial 1 finished with value: 0.6878502065377774 and parameters: {'embedding_dim': 182, 'num_filters': 486, 'hidden_dim': 496, 'dropout_p': 0.4667952286923533, 'lr': 0.0001935715676509405}. Best is trial 1 with value: 0.6878502065377774.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00856, val_loss: 0.00450, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00639, val_loss: 0.00435, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00569, val_loss: 0.00408, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00530, val_loss: 0.00397, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00490, val_loss: 0.00388, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00467, val_loss: 0.00378, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00444, val_loss: 0.00365, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00415, val_loss: 0.00359, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00396, val_loss: 0.00347, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00384, val_loss: 0.00340, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00359, val_loss: 0.00330, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00342, val_loss: 0.00318, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00330, val_loss: 0.00307, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00315, val_loss: 0.00302, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00308, val_loss: 0.00300, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00295, val_loss: 0.00293, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00285, val_loss: 0.00280, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00270, val_loss: 0.00280, lr: 8.74E-05, _patience: 9\n",
            "Epoch: 19 | train_loss: 0.00263, val_loss: 0.00270, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00248, val_loss: 0.00264, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00242, val_loss: 0.00265, lr: 8.74E-05, _patience: 9\n",
            "Epoch: 22 | train_loss: 0.00236, val_loss: 0.00259, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00222, val_loss: 0.00253, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00224, val_loss: 0.00245, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00215, val_loss: 0.00248, lr: 8.74E-05, _patience: 9\n",
            "Epoch: 26 | train_loss: 0.00210, val_loss: 0.00245, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00202, val_loss: 0.00245, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00185, val_loss: 0.00244, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00188, val_loss: 0.00242, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00176, val_loss: 0.00242, lr: 8.74E-05, _patience: 9\n",
            "Epoch: 31 | train_loss: 0.00179, val_loss: 0.00235, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 32 | train_loss: 0.00170, val_loss: 0.00237, lr: 8.74E-05, _patience: 9\n",
            "Epoch: 33 | train_loss: 0.00169, val_loss: 0.00233, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 34 | train_loss: 0.00154, val_loss: 0.00234, lr: 8.74E-05, _patience: 9\n",
            "Epoch: 35 | train_loss: 0.00156, val_loss: 0.00239, lr: 8.74E-05, _patience: 8\n",
            "Epoch: 36 | train_loss: 0.00150, val_loss: 0.00233, lr: 8.74E-05, _patience: 7\n",
            "Epoch: 37 | train_loss: 0.00144, val_loss: 0.00235, lr: 8.74E-05, _patience: 6\n",
            "Epoch: 38 | train_loss: 0.00137, val_loss: 0.00231, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 39 | train_loss: 0.00136, val_loss: 0.00231, lr: 8.74E-05, _patience: 9\n",
            "Epoch: 40 | train_loss: 0.00137, val_loss: 0.00231, lr: 8.74E-05, _patience: 8\n",
            "Epoch: 41 | train_loss: 0.00128, val_loss: 0.00228, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 42 | train_loss: 0.00128, val_loss: 0.00238, lr: 8.74E-05, _patience: 9\n",
            "Epoch: 43 | train_loss: 0.00124, val_loss: 0.00232, lr: 8.74E-05, _patience: 8\n",
            "Epoch: 44 | train_loss: 0.00121, val_loss: 0.00224, lr: 8.74E-05, _patience: 10\n",
            "Epoch: 45 | train_loss: 0.00119, val_loss: 0.00234, lr: 8.74E-05, _patience: 9\n",
            "Epoch: 46 | train_loss: 0.00117, val_loss: 0.00228, lr: 8.74E-05, _patience: 8\n",
            "Epoch: 47 | train_loss: 0.00112, val_loss: 0.00228, lr: 8.74E-05, _patience: 7\n",
            "Epoch: 48 | train_loss: 0.00106, val_loss: 0.00235, lr: 8.74E-05, _patience: 6\n",
            "Epoch: 49 | train_loss: 0.00104, val_loss: 0.00230, lr: 8.74E-05, _patience: 5\n",
            "Epoch: 50 | train_loss: 0.00105, val_loss: 0.00229, lr: 8.74E-06, _patience: 4\n",
            "Epoch: 51 | train_loss: 0.00101, val_loss: 0.00252, lr: 8.74E-06, _patience: 3\n",
            "Epoch: 52 | train_loss: 0.00096, val_loss: 0.00241, lr: 8.74E-06, _patience: 2\n",
            "Epoch: 53 | train_loss: 0.00100, val_loss: 0.00243, lr: 8.74E-06, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:23:20,020]\u001b[0m Trial 2 finished with value: 0.6545345523397196 and parameters: {'embedding_dim': 417, 'num_filters': 267, 'hidden_dim': 142, 'dropout_p': 0.6175157402027225, 'lr': 8.744178370658122e-05}. Best is trial 1 with value: 0.6878502065377774.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00701, val_loss: 0.00526, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00509, val_loss: 0.00417, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00449, val_loss: 0.00399, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00422, val_loss: 0.00387, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00394, val_loss: 0.00370, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00376, val_loss: 0.00352, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00351, val_loss: 0.00336, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00325, val_loss: 0.00317, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00301, val_loss: 0.00298, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00281, val_loss: 0.00285, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00266, val_loss: 0.00276, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00250, val_loss: 0.00265, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00232, val_loss: 0.00259, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00224, val_loss: 0.00249, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00214, val_loss: 0.00248, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00196, val_loss: 0.00239, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00190, val_loss: 0.00233, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00178, val_loss: 0.00232, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00171, val_loss: 0.00229, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00159, val_loss: 0.00227, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00152, val_loss: 0.00224, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00143, val_loss: 0.00220, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00139, val_loss: 0.00222, lr: 1.52E-04, _patience: 9\n",
            "Epoch: 24 | train_loss: 0.00128, val_loss: 0.00223, lr: 1.52E-04, _patience: 8\n",
            "Epoch: 25 | train_loss: 0.00126, val_loss: 0.00215, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00116, val_loss: 0.00219, lr: 1.52E-04, _patience: 9\n",
            "Epoch: 27 | train_loss: 0.00112, val_loss: 0.00219, lr: 1.52E-04, _patience: 8\n",
            "Epoch: 28 | train_loss: 0.00105, val_loss: 0.00215, lr: 1.52E-04, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00100, val_loss: 0.00220, lr: 1.52E-04, _patience: 9\n",
            "Epoch: 30 | train_loss: 0.00098, val_loss: 0.00224, lr: 1.52E-04, _patience: 8\n",
            "Epoch: 31 | train_loss: 0.00089, val_loss: 0.00218, lr: 1.52E-04, _patience: 7\n",
            "Epoch: 32 | train_loss: 0.00087, val_loss: 0.00217, lr: 1.52E-04, _patience: 6\n",
            "Epoch: 33 | train_loss: 0.00082, val_loss: 0.00220, lr: 1.52E-04, _patience: 5\n",
            "Epoch: 34 | train_loss: 0.00079, val_loss: 0.00219, lr: 1.52E-05, _patience: 4\n",
            "Epoch: 35 | train_loss: 0.00075, val_loss: 0.00236, lr: 1.52E-05, _patience: 3\n",
            "Epoch: 36 | train_loss: 0.00071, val_loss: 0.00229, lr: 1.52E-05, _patience: 2\n",
            "Epoch: 37 | train_loss: 0.00072, val_loss: 0.00227, lr: 1.52E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:24:24,184]\u001b[0m Trial 3 finished with value: 0.6641709919290605 and parameters: {'embedding_dim': 336, 'num_filters': 149, 'hidden_dim': 304, 'dropout_p': 0.6186526418309053, 'lr': 0.00015162361532599776}. Best is trial 1 with value: 0.6878502065377774.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00922, val_loss: 0.00559, lr: 1.81E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00657, val_loss: 0.00409, lr: 1.81E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00534, val_loss: 0.00401, lr: 1.81E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00481, val_loss: 0.00383, lr: 1.81E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00450, val_loss: 0.00370, lr: 1.81E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00417, val_loss: 0.00352, lr: 1.81E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00390, val_loss: 0.00335, lr: 1.81E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00363, val_loss: 0.00322, lr: 1.81E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00343, val_loss: 0.00302, lr: 1.81E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00319, val_loss: 0.00284, lr: 1.81E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00305, val_loss: 0.00275, lr: 1.81E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00297, val_loss: 0.00271, lr: 1.81E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00278, val_loss: 0.00260, lr: 1.81E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00266, val_loss: 0.00253, lr: 1.81E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00244, val_loss: 0.00250, lr: 1.81E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00234, val_loss: 0.00245, lr: 1.81E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00227, val_loss: 0.00249, lr: 1.81E-04, _patience: 9\n",
            "Epoch: 18 | train_loss: 0.00216, val_loss: 0.00240, lr: 1.81E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00203, val_loss: 0.00237, lr: 1.81E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00193, val_loss: 0.00239, lr: 1.81E-04, _patience: 9\n",
            "Epoch: 21 | train_loss: 0.00183, val_loss: 0.00223, lr: 1.81E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00170, val_loss: 0.00226, lr: 1.81E-04, _patience: 9\n",
            "Epoch: 23 | train_loss: 0.00169, val_loss: 0.00235, lr: 1.81E-04, _patience: 8\n",
            "Epoch: 24 | train_loss: 0.00163, val_loss: 0.00237, lr: 1.81E-04, _patience: 7\n",
            "Epoch: 25 | train_loss: 0.00158, val_loss: 0.00223, lr: 1.81E-04, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00152, val_loss: 0.00213, lr: 1.81E-04, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00148, val_loss: 0.00253, lr: 1.81E-04, _patience: 9\n",
            "Epoch: 28 | train_loss: 0.00141, val_loss: 0.00227, lr: 1.81E-04, _patience: 8\n",
            "Epoch: 29 | train_loss: 0.00131, val_loss: 0.00214, lr: 1.81E-04, _patience: 7\n",
            "Epoch: 30 | train_loss: 0.00124, val_loss: 0.00227, lr: 1.81E-04, _patience: 6\n",
            "Epoch: 31 | train_loss: 0.00122, val_loss: 0.00236, lr: 1.81E-04, _patience: 5\n",
            "Epoch: 32 | train_loss: 0.00116, val_loss: 0.00224, lr: 1.81E-05, _patience: 4\n",
            "Epoch: 33 | train_loss: 0.00111, val_loss: 0.00251, lr: 1.81E-05, _patience: 3\n",
            "Epoch: 34 | train_loss: 0.00106, val_loss: 0.00234, lr: 1.81E-05, _patience: 2\n",
            "Epoch: 35 | train_loss: 0.00096, val_loss: 0.00238, lr: 1.81E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:26:11,152]\u001b[0m Trial 4 finished with value: 0.6556943228637905 and parameters: {'embedding_dim': 293, 'num_filters': 360, 'hidden_dim': 290, 'dropout_p': 0.7788319993004884, 'lr': 0.00018090028216966177}. Best is trial 1 with value: 0.6878502065377774.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.01202, val_loss: 0.00454, lr: 2.44E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00821, val_loss: 0.00406, lr: 2.44E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00667, val_loss: 0.00387, lr: 2.44E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00602, val_loss: 0.00370, lr: 2.44E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00550, val_loss: 0.00361, lr: 2.44E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00494, val_loss: 0.00346, lr: 2.44E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00455, val_loss: 0.00335, lr: 2.44E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00433, val_loss: 0.00312, lr: 2.44E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00411, val_loss: 0.00304, lr: 2.44E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00389, val_loss: 0.00305, lr: 2.44E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00372, val_loss: 0.00290, lr: 2.44E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00353, val_loss: 0.00285, lr: 2.44E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00330, val_loss: 0.00275, lr: 2.44E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00317, val_loss: 0.00278, lr: 2.44E-04, _patience: 9\n",
            "Epoch: 15 | train_loss: 0.00307, val_loss: 0.00273, lr: 2.44E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00290, val_loss: 0.00261, lr: 2.44E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00280, val_loss: 0.00263, lr: 2.44E-04, _patience: 9\n",
            "Epoch: 18 | train_loss: 0.00284, val_loss: 0.00255, lr: 2.44E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00269, val_loss: 0.00264, lr: 2.44E-04, _patience: 9\n",
            "Epoch: 20 | train_loss: 0.00257, val_loss: 0.00284, lr: 2.44E-04, _patience: 8\n",
            "Epoch: 21 | train_loss: 0.00261, val_loss: 0.00272, lr: 2.44E-04, _patience: 7\n",
            "Epoch: 22 | train_loss: 0.00244, val_loss: 0.00244, lr: 2.44E-04, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00257, val_loss: 0.00244, lr: 2.44E-04, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00249, val_loss: 0.00240, lr: 2.44E-04, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00249, val_loss: 0.00280, lr: 2.44E-04, _patience: 9\n",
            "Epoch: 26 | train_loss: 0.00264, val_loss: 0.00306, lr: 2.44E-04, _patience: 8\n",
            "Epoch: 27 | train_loss: 0.00258, val_loss: 0.00297, lr: 2.44E-04, _patience: 7\n",
            "Epoch: 28 | train_loss: 0.00235, val_loss: 0.00252, lr: 2.44E-04, _patience: 6\n",
            "Epoch: 29 | train_loss: 0.00232, val_loss: 0.00234, lr: 2.44E-04, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00213, val_loss: 0.00257, lr: 2.44E-04, _patience: 9\n",
            "Epoch: 31 | train_loss: 0.00205, val_loss: 0.00273, lr: 2.44E-04, _patience: 8\n",
            "Epoch: 32 | train_loss: 0.00206, val_loss: 0.00246, lr: 2.44E-04, _patience: 7\n",
            "Epoch: 33 | train_loss: 0.00197, val_loss: 0.00228, lr: 2.44E-04, _patience: 10\n",
            "Epoch: 34 | train_loss: 0.00178, val_loss: 0.00240, lr: 2.44E-04, _patience: 9\n",
            "Epoch: 35 | train_loss: 0.00177, val_loss: 0.00247, lr: 2.44E-04, _patience: 8\n",
            "Epoch: 36 | train_loss: 0.00171, val_loss: 0.00235, lr: 2.44E-04, _patience: 7\n",
            "Epoch: 37 | train_loss: 0.00172, val_loss: 0.00244, lr: 2.44E-04, _patience: 6\n",
            "Epoch: 38 | train_loss: 0.00165, val_loss: 0.00259, lr: 2.44E-04, _patience: 5\n",
            "Epoch: 39 | train_loss: 0.00167, val_loss: 0.00277, lr: 2.44E-05, _patience: 4\n",
            "Epoch: 40 | train_loss: 0.00166, val_loss: 0.00295, lr: 2.44E-05, _patience: 3\n",
            "Epoch: 41 | train_loss: 0.00153, val_loss: 0.00272, lr: 2.44E-05, _patience: 2\n",
            "Epoch: 42 | train_loss: 0.00150, val_loss: 0.00281, lr: 2.44E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:29:02,515]\u001b[0m Trial 5 finished with value: 0.6304044130747363 and parameters: {'embedding_dim': 380, 'num_filters': 451, 'hidden_dim': 138, 'dropout_p': 0.7919175725364053, 'lr': 0.00024408053444791993}. Best is trial 1 with value: 0.6878502065377774.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00695, val_loss: 0.00569, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00526, val_loss: 0.00408, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00455, val_loss: 0.00389, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00415, val_loss: 0.00374, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00384, val_loss: 0.00353, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00353, val_loss: 0.00338, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00328, val_loss: 0.00318, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00304, val_loss: 0.00303, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00279, val_loss: 0.00289, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00265, val_loss: 0.00275, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00247, val_loss: 0.00264, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00230, val_loss: 0.00256, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00222, val_loss: 0.00250, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00202, val_loss: 0.00244, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00185, val_loss: 0.00239, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00177, val_loss: 0.00231, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00169, val_loss: 0.00228, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00154, val_loss: 0.00225, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00151, val_loss: 0.00224, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00138, val_loss: 0.00223, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00129, val_loss: 0.00222, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00123, val_loss: 0.00216, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00117, val_loss: 0.00219, lr: 1.15E-04, _patience: 9\n",
            "Epoch: 24 | train_loss: 0.00109, val_loss: 0.00219, lr: 1.15E-04, _patience: 8\n",
            "Epoch: 25 | train_loss: 0.00107, val_loss: 0.00214, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00098, val_loss: 0.00218, lr: 1.15E-04, _patience: 9\n",
            "Epoch: 27 | train_loss: 0.00095, val_loss: 0.00222, lr: 1.15E-04, _patience: 8\n",
            "Epoch: 28 | train_loss: 0.00088, val_loss: 0.00221, lr: 1.15E-04, _patience: 7\n",
            "Epoch: 29 | train_loss: 0.00083, val_loss: 0.00218, lr: 1.15E-04, _patience: 6\n",
            "Epoch: 30 | train_loss: 0.00080, val_loss: 0.00209, lr: 1.15E-04, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00075, val_loss: 0.00219, lr: 1.15E-04, _patience: 9\n",
            "Epoch: 32 | train_loss: 0.00075, val_loss: 0.00215, lr: 1.15E-04, _patience: 8\n",
            "Epoch: 33 | train_loss: 0.00068, val_loss: 0.00218, lr: 1.15E-04, _patience: 7\n",
            "Epoch: 34 | train_loss: 0.00067, val_loss: 0.00229, lr: 1.15E-04, _patience: 6\n",
            "Epoch: 35 | train_loss: 0.00063, val_loss: 0.00222, lr: 1.15E-04, _patience: 5\n",
            "Epoch: 36 | train_loss: 0.00063, val_loss: 0.00240, lr: 1.15E-05, _patience: 4\n",
            "Epoch: 37 | train_loss: 0.00056, val_loss: 0.00231, lr: 1.15E-05, _patience: 3\n",
            "Epoch: 38 | train_loss: 0.00053, val_loss: 0.00230, lr: 1.15E-05, _patience: 2\n",
            "Epoch: 39 | train_loss: 0.00052, val_loss: 0.00229, lr: 1.15E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:31:12,915]\u001b[0m Trial 6 finished with value: 0.6760696455945018 and parameters: {'embedding_dim': 278, 'num_filters': 442, 'hidden_dim': 239, 'dropout_p': 0.49059175382969394, 'lr': 0.0001147282071154538}. Best is trial 1 with value: 0.6878502065377774.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00647, val_loss: 0.00578, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00477, val_loss: 0.00413, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00420, val_loss: 0.00403, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00406, val_loss: 0.00396, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00386, val_loss: 0.00381, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00367, val_loss: 0.00366, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00341, val_loss: 0.00349, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00324, val_loss: 0.00329, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00303, val_loss: 0.00314, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00283, val_loss: 0.00297, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00265, val_loss: 0.00287, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00250, val_loss: 0.00276, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00234, val_loss: 0.00265, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00220, val_loss: 0.00256, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00211, val_loss: 0.00251, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00197, val_loss: 0.00247, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00187, val_loss: 0.00241, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00175, val_loss: 0.00236, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00166, val_loss: 0.00231, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00158, val_loss: 0.00223, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00149, val_loss: 0.00224, lr: 1.13E-04, _patience: 9\n",
            "Epoch: 22 | train_loss: 0.00141, val_loss: 0.00222, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00136, val_loss: 0.00216, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00125, val_loss: 0.00214, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00116, val_loss: 0.00214, lr: 1.13E-04, _patience: 9\n",
            "Epoch: 26 | train_loss: 0.00113, val_loss: 0.00214, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00109, val_loss: 0.00212, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00103, val_loss: 0.00211, lr: 1.13E-04, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00101, val_loss: 0.00213, lr: 1.13E-04, _patience: 9\n",
            "Epoch: 30 | train_loss: 0.00092, val_loss: 0.00216, lr: 1.13E-04, _patience: 8\n",
            "Epoch: 31 | train_loss: 0.00090, val_loss: 0.00216, lr: 1.13E-04, _patience: 7\n",
            "Epoch: 32 | train_loss: 0.00084, val_loss: 0.00215, lr: 1.13E-04, _patience: 6\n",
            "Epoch: 33 | train_loss: 0.00082, val_loss: 0.00215, lr: 1.13E-04, _patience: 5\n",
            "Epoch: 34 | train_loss: 0.00074, val_loss: 0.00217, lr: 1.13E-05, _patience: 4\n",
            "Epoch: 35 | train_loss: 0.00067, val_loss: 0.00215, lr: 1.13E-05, _patience: 3\n",
            "Epoch: 36 | train_loss: 0.00065, val_loss: 0.00216, lr: 1.13E-05, _patience: 2\n",
            "Epoch: 37 | train_loss: 0.00063, val_loss: 0.00214, lr: 1.13E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:32:41,009]\u001b[0m Trial 7 finished with value: 0.6812641884892998 and parameters: {'embedding_dim': 143, 'num_filters': 435, 'hidden_dim': 402, 'dropout_p': 0.4249064577125997, 'lr': 0.00011307774367830222}. Best is trial 1 with value: 0.6878502065377774.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.01147, val_loss: 0.00466, lr: 3.23E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00788, val_loss: 0.00420, lr: 3.23E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00636, val_loss: 0.00402, lr: 3.23E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00559, val_loss: 0.00388, lr: 3.23E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00513, val_loss: 0.00375, lr: 3.23E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00479, val_loss: 0.00361, lr: 3.23E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00443, val_loss: 0.00350, lr: 3.23E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00429, val_loss: 0.00336, lr: 3.23E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00406, val_loss: 0.00323, lr: 3.23E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00394, val_loss: 0.00313, lr: 3.23E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00365, val_loss: 0.00323, lr: 3.23E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00365, val_loss: 0.00295, lr: 3.23E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00344, val_loss: 0.00293, lr: 3.23E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00330, val_loss: 0.00280, lr: 3.23E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00323, val_loss: 0.00285, lr: 3.23E-04, _patience: 9\n",
            "Epoch: 16 | train_loss: 0.00305, val_loss: 0.00274, lr: 3.23E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00298, val_loss: 0.00274, lr: 3.23E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00282, val_loss: 0.00271, lr: 3.23E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00274, val_loss: 0.00272, lr: 3.23E-04, _patience: 9\n",
            "Epoch: 20 | train_loss: 0.00268, val_loss: 0.00266, lr: 3.23E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00264, val_loss: 0.00265, lr: 3.23E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00260, val_loss: 0.00289, lr: 3.23E-04, _patience: 9\n",
            "Epoch: 23 | train_loss: 0.00246, val_loss: 0.00293, lr: 3.23E-04, _patience: 8\n",
            "Epoch: 24 | train_loss: 0.00250, val_loss: 0.00254, lr: 3.23E-04, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00237, val_loss: 0.00270, lr: 3.23E-04, _patience: 9\n",
            "Epoch: 26 | train_loss: 0.00245, val_loss: 0.00259, lr: 3.23E-04, _patience: 8\n",
            "Epoch: 27 | train_loss: 0.00237, val_loss: 0.00239, lr: 3.23E-04, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00242, val_loss: 0.00239, lr: 3.23E-04, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00256, val_loss: 0.00324, lr: 3.23E-04, _patience: 9\n",
            "Epoch: 30 | train_loss: 0.00238, val_loss: 0.00283, lr: 3.23E-04, _patience: 8\n",
            "Epoch: 31 | train_loss: 0.00218, val_loss: 0.00239, lr: 3.23E-04, _patience: 7\n",
            "Epoch: 32 | train_loss: 0.00205, val_loss: 0.00256, lr: 3.23E-04, _patience: 6\n",
            "Epoch: 33 | train_loss: 0.00202, val_loss: 0.00254, lr: 3.23E-04, _patience: 5\n",
            "Epoch: 34 | train_loss: 0.00192, val_loss: 0.00258, lr: 3.23E-05, _patience: 4\n",
            "Epoch: 35 | train_loss: 0.00184, val_loss: 0.00266, lr: 3.23E-05, _patience: 3\n",
            "Epoch: 36 | train_loss: 0.00177, val_loss: 0.00254, lr: 3.23E-05, _patience: 2\n",
            "Epoch: 37 | train_loss: 0.00173, val_loss: 0.00259, lr: 3.23E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:33:39,275]\u001b[0m Trial 8 finished with value: 0.6037287009247577 and parameters: {'embedding_dim': 264, 'num_filters': 167, 'hidden_dim': 129, 'dropout_p': 0.7925746802485985, 'lr': 0.0003234720460926899}. Best is trial 1 with value: 0.6878502065377774.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00843, val_loss: 0.00463, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00545, val_loss: 0.00476, lr: 7.90E-05, _patience: 9\n",
            "Epoch: 3 | train_loss: 0.00498, val_loss: 0.00427, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00472, val_loss: 0.00415, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00462, val_loss: 0.00414, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00448, val_loss: 0.00409, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00435, val_loss: 0.00405, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00423, val_loss: 0.00400, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00416, val_loss: 0.00396, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00407, val_loss: 0.00390, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00394, val_loss: 0.00386, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00384, val_loss: 0.00380, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00371, val_loss: 0.00374, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00366, val_loss: 0.00365, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00359, val_loss: 0.00360, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00346, val_loss: 0.00352, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00336, val_loss: 0.00344, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00326, val_loss: 0.00334, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00320, val_loss: 0.00328, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00307, val_loss: 0.00324, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00300, val_loss: 0.00315, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00293, val_loss: 0.00306, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00279, val_loss: 0.00303, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00275, val_loss: 0.00299, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00269, val_loss: 0.00293, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00259, val_loss: 0.00287, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00257, val_loss: 0.00282, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00247, val_loss: 0.00278, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00238, val_loss: 0.00274, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00237, val_loss: 0.00271, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00226, val_loss: 0.00267, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 32 | train_loss: 0.00224, val_loss: 0.00260, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 33 | train_loss: 0.00218, val_loss: 0.00260, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 34 | train_loss: 0.00212, val_loss: 0.00257, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 35 | train_loss: 0.00207, val_loss: 0.00256, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 36 | train_loss: 0.00201, val_loss: 0.00249, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 37 | train_loss: 0.00196, val_loss: 0.00246, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 38 | train_loss: 0.00190, val_loss: 0.00245, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 39 | train_loss: 0.00185, val_loss: 0.00241, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 40 | train_loss: 0.00179, val_loss: 0.00239, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 41 | train_loss: 0.00176, val_loss: 0.00239, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 42 | train_loss: 0.00174, val_loss: 0.00237, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 43 | train_loss: 0.00165, val_loss: 0.00237, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 44 | train_loss: 0.00171, val_loss: 0.00232, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 45 | train_loss: 0.00157, val_loss: 0.00234, lr: 7.90E-05, _patience: 9\n",
            "Epoch: 46 | train_loss: 0.00157, val_loss: 0.00230, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 47 | train_loss: 0.00152, val_loss: 0.00229, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 48 | train_loss: 0.00150, val_loss: 0.00228, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 49 | train_loss: 0.00143, val_loss: 0.00229, lr: 7.90E-05, _patience: 9\n",
            "Epoch: 50 | train_loss: 0.00142, val_loss: 0.00229, lr: 7.90E-05, _patience: 8\n",
            "Epoch: 51 | train_loss: 0.00139, val_loss: 0.00225, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 52 | train_loss: 0.00136, val_loss: 0.00226, lr: 7.90E-05, _patience: 9\n",
            "Epoch: 53 | train_loss: 0.00129, val_loss: 0.00224, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 54 | train_loss: 0.00127, val_loss: 0.00230, lr: 7.90E-05, _patience: 9\n",
            "Epoch: 55 | train_loss: 0.00123, val_loss: 0.00226, lr: 7.90E-05, _patience: 8\n",
            "Epoch: 56 | train_loss: 0.00122, val_loss: 0.00223, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 57 | train_loss: 0.00118, val_loss: 0.00221, lr: 7.90E-05, _patience: 10\n",
            "Epoch: 58 | train_loss: 0.00116, val_loss: 0.00227, lr: 7.90E-05, _patience: 9\n",
            "Epoch: 59 | train_loss: 0.00114, val_loss: 0.00226, lr: 7.90E-05, _patience: 8\n",
            "Epoch: 60 | train_loss: 0.00109, val_loss: 0.00224, lr: 7.90E-05, _patience: 7\n",
            "Epoch: 61 | train_loss: 0.00105, val_loss: 0.00224, lr: 7.90E-05, _patience: 6\n",
            "Epoch: 62 | train_loss: 0.00108, val_loss: 0.00222, lr: 7.90E-05, _patience: 5\n",
            "Epoch: 63 | train_loss: 0.00102, val_loss: 0.00225, lr: 7.90E-06, _patience: 4\n",
            "Epoch: 64 | train_loss: 0.00099, val_loss: 0.00226, lr: 7.90E-06, _patience: 3\n",
            "Epoch: 65 | train_loss: 0.00098, val_loss: 0.00227, lr: 7.90E-06, _patience: 2\n",
            "Epoch: 66 | train_loss: 0.00096, val_loss: 0.00223, lr: 7.90E-06, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:34:57,306]\u001b[0m Trial 9 finished with value: 0.6577800506578666 and parameters: {'embedding_dim': 161, 'num_filters': 213, 'hidden_dim': 394, 'dropout_p': 0.6869216587736107, 'lr': 7.904835653843723e-05}. Best is trial 1 with value: 0.6878502065377774.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00936, val_loss: 0.00552, lr: 3.96E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00510, val_loss: 0.00425, lr: 3.96E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00382, val_loss: 0.00349, lr: 3.96E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00305, val_loss: 0.00295, lr: 3.96E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00250, val_loss: 0.00263, lr: 3.96E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00208, val_loss: 0.00247, lr: 3.96E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00173, val_loss: 0.00239, lr: 3.96E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00144, val_loss: 0.00227, lr: 3.96E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00117, val_loss: 0.00221, lr: 3.96E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00096, val_loss: 0.00226, lr: 3.96E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00080, val_loss: 0.00223, lr: 3.96E-04, _patience: 8\n",
            "Epoch: 12 | train_loss: 0.00066, val_loss: 0.00228, lr: 3.96E-04, _patience: 7\n",
            "Epoch: 13 | train_loss: 0.00054, val_loss: 0.00239, lr: 3.96E-04, _patience: 6\n",
            "Epoch: 14 | train_loss: 0.00047, val_loss: 0.00258, lr: 3.96E-04, _patience: 5\n",
            "Epoch: 15 | train_loss: 0.00044, val_loss: 0.00254, lr: 3.96E-05, _patience: 4\n",
            "Epoch: 16 | train_loss: 0.00035, val_loss: 0.00244, lr: 3.96E-05, _patience: 3\n",
            "Epoch: 17 | train_loss: 0.00029, val_loss: 0.00243, lr: 3.96E-05, _patience: 2\n",
            "Epoch: 18 | train_loss: 0.00030, val_loss: 0.00240, lr: 3.96E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:35:53,502]\u001b[0m Trial 10 finished with value: 0.6789307249717715 and parameters: {'embedding_dim': 196, 'num_filters': 508, 'hidden_dim': 482, 'dropout_p': 0.3458682136775321, 'lr': 0.00039586259922156513}. Best is trial 1 with value: 0.6878502065377774.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00673, val_loss: 0.00571, lr: 1.59E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00490, val_loss: 0.00417, lr: 1.59E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00419, val_loss: 0.00406, lr: 1.59E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00390, val_loss: 0.00387, lr: 1.59E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00368, val_loss: 0.00374, lr: 1.59E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00345, val_loss: 0.00349, lr: 1.59E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00319, val_loss: 0.00331, lr: 1.59E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00291, val_loss: 0.00308, lr: 1.59E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00265, val_loss: 0.00290, lr: 1.59E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00243, val_loss: 0.00274, lr: 1.59E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00222, val_loss: 0.00262, lr: 1.59E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00207, val_loss: 0.00252, lr: 1.59E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00194, val_loss: 0.00247, lr: 1.59E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00178, val_loss: 0.00241, lr: 1.59E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00170, val_loss: 0.00235, lr: 1.59E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00157, val_loss: 0.00235, lr: 1.59E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00150, val_loss: 0.00232, lr: 1.59E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00139, val_loss: 0.00228, lr: 1.59E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00126, val_loss: 0.00227, lr: 1.59E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00116, val_loss: 0.00223, lr: 1.59E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00109, val_loss: 0.00216, lr: 1.59E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00102, val_loss: 0.00216, lr: 1.59E-04, _patience: 9\n",
            "Epoch: 23 | train_loss: 0.00097, val_loss: 0.00218, lr: 1.59E-04, _patience: 8\n",
            "Epoch: 24 | train_loss: 0.00088, val_loss: 0.00214, lr: 1.59E-04, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00083, val_loss: 0.00216, lr: 1.59E-04, _patience: 9\n",
            "Epoch: 26 | train_loss: 0.00077, val_loss: 0.00218, lr: 1.59E-04, _patience: 8\n",
            "Epoch: 27 | train_loss: 0.00074, val_loss: 0.00222, lr: 1.59E-04, _patience: 7\n",
            "Epoch: 28 | train_loss: 0.00070, val_loss: 0.00224, lr: 1.59E-04, _patience: 6\n",
            "Epoch: 29 | train_loss: 0.00065, val_loss: 0.00226, lr: 1.59E-04, _patience: 5\n",
            "Epoch: 30 | train_loss: 0.00061, val_loss: 0.00222, lr: 1.59E-05, _patience: 4\n",
            "Epoch: 31 | train_loss: 0.00054, val_loss: 0.00225, lr: 1.59E-05, _patience: 3\n",
            "Epoch: 32 | train_loss: 0.00049, val_loss: 0.00226, lr: 1.59E-05, _patience: 2\n",
            "Epoch: 33 | train_loss: 0.00048, val_loss: 0.00225, lr: 1.59E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:37:04,981]\u001b[0m Trial 11 finished with value: 0.6694897828389194 and parameters: {'embedding_dim': 129, 'num_filters': 388, 'hidden_dim': 511, 'dropout_p': 0.42575842372533995, 'lr': 0.00015922214044810807}. Best is trial 1 with value: 0.6878502065377774.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00752, val_loss: 0.00571, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00488, val_loss: 0.00409, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00403, val_loss: 0.00389, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00367, val_loss: 0.00362, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00330, val_loss: 0.00332, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00292, val_loss: 0.00305, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00262, val_loss: 0.00282, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00232, val_loss: 0.00265, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00205, val_loss: 0.00252, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00187, val_loss: 0.00248, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00170, val_loss: 0.00247, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00150, val_loss: 0.00234, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00133, val_loss: 0.00229, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00122, val_loss: 0.00232, lr: 2.21E-04, _patience: 9\n",
            "Epoch: 15 | train_loss: 0.00115, val_loss: 0.00229, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00105, val_loss: 0.00229, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00095, val_loss: 0.00228, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00086, val_loss: 0.00229, lr: 2.21E-04, _patience: 9\n",
            "Epoch: 19 | train_loss: 0.00079, val_loss: 0.00238, lr: 2.21E-04, _patience: 8\n",
            "Epoch: 20 | train_loss: 0.00072, val_loss: 0.00254, lr: 2.21E-04, _patience: 7\n",
            "Epoch: 21 | train_loss: 0.00067, val_loss: 0.00256, lr: 2.21E-04, _patience: 6\n",
            "Epoch: 22 | train_loss: 0.00059, val_loss: 0.00255, lr: 2.21E-04, _patience: 5\n",
            "Epoch: 23 | train_loss: 0.00057, val_loss: 0.00259, lr: 2.21E-05, _patience: 4\n",
            "Epoch: 24 | train_loss: 0.00051, val_loss: 0.00233, lr: 2.21E-05, _patience: 3\n",
            "Epoch: 25 | train_loss: 0.00043, val_loss: 0.00229, lr: 2.21E-05, _patience: 2\n",
            "Epoch: 26 | train_loss: 0.00041, val_loss: 0.00232, lr: 2.21E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:38:08,336]\u001b[0m Trial 12 finished with value: 0.6740707036488466 and parameters: {'embedding_dim': 128, 'num_filters': 512, 'hidden_dim': 421, 'dropout_p': 0.3450977488645123, 'lr': 0.00022095061201785128}. Best is trial 1 with value: 0.6878502065377774.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00648, val_loss: 0.00580, lr: 1.07E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00474, val_loss: 0.00401, lr: 1.07E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00411, val_loss: 0.00394, lr: 1.07E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00387, val_loss: 0.00377, lr: 1.07E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00359, val_loss: 0.00358, lr: 1.07E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00337, val_loss: 0.00337, lr: 1.07E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00315, val_loss: 0.00315, lr: 1.07E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00288, val_loss: 0.00299, lr: 1.07E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00268, val_loss: 0.00283, lr: 1.07E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00249, val_loss: 0.00272, lr: 1.07E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00235, val_loss: 0.00261, lr: 1.07E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00214, val_loss: 0.00252, lr: 1.07E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00200, val_loss: 0.00242, lr: 1.07E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00185, val_loss: 0.00237, lr: 1.07E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00177, val_loss: 0.00231, lr: 1.07E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00165, val_loss: 0.00227, lr: 1.07E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00156, val_loss: 0.00222, lr: 1.07E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00145, val_loss: 0.00218, lr: 1.07E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00138, val_loss: 0.00218, lr: 1.07E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00129, val_loss: 0.00215, lr: 1.07E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00118, val_loss: 0.00214, lr: 1.07E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00116, val_loss: 0.00210, lr: 1.07E-04, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00107, val_loss: 0.00211, lr: 1.07E-04, _patience: 9\n",
            "Epoch: 24 | train_loss: 0.00100, val_loss: 0.00214, lr: 1.07E-04, _patience: 8\n",
            "Epoch: 25 | train_loss: 0.00093, val_loss: 0.00217, lr: 1.07E-04, _patience: 7\n",
            "Epoch: 26 | train_loss: 0.00090, val_loss: 0.00213, lr: 1.07E-04, _patience: 6\n",
            "Epoch: 27 | train_loss: 0.00082, val_loss: 0.00216, lr: 1.07E-04, _patience: 5\n",
            "Epoch: 28 | train_loss: 0.00078, val_loss: 0.00216, lr: 1.07E-05, _patience: 4\n",
            "Epoch: 29 | train_loss: 0.00073, val_loss: 0.00213, lr: 1.07E-05, _patience: 3\n",
            "Epoch: 30 | train_loss: 0.00069, val_loss: 0.00215, lr: 1.07E-05, _patience: 2\n",
            "Epoch: 31 | train_loss: 0.00067, val_loss: 0.00213, lr: 1.07E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:39:41,049]\u001b[0m Trial 13 finished with value: 0.6700895444744346 and parameters: {'embedding_dim': 219, 'num_filters': 449, 'hidden_dim': 411, 'dropout_p': 0.4422439623256509, 'lr': 0.00010682946560523402}. Best is trial 1 with value: 0.6878502065377774.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00664, val_loss: 0.00554, lr: 1.23E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00452, val_loss: 0.00393, lr: 1.23E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00391, val_loss: 0.00369, lr: 1.23E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00338, val_loss: 0.00333, lr: 1.23E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00304, val_loss: 0.00304, lr: 1.23E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00268, val_loss: 0.00283, lr: 1.23E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00241, val_loss: 0.00264, lr: 1.23E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00219, val_loss: 0.00258, lr: 1.23E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00198, val_loss: 0.00245, lr: 1.23E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00181, val_loss: 0.00242, lr: 1.23E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00164, val_loss: 0.00240, lr: 1.23E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00150, val_loss: 0.00229, lr: 1.23E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00132, val_loss: 0.00229, lr: 1.23E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00123, val_loss: 0.00224, lr: 1.23E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00111, val_loss: 0.00223, lr: 1.23E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00100, val_loss: 0.00229, lr: 1.23E-04, _patience: 9\n",
            "Epoch: 17 | train_loss: 0.00096, val_loss: 0.00230, lr: 1.23E-04, _patience: 8\n",
            "Epoch: 18 | train_loss: 0.00084, val_loss: 0.00235, lr: 1.23E-04, _patience: 7\n",
            "Epoch: 19 | train_loss: 0.00077, val_loss: 0.00234, lr: 1.23E-04, _patience: 6\n",
            "Epoch: 20 | train_loss: 0.00069, val_loss: 0.00234, lr: 1.23E-04, _patience: 5\n",
            "Epoch: 21 | train_loss: 0.00065, val_loss: 0.00244, lr: 1.23E-05, _patience: 4\n",
            "Epoch: 22 | train_loss: 0.00057, val_loss: 0.00228, lr: 1.23E-05, _patience: 3\n",
            "Epoch: 23 | train_loss: 0.00053, val_loss: 0.00225, lr: 1.23E-05, _patience: 2\n",
            "Epoch: 24 | train_loss: 0.00050, val_loss: 0.00228, lr: 1.23E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:41:24,721]\u001b[0m Trial 14 finished with value: 0.6695801319370777 and parameters: {'embedding_dim': 497, 'num_filters': 396, 'hidden_dim': 458, 'dropout_p': 0.4748623756212068, 'lr': 0.0001234013454462735}. Best is trial 1 with value: 0.6878502065377774.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00696, val_loss: 0.00472, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00459, val_loss: 0.00462, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00421, val_loss: 0.00416, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00402, val_loss: 0.00408, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00393, val_loss: 0.00403, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00383, val_loss: 0.00398, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00370, val_loss: 0.00390, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00362, val_loss: 0.00383, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00350, val_loss: 0.00374, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00338, val_loss: 0.00366, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00326, val_loss: 0.00356, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00319, val_loss: 0.00346, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00306, val_loss: 0.00337, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00297, val_loss: 0.00326, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00284, val_loss: 0.00318, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00271, val_loss: 0.00308, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00262, val_loss: 0.00299, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00250, val_loss: 0.00291, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00239, val_loss: 0.00283, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00235, val_loss: 0.00276, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00223, val_loss: 0.00271, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00216, val_loss: 0.00265, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00209, val_loss: 0.00260, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00201, val_loss: 0.00255, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00193, val_loss: 0.00253, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00185, val_loss: 0.00247, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00181, val_loss: 0.00246, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00175, val_loss: 0.00242, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00170, val_loss: 0.00238, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00164, val_loss: 0.00235, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00160, val_loss: 0.00234, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 32 | train_loss: 0.00154, val_loss: 0.00232, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 33 | train_loss: 0.00147, val_loss: 0.00228, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 34 | train_loss: 0.00141, val_loss: 0.00226, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 35 | train_loss: 0.00138, val_loss: 0.00225, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 36 | train_loss: 0.00134, val_loss: 0.00226, lr: 5.95E-05, _patience: 9\n",
            "Epoch: 37 | train_loss: 0.00129, val_loss: 0.00222, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 38 | train_loss: 0.00125, val_loss: 0.00223, lr: 5.95E-05, _patience: 9\n",
            "Epoch: 39 | train_loss: 0.00118, val_loss: 0.00222, lr: 5.95E-05, _patience: 8\n",
            "Epoch: 40 | train_loss: 0.00116, val_loss: 0.00219, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 41 | train_loss: 0.00113, val_loss: 0.00217, lr: 5.95E-05, _patience: 10\n",
            "Epoch: 42 | train_loss: 0.00107, val_loss: 0.00219, lr: 5.95E-05, _patience: 9\n",
            "Epoch: 43 | train_loss: 0.00105, val_loss: 0.00219, lr: 5.95E-05, _patience: 8\n",
            "Epoch: 44 | train_loss: 0.00101, val_loss: 0.00220, lr: 5.95E-05, _patience: 7\n",
            "Epoch: 45 | train_loss: 0.00097, val_loss: 0.00217, lr: 5.95E-05, _patience: 6\n",
            "Epoch: 46 | train_loss: 0.00095, val_loss: 0.00218, lr: 5.95E-05, _patience: 5\n",
            "Epoch: 47 | train_loss: 0.00093, val_loss: 0.00221, lr: 5.95E-06, _patience: 4\n",
            "Epoch: 48 | train_loss: 0.00089, val_loss: 0.00216, lr: 5.95E-06, _patience: 10\n",
            "Epoch: 49 | train_loss: 0.00086, val_loss: 0.00215, lr: 5.95E-06, _patience: 10\n",
            "Epoch: 50 | train_loss: 0.00086, val_loss: 0.00214, lr: 5.95E-06, _patience: 10\n",
            "Epoch: 51 | train_loss: 0.00086, val_loss: 0.00214, lr: 5.95E-06, _patience: 10\n",
            "Epoch: 52 | train_loss: 0.00086, val_loss: 0.00215, lr: 5.95E-06, _patience: 9\n",
            "Epoch: 53 | train_loss: 0.00085, val_loss: 0.00215, lr: 5.95E-06, _patience: 8\n",
            "Epoch: 54 | train_loss: 0.00084, val_loss: 0.00215, lr: 5.95E-06, _patience: 7\n",
            "Epoch: 55 | train_loss: 0.00082, val_loss: 0.00215, lr: 5.95E-06, _patience: 6\n",
            "Epoch: 56 | train_loss: 0.00084, val_loss: 0.00215, lr: 5.95E-06, _patience: 5\n",
            "Epoch: 57 | train_loss: 0.00084, val_loss: 0.00214, lr: 5.95E-06, _patience: 10\n",
            "Epoch: 58 | train_loss: 0.00080, val_loss: 0.00215, lr: 5.95E-06, _patience: 9\n",
            "Epoch: 59 | train_loss: 0.00082, val_loss: 0.00215, lr: 5.95E-06, _patience: 8\n",
            "Epoch: 60 | train_loss: 0.00081, val_loss: 0.00215, lr: 5.95E-06, _patience: 7\n",
            "Epoch: 61 | train_loss: 0.00081, val_loss: 0.00216, lr: 5.95E-06, _patience: 6\n",
            "Epoch: 62 | train_loss: 0.00081, val_loss: 0.00214, lr: 5.95E-06, _patience: 5\n",
            "Epoch: 63 | train_loss: 0.00081, val_loss: 0.00215, lr: 5.95E-07, _patience: 4\n",
            "Epoch: 64 | train_loss: 0.00082, val_loss: 0.00215, lr: 5.95E-07, _patience: 3\n",
            "Epoch: 65 | train_loss: 0.00078, val_loss: 0.00215, lr: 5.95E-07, _patience: 2\n",
            "Epoch: 66 | train_loss: 0.00080, val_loss: 0.00215, lr: 5.95E-07, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:43:35,221]\u001b[0m Trial 15 finished with value: 0.6493208822681001 and parameters: {'embedding_dim': 169, 'num_filters': 313, 'hidden_dim': 360, 'dropout_p': 0.3045297423130306, 'lr': 5.951900802779886e-05}. Best is trial 1 with value: 0.6878502065377774.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00840, val_loss: 0.00581, lr: 2.68E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00538, val_loss: 0.00427, lr: 2.68E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00417, val_loss: 0.00388, lr: 2.68E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00362, val_loss: 0.00356, lr: 2.68E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00319, val_loss: 0.00315, lr: 2.68E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00276, val_loss: 0.00287, lr: 2.68E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00243, val_loss: 0.00269, lr: 2.68E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00213, val_loss: 0.00256, lr: 2.68E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00191, val_loss: 0.00246, lr: 2.68E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00170, val_loss: 0.00239, lr: 2.68E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00150, val_loss: 0.00236, lr: 2.68E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00131, val_loss: 0.00238, lr: 2.68E-04, _patience: 9\n",
            "Epoch: 13 | train_loss: 0.00122, val_loss: 0.00234, lr: 2.68E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00106, val_loss: 0.00229, lr: 2.68E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00096, val_loss: 0.00227, lr: 2.68E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00083, val_loss: 0.00224, lr: 2.68E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00076, val_loss: 0.00229, lr: 2.68E-04, _patience: 9\n",
            "Epoch: 18 | train_loss: 0.00070, val_loss: 0.00226, lr: 2.68E-04, _patience: 8\n",
            "Epoch: 19 | train_loss: 0.00063, val_loss: 0.00238, lr: 2.68E-04, _patience: 7\n",
            "Epoch: 20 | train_loss: 0.00059, val_loss: 0.00245, lr: 2.68E-04, _patience: 6\n",
            "Epoch: 21 | train_loss: 0.00055, val_loss: 0.00247, lr: 2.68E-04, _patience: 5\n",
            "Epoch: 22 | train_loss: 0.00049, val_loss: 0.00251, lr: 2.68E-05, _patience: 4\n",
            "Epoch: 23 | train_loss: 0.00043, val_loss: 0.00242, lr: 2.68E-05, _patience: 3\n",
            "Epoch: 24 | train_loss: 0.00036, val_loss: 0.00235, lr: 2.68E-05, _patience: 2\n",
            "Epoch: 25 | train_loss: 0.00035, val_loss: 0.00234, lr: 2.68E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:44:39,778]\u001b[0m Trial 16 finished with value: 0.6780570770943167 and parameters: {'embedding_dim': 140, 'num_filters': 491, 'hidden_dim': 504, 'dropout_p': 0.39559363158799893, 'lr': 0.00026756160114541246}. Best is trial 1 with value: 0.6878502065377774.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.01075, val_loss: 0.00540, lr: 4.81E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00541, val_loss: 0.00413, lr: 4.81E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00405, val_loss: 0.00356, lr: 4.81E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00334, val_loss: 0.00298, lr: 4.81E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00273, val_loss: 0.00262, lr: 4.81E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00231, val_loss: 0.00246, lr: 4.81E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00196, val_loss: 0.00236, lr: 4.81E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00163, val_loss: 0.00227, lr: 4.81E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00140, val_loss: 0.00228, lr: 4.81E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00115, val_loss: 0.00229, lr: 4.81E-04, _patience: 8\n",
            "Epoch: 11 | train_loss: 0.00094, val_loss: 0.00228, lr: 4.81E-04, _patience: 7\n",
            "Epoch: 12 | train_loss: 0.00083, val_loss: 0.00228, lr: 4.81E-04, _patience: 6\n",
            "Epoch: 13 | train_loss: 0.00066, val_loss: 0.00246, lr: 4.81E-04, _patience: 5\n",
            "Epoch: 14 | train_loss: 0.00062, val_loss: 0.00249, lr: 4.81E-05, _patience: 4\n",
            "Epoch: 15 | train_loss: 0.00055, val_loss: 0.00246, lr: 4.81E-05, _patience: 3\n",
            "Epoch: 16 | train_loss: 0.00044, val_loss: 0.00242, lr: 4.81E-05, _patience: 2\n",
            "Epoch: 17 | train_loss: 0.00040, val_loss: 0.00239, lr: 4.81E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:45:36,733]\u001b[0m Trial 17 finished with value: 0.6754963510830186 and parameters: {'embedding_dim': 242, 'num_filters': 476, 'hidden_dim': 359, 'dropout_p': 0.5128207090403741, 'lr': 0.00048060762144196015}. Best is trial 1 with value: 0.6878502065377774.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00652, val_loss: 0.00512, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00498, val_loss: 0.00458, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00444, val_loss: 0.00414, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00427, val_loss: 0.00410, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00408, val_loss: 0.00407, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00405, val_loss: 0.00399, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00394, val_loss: 0.00392, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00385, val_loss: 0.00386, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00372, val_loss: 0.00379, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00360, val_loss: 0.00370, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00351, val_loss: 0.00362, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00339, val_loss: 0.00354, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00331, val_loss: 0.00344, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00316, val_loss: 0.00336, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00303, val_loss: 0.00325, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00296, val_loss: 0.00320, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00290, val_loss: 0.00310, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00274, val_loss: 0.00302, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00263, val_loss: 0.00296, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00256, val_loss: 0.00287, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00250, val_loss: 0.00283, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00241, val_loss: 0.00277, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00232, val_loss: 0.00272, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00225, val_loss: 0.00267, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00219, val_loss: 0.00264, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00215, val_loss: 0.00258, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00206, val_loss: 0.00254, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00199, val_loss: 0.00253, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00191, val_loss: 0.00249, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00190, val_loss: 0.00248, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00185, val_loss: 0.00243, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 32 | train_loss: 0.00179, val_loss: 0.00242, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 33 | train_loss: 0.00175, val_loss: 0.00239, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 34 | train_loss: 0.00169, val_loss: 0.00237, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 35 | train_loss: 0.00160, val_loss: 0.00234, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 36 | train_loss: 0.00157, val_loss: 0.00234, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 37 | train_loss: 0.00154, val_loss: 0.00231, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 38 | train_loss: 0.00148, val_loss: 0.00229, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 39 | train_loss: 0.00143, val_loss: 0.00230, lr: 5.02E-05, _patience: 9\n",
            "Epoch: 40 | train_loss: 0.00142, val_loss: 0.00228, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 41 | train_loss: 0.00136, val_loss: 0.00228, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 42 | train_loss: 0.00134, val_loss: 0.00224, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 43 | train_loss: 0.00129, val_loss: 0.00229, lr: 5.02E-05, _patience: 9\n",
            "Epoch: 44 | train_loss: 0.00125, val_loss: 0.00222, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 45 | train_loss: 0.00124, val_loss: 0.00221, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 46 | train_loss: 0.00122, val_loss: 0.00220, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 47 | train_loss: 0.00113, val_loss: 0.00220, lr: 5.02E-05, _patience: 9\n",
            "Epoch: 48 | train_loss: 0.00113, val_loss: 0.00222, lr: 5.02E-05, _patience: 8\n",
            "Epoch: 49 | train_loss: 0.00108, val_loss: 0.00223, lr: 5.02E-05, _patience: 7\n",
            "Epoch: 50 | train_loss: 0.00104, val_loss: 0.00219, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 51 | train_loss: 0.00102, val_loss: 0.00218, lr: 5.02E-05, _patience: 10\n",
            "Epoch: 52 | train_loss: 0.00101, val_loss: 0.00219, lr: 5.02E-05, _patience: 9\n",
            "Epoch: 53 | train_loss: 0.00097, val_loss: 0.00218, lr: 5.02E-05, _patience: 8\n",
            "Epoch: 54 | train_loss: 0.00092, val_loss: 0.00224, lr: 5.02E-05, _patience: 7\n",
            "Epoch: 55 | train_loss: 0.00090, val_loss: 0.00220, lr: 5.02E-05, _patience: 6\n",
            "Epoch: 56 | train_loss: 0.00090, val_loss: 0.00220, lr: 5.02E-05, _patience: 5\n",
            "Epoch: 57 | train_loss: 0.00088, val_loss: 0.00218, lr: 5.02E-06, _patience: 4\n",
            "Epoch: 58 | train_loss: 0.00081, val_loss: 0.00218, lr: 5.02E-06, _patience: 3\n",
            "Epoch: 59 | train_loss: 0.00082, val_loss: 0.00218, lr: 5.02E-06, _patience: 2\n",
            "Epoch: 60 | train_loss: 0.00081, val_loss: 0.00217, lr: 5.02E-06, _patience: 10\n",
            "Epoch: 61 | train_loss: 0.00081, val_loss: 0.00217, lr: 5.02E-06, _patience: 10\n",
            "Epoch: 62 | train_loss: 0.00081, val_loss: 0.00217, lr: 5.02E-06, _patience: 10\n",
            "Epoch: 63 | train_loss: 0.00079, val_loss: 0.00217, lr: 5.02E-06, _patience: 9\n",
            "Epoch: 64 | train_loss: 0.00079, val_loss: 0.00218, lr: 5.02E-06, _patience: 8\n",
            "Epoch: 65 | train_loss: 0.00080, val_loss: 0.00217, lr: 5.02E-06, _patience: 7\n",
            "Epoch: 66 | train_loss: 0.00079, val_loss: 0.00216, lr: 5.02E-06, _patience: 10\n",
            "Epoch: 67 | train_loss: 0.00078, val_loss: 0.00216, lr: 5.02E-06, _patience: 10\n",
            "Epoch: 68 | train_loss: 0.00077, val_loss: 0.00217, lr: 5.02E-06, _patience: 9\n",
            "Epoch: 69 | train_loss: 0.00078, val_loss: 0.00216, lr: 5.02E-06, _patience: 8\n",
            "Epoch: 70 | train_loss: 0.00078, val_loss: 0.00217, lr: 5.02E-06, _patience: 7\n",
            "Epoch: 71 | train_loss: 0.00076, val_loss: 0.00216, lr: 5.02E-06, _patience: 6\n",
            "Epoch: 72 | train_loss: 0.00076, val_loss: 0.00217, lr: 5.02E-06, _patience: 5\n",
            "Epoch: 73 | train_loss: 0.00076, val_loss: 0.00217, lr: 5.02E-07, _patience: 4\n",
            "Epoch: 74 | train_loss: 0.00077, val_loss: 0.00217, lr: 5.02E-07, _patience: 3\n",
            "Epoch: 75 | train_loss: 0.00076, val_loss: 0.00217, lr: 5.02E-07, _patience: 2\n",
            "Epoch: 76 | train_loss: 0.00075, val_loss: 0.00217, lr: 5.02E-07, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:48:49,348]\u001b[0m Trial 18 finished with value: 0.6565349082576424 and parameters: {'embedding_dim': 183, 'num_filters': 399, 'hidden_dim': 463, 'dropout_p': 0.5375301426471648, 'lr': 5.022892907417671e-05}. Best is trial 1 with value: 0.6878502065377774.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00654, val_loss: 0.00477, lr: 2.07E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00434, val_loss: 0.00391, lr: 2.07E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00369, val_loss: 0.00358, lr: 2.07E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00321, val_loss: 0.00317, lr: 2.07E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00278, val_loss: 0.00289, lr: 2.07E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00244, val_loss: 0.00266, lr: 2.07E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00212, val_loss: 0.00250, lr: 2.07E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00183, val_loss: 0.00241, lr: 2.07E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00160, val_loss: 0.00230, lr: 2.07E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00142, val_loss: 0.00232, lr: 2.07E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00126, val_loss: 0.00223, lr: 2.07E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00112, val_loss: 0.00220, lr: 2.07E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00101, val_loss: 0.00217, lr: 2.07E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00087, val_loss: 0.00213, lr: 2.07E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00079, val_loss: 0.00217, lr: 2.07E-04, _patience: 9\n",
            "Epoch: 16 | train_loss: 0.00068, val_loss: 0.00222, lr: 2.07E-04, _patience: 8\n",
            "Epoch: 17 | train_loss: 0.00063, val_loss: 0.00228, lr: 2.07E-04, _patience: 7\n",
            "Epoch: 18 | train_loss: 0.00061, val_loss: 0.00242, lr: 2.07E-04, _patience: 6\n",
            "Epoch: 19 | train_loss: 0.00053, val_loss: 0.00239, lr: 2.07E-04, _patience: 5\n",
            "Epoch: 20 | train_loss: 0.00050, val_loss: 0.00235, lr: 2.07E-05, _patience: 4\n",
            "Epoch: 21 | train_loss: 0.00043, val_loss: 0.00238, lr: 2.07E-05, _patience: 3\n",
            "Epoch: 22 | train_loss: 0.00037, val_loss: 0.00234, lr: 2.07E-05, _patience: 2\n",
            "Epoch: 23 | train_loss: 0.00036, val_loss: 0.00230, lr: 2.07E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:50:01,049]\u001b[0m Trial 19 finished with value: 0.6749437845946652 and parameters: {'embedding_dim': 323, 'num_filters': 331, 'hidden_dim': 436, 'dropout_p': 0.3756055510213373, 'lr': 0.0002072148717956434}. Best is trial 1 with value: 0.6878502065377774.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00671, val_loss: 0.00550, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00451, val_loss: 0.00380, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00375, val_loss: 0.00355, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00331, val_loss: 0.00314, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00288, val_loss: 0.00290, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00261, val_loss: 0.00272, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00228, val_loss: 0.00254, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00201, val_loss: 0.00241, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00187, val_loss: 0.00232, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00165, val_loss: 0.00229, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00150, val_loss: 0.00225, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00136, val_loss: 0.00220, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00121, val_loss: 0.00216, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00110, val_loss: 0.00221, lr: 1.33E-04, _patience: 9\n",
            "Epoch: 15 | train_loss: 0.00100, val_loss: 0.00219, lr: 1.33E-04, _patience: 8\n",
            "Epoch: 16 | train_loss: 0.00091, val_loss: 0.00222, lr: 1.33E-04, _patience: 7\n",
            "Epoch: 17 | train_loss: 0.00087, val_loss: 0.00217, lr: 1.33E-04, _patience: 6\n",
            "Epoch: 18 | train_loss: 0.00074, val_loss: 0.00231, lr: 1.33E-04, _patience: 5\n",
            "Epoch: 19 | train_loss: 0.00074, val_loss: 0.00228, lr: 1.33E-05, _patience: 4\n",
            "Epoch: 20 | train_loss: 0.00064, val_loss: 0.00225, lr: 1.33E-05, _patience: 3\n",
            "Epoch: 21 | train_loss: 0.00057, val_loss: 0.00222, lr: 1.33E-05, _patience: 2\n",
            "Epoch: 22 | train_loss: 0.00055, val_loss: 0.00224, lr: 1.33E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:51:40,264]\u001b[0m Trial 20 finished with value: 0.6734628252689255 and parameters: {'embedding_dim': 493, 'num_filters': 426, 'hidden_dim': 365, 'dropout_p': 0.4531425355825031, 'lr': 0.00013343159644667093}. Best is trial 1 with value: 0.6878502065377774.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00968, val_loss: 0.00491, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00494, val_loss: 0.00415, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00368, val_loss: 0.00343, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00291, val_loss: 0.00287, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00231, val_loss: 0.00255, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00183, val_loss: 0.00239, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00153, val_loss: 0.00231, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00121, val_loss: 0.00230, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00098, val_loss: 0.00231, lr: 4.96E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00077, val_loss: 0.00238, lr: 4.96E-04, _patience: 8\n",
            "Epoch: 11 | train_loss: 0.00060, val_loss: 0.00247, lr: 4.96E-04, _patience: 7\n",
            "Epoch: 12 | train_loss: 0.00051, val_loss: 0.00257, lr: 4.96E-04, _patience: 6\n",
            "Epoch: 13 | train_loss: 0.00045, val_loss: 0.00263, lr: 4.96E-04, _patience: 5\n",
            "Epoch: 14 | train_loss: 0.00038, val_loss: 0.00274, lr: 4.96E-05, _patience: 4\n",
            "Epoch: 15 | train_loss: 0.00030, val_loss: 0.00251, lr: 4.96E-05, _patience: 3\n",
            "Epoch: 16 | train_loss: 0.00025, val_loss: 0.00248, lr: 4.96E-05, _patience: 2\n",
            "Epoch: 17 | train_loss: 0.00024, val_loss: 0.00252, lr: 4.96E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:52:32,747]\u001b[0m Trial 21 finished with value: 0.6838145202242131 and parameters: {'embedding_dim': 192, 'num_filters': 506, 'hidden_dim': 486, 'dropout_p': 0.3103010505203235, 'lr': 0.0004959529149232021}. Best is trial 1 with value: 0.6878502065377774.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.01039, val_loss: 0.00621, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00533, val_loss: 0.00423, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00383, val_loss: 0.00360, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00306, val_loss: 0.00298, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00245, val_loss: 0.00263, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00200, val_loss: 0.00248, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00164, val_loss: 0.00234, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00131, val_loss: 0.00232, lr: 4.98E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00108, val_loss: 0.00233, lr: 4.98E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00088, val_loss: 0.00250, lr: 4.98E-04, _patience: 8\n",
            "Epoch: 11 | train_loss: 0.00071, val_loss: 0.00250, lr: 4.98E-04, _patience: 7\n",
            "Epoch: 12 | train_loss: 0.00063, val_loss: 0.00252, lr: 4.98E-04, _patience: 6\n",
            "Epoch: 13 | train_loss: 0.00051, val_loss: 0.00258, lr: 4.98E-04, _patience: 5\n",
            "Epoch: 14 | train_loss: 0.00046, val_loss: 0.00263, lr: 4.98E-05, _patience: 4\n",
            "Epoch: 15 | train_loss: 0.00037, val_loss: 0.00247, lr: 4.98E-05, _patience: 3\n",
            "Epoch: 16 | train_loss: 0.00029, val_loss: 0.00246, lr: 4.98E-05, _patience: 2\n",
            "Epoch: 17 | train_loss: 0.00028, val_loss: 0.00247, lr: 4.98E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:53:21,956]\u001b[0m Trial 22 finished with value: 0.6731457425105557 and parameters: {'embedding_dim': 161, 'num_filters': 507, 'hidden_dim': 506, 'dropout_p': 0.3193223079661554, 'lr': 0.0004979294994865425}. Best is trial 1 with value: 0.6878502065377774.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00894, val_loss: 0.00607, lr: 3.18E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00515, val_loss: 0.00408, lr: 3.18E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00383, val_loss: 0.00363, lr: 3.18E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00319, val_loss: 0.00313, lr: 3.18E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00265, val_loss: 0.00277, lr: 3.18E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00225, val_loss: 0.00262, lr: 3.18E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00191, val_loss: 0.00246, lr: 3.18E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00164, val_loss: 0.00240, lr: 3.18E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00135, val_loss: 0.00228, lr: 3.18E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00112, val_loss: 0.00227, lr: 3.18E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00097, val_loss: 0.00242, lr: 3.18E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00087, val_loss: 0.00235, lr: 3.18E-04, _patience: 8\n",
            "Epoch: 13 | train_loss: 0.00073, val_loss: 0.00241, lr: 3.18E-04, _patience: 7\n",
            "Epoch: 14 | train_loss: 0.00063, val_loss: 0.00242, lr: 3.18E-04, _patience: 6\n",
            "Epoch: 15 | train_loss: 0.00055, val_loss: 0.00228, lr: 3.18E-04, _patience: 5\n",
            "Epoch: 16 | train_loss: 0.00049, val_loss: 0.00246, lr: 3.18E-05, _patience: 4\n",
            "Epoch: 17 | train_loss: 0.00040, val_loss: 0.00235, lr: 3.18E-05, _patience: 3\n",
            "Epoch: 18 | train_loss: 0.00036, val_loss: 0.00240, lr: 3.18E-05, _patience: 2\n",
            "Epoch: 19 | train_loss: 0.00034, val_loss: 0.00240, lr: 3.18E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:54:24,108]\u001b[0m Trial 23 finished with value: 0.6893605235149695 and parameters: {'embedding_dim': 231, 'num_filters': 476, 'hidden_dim': 471, 'dropout_p': 0.39253220838548886, 'lr': 0.0003177277068343745}. Best is trial 23 with value: 0.6893605235149695.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00840, val_loss: 0.00515, lr: 3.22E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00506, val_loss: 0.00400, lr: 3.22E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00384, val_loss: 0.00353, lr: 3.22E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00312, val_loss: 0.00299, lr: 3.22E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00255, val_loss: 0.00266, lr: 3.22E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00216, val_loss: 0.00251, lr: 3.22E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00184, val_loss: 0.00241, lr: 3.22E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00156, val_loss: 0.00232, lr: 3.22E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00131, val_loss: 0.00225, lr: 3.22E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00106, val_loss: 0.00227, lr: 3.22E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00094, val_loss: 0.00226, lr: 3.22E-04, _patience: 8\n",
            "Epoch: 12 | train_loss: 0.00078, val_loss: 0.00226, lr: 3.22E-04, _patience: 7\n",
            "Epoch: 13 | train_loss: 0.00068, val_loss: 0.00227, lr: 3.22E-04, _patience: 6\n",
            "Epoch: 14 | train_loss: 0.00058, val_loss: 0.00230, lr: 3.22E-04, _patience: 5\n",
            "Epoch: 15 | train_loss: 0.00053, val_loss: 0.00248, lr: 3.22E-05, _patience: 4\n",
            "Epoch: 16 | train_loss: 0.00047, val_loss: 0.00231, lr: 3.22E-05, _patience: 3\n",
            "Epoch: 17 | train_loss: 0.00037, val_loss: 0.00235, lr: 3.22E-05, _patience: 2\n",
            "Epoch: 18 | train_loss: 0.00035, val_loss: 0.00235, lr: 3.22E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:55:22,988]\u001b[0m Trial 24 finished with value: 0.6692339705203999 and parameters: {'embedding_dim': 234, 'num_filters': 472, 'hidden_dim': 482, 'dropout_p': 0.39636368855592796, 'lr': 0.0003223403889074547}. Best is trial 23 with value: 0.6893605235149695.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00827, val_loss: 0.00521, lr: 3.62E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00477, val_loss: 0.00409, lr: 3.62E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00365, val_loss: 0.00343, lr: 3.62E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00290, val_loss: 0.00293, lr: 3.62E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00233, val_loss: 0.00260, lr: 3.62E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00190, val_loss: 0.00242, lr: 3.62E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00156, val_loss: 0.00237, lr: 3.62E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00131, val_loss: 0.00235, lr: 3.62E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00111, val_loss: 0.00237, lr: 3.62E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00094, val_loss: 0.00238, lr: 3.62E-04, _patience: 8\n",
            "Epoch: 11 | train_loss: 0.00079, val_loss: 0.00238, lr: 3.62E-04, _patience: 7\n",
            "Epoch: 12 | train_loss: 0.00071, val_loss: 0.00259, lr: 3.62E-04, _patience: 6\n",
            "Epoch: 13 | train_loss: 0.00063, val_loss: 0.00266, lr: 3.62E-04, _patience: 5\n",
            "Epoch: 14 | train_loss: 0.00055, val_loss: 0.00259, lr: 3.62E-05, _patience: 4\n",
            "Epoch: 15 | train_loss: 0.00043, val_loss: 0.00251, lr: 3.62E-05, _patience: 3\n",
            "Epoch: 16 | train_loss: 0.00036, val_loss: 0.00242, lr: 3.62E-05, _patience: 2\n",
            "Epoch: 17 | train_loss: 0.00033, val_loss: 0.00241, lr: 3.62E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:56:15,218]\u001b[0m Trial 25 finished with value: 0.6728039551963331 and parameters: {'embedding_dim': 199, 'num_filters': 477, 'hidden_dim': 450, 'dropout_p': 0.30369084382162465, 'lr': 0.0003618977945722521}. Best is trial 23 with value: 0.6893605235149695.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00899, val_loss: 0.00507, lr: 4.25E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00473, val_loss: 0.00393, lr: 4.25E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00345, val_loss: 0.00320, lr: 4.25E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00277, val_loss: 0.00271, lr: 4.25E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00223, val_loss: 0.00247, lr: 4.25E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00178, val_loss: 0.00228, lr: 4.25E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00145, val_loss: 0.00224, lr: 4.25E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00113, val_loss: 0.00226, lr: 4.25E-04, _patience: 9\n",
            "Epoch: 9 | train_loss: 0.00093, val_loss: 0.00234, lr: 4.25E-04, _patience: 8\n",
            "Epoch: 10 | train_loss: 0.00079, val_loss: 0.00245, lr: 4.25E-04, _patience: 7\n",
            "Epoch: 11 | train_loss: 0.00065, val_loss: 0.00271, lr: 4.25E-04, _patience: 6\n",
            "Epoch: 12 | train_loss: 0.00062, val_loss: 0.00277, lr: 4.25E-04, _patience: 5\n",
            "Epoch: 13 | train_loss: 0.00050, val_loss: 0.00275, lr: 4.25E-05, _patience: 4\n",
            "Epoch: 14 | train_loss: 0.00040, val_loss: 0.00259, lr: 4.25E-05, _patience: 3\n",
            "Epoch: 15 | train_loss: 0.00031, val_loss: 0.00251, lr: 4.25E-05, _patience: 2\n",
            "Epoch: 16 | train_loss: 0.00028, val_loss: 0.00249, lr: 4.25E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:57:10,126]\u001b[0m Trial 26 finished with value: 0.687146310954673 and parameters: {'embedding_dim': 240, 'num_filters': 504, 'hidden_dim': 485, 'dropout_p': 0.3649819780181304, 'lr': 0.00042539947611324364}. Best is trial 23 with value: 0.6893605235149695.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00858, val_loss: 0.00492, lr: 4.16E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00480, val_loss: 0.00406, lr: 4.16E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00361, val_loss: 0.00331, lr: 4.16E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00289, val_loss: 0.00275, lr: 4.16E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00232, val_loss: 0.00248, lr: 4.16E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00192, val_loss: 0.00235, lr: 4.16E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00162, val_loss: 0.00233, lr: 4.16E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00130, val_loss: 0.00222, lr: 4.16E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00106, val_loss: 0.00220, lr: 4.16E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00090, val_loss: 0.00231, lr: 4.16E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00073, val_loss: 0.00244, lr: 4.16E-04, _patience: 8\n",
            "Epoch: 12 | train_loss: 0.00062, val_loss: 0.00255, lr: 4.16E-04, _patience: 7\n",
            "Epoch: 13 | train_loss: 0.00055, val_loss: 0.00259, lr: 4.16E-04, _patience: 6\n",
            "Epoch: 14 | train_loss: 0.00047, val_loss: 0.00269, lr: 4.16E-04, _patience: 5\n",
            "Epoch: 15 | train_loss: 0.00043, val_loss: 0.00256, lr: 4.16E-05, _patience: 4\n",
            "Epoch: 16 | train_loss: 0.00033, val_loss: 0.00241, lr: 4.16E-05, _patience: 3\n",
            "Epoch: 17 | train_loss: 0.00028, val_loss: 0.00247, lr: 4.16E-05, _patience: 2\n",
            "Epoch: 18 | train_loss: 0.00025, val_loss: 0.00250, lr: 4.16E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:58:06,820]\u001b[0m Trial 27 finished with value: 0.6854237586527557 and parameters: {'embedding_dim': 246, 'num_filters': 417, 'hidden_dim': 471, 'dropout_p': 0.3668527628702528, 'lr': 0.0004156393597152231}. Best is trial 23 with value: 0.6893605235149695.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00763, val_loss: 0.00511, lr: 2.83E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00477, val_loss: 0.00399, lr: 2.83E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00383, val_loss: 0.00353, lr: 2.83E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00317, val_loss: 0.00304, lr: 2.83E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00267, val_loss: 0.00270, lr: 2.83E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00229, val_loss: 0.00250, lr: 2.83E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00197, val_loss: 0.00238, lr: 2.83E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00169, val_loss: 0.00225, lr: 2.83E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00145, val_loss: 0.00221, lr: 2.83E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00129, val_loss: 0.00226, lr: 2.83E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00112, val_loss: 0.00220, lr: 2.83E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00095, val_loss: 0.00225, lr: 2.83E-04, _patience: 9\n",
            "Epoch: 13 | train_loss: 0.00082, val_loss: 0.00226, lr: 2.83E-04, _patience: 8\n",
            "Epoch: 14 | train_loss: 0.00071, val_loss: 0.00235, lr: 2.83E-04, _patience: 7\n",
            "Epoch: 15 | train_loss: 0.00065, val_loss: 0.00244, lr: 2.83E-04, _patience: 6\n",
            "Epoch: 16 | train_loss: 0.00057, val_loss: 0.00246, lr: 2.83E-04, _patience: 5\n",
            "Epoch: 17 | train_loss: 0.00049, val_loss: 0.00257, lr: 2.83E-05, _patience: 4\n",
            "Epoch: 18 | train_loss: 0.00044, val_loss: 0.00237, lr: 2.83E-05, _patience: 3\n",
            "Epoch: 19 | train_loss: 0.00037, val_loss: 0.00232, lr: 2.83E-05, _patience: 2\n",
            "Epoch: 20 | train_loss: 0.00037, val_loss: 0.00233, lr: 2.83E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 01:59:10,974]\u001b[0m Trial 28 finished with value: 0.6804190420257422 and parameters: {'embedding_dim': 294, 'num_filters': 368, 'hidden_dim': 511, 'dropout_p': 0.4803885155217381, 'lr': 0.0002830585969387563}. Best is trial 23 with value: 0.6893605235149695.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00870, val_loss: 0.00562, lr: 3.05E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00556, val_loss: 0.00402, lr: 3.05E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00446, val_loss: 0.00374, lr: 3.05E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00383, val_loss: 0.00334, lr: 3.05E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00333, val_loss: 0.00299, lr: 3.05E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00294, val_loss: 0.00276, lr: 3.05E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00263, val_loss: 0.00257, lr: 3.05E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00232, val_loss: 0.00249, lr: 3.05E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00205, val_loss: 0.00238, lr: 3.05E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00189, val_loss: 0.00236, lr: 3.05E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00169, val_loss: 0.00231, lr: 3.05E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00150, val_loss: 0.00229, lr: 3.05E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00139, val_loss: 0.00216, lr: 3.05E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00127, val_loss: 0.00218, lr: 3.05E-04, _patience: 9\n",
            "Epoch: 15 | train_loss: 0.00115, val_loss: 0.00243, lr: 3.05E-04, _patience: 8\n",
            "Epoch: 16 | train_loss: 0.00105, val_loss: 0.00238, lr: 3.05E-04, _patience: 7\n",
            "Epoch: 17 | train_loss: 0.00097, val_loss: 0.00221, lr: 3.05E-04, _patience: 6\n",
            "Epoch: 18 | train_loss: 0.00088, val_loss: 0.00212, lr: 3.05E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00083, val_loss: 0.00217, lr: 3.05E-04, _patience: 9\n",
            "Epoch: 20 | train_loss: 0.00076, val_loss: 0.00246, lr: 3.05E-04, _patience: 8\n",
            "Epoch: 21 | train_loss: 0.00070, val_loss: 0.00249, lr: 3.05E-04, _patience: 7\n",
            "Epoch: 22 | train_loss: 0.00067, val_loss: 0.00260, lr: 3.05E-04, _patience: 6\n",
            "Epoch: 23 | train_loss: 0.00070, val_loss: 0.00227, lr: 3.05E-04, _patience: 5\n",
            "Epoch: 24 | train_loss: 0.00065, val_loss: 0.00225, lr: 3.05E-05, _patience: 4\n",
            "Epoch: 25 | train_loss: 0.00058, val_loss: 0.00283, lr: 3.05E-05, _patience: 3\n",
            "Epoch: 26 | train_loss: 0.00050, val_loss: 0.00241, lr: 3.05E-05, _patience: 2\n",
            "Epoch: 27 | train_loss: 0.00043, val_loss: 0.00251, lr: 3.05E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 02:00:35,786]\u001b[0m Trial 29 finished with value: 0.6792903912236194 and parameters: {'embedding_dim': 229, 'num_filters': 466, 'hidden_dim': 230, 'dropout_p': 0.5807220854326729, 'lr': 0.0003053725835980111}. Best is trial 23 with value: 0.6893605235149695.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00632, val_loss: 0.00509, lr: 1.83E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00434, val_loss: 0.00396, lr: 1.83E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00383, val_loss: 0.00373, lr: 1.83E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00335, val_loss: 0.00333, lr: 1.83E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00295, val_loss: 0.00302, lr: 1.83E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00259, val_loss: 0.00281, lr: 1.83E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00226, val_loss: 0.00267, lr: 1.83E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00207, val_loss: 0.00255, lr: 1.83E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00179, val_loss: 0.00248, lr: 1.83E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00163, val_loss: 0.00244, lr: 1.83E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00145, val_loss: 0.00240, lr: 1.83E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00128, val_loss: 0.00239, lr: 1.83E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00114, val_loss: 0.00235, lr: 1.83E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00103, val_loss: 0.00234, lr: 1.83E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00094, val_loss: 0.00231, lr: 1.83E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00087, val_loss: 0.00233, lr: 1.83E-04, _patience: 9\n",
            "Epoch: 17 | train_loss: 0.00077, val_loss: 0.00229, lr: 1.83E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00071, val_loss: 0.00235, lr: 1.83E-04, _patience: 9\n",
            "Epoch: 19 | train_loss: 0.00064, val_loss: 0.00238, lr: 1.83E-04, _patience: 8\n",
            "Epoch: 20 | train_loss: 0.00059, val_loss: 0.00242, lr: 1.83E-04, _patience: 7\n",
            "Epoch: 21 | train_loss: 0.00054, val_loss: 0.00261, lr: 1.83E-04, _patience: 6\n",
            "Epoch: 22 | train_loss: 0.00050, val_loss: 0.00254, lr: 1.83E-04, _patience: 5\n",
            "Epoch: 23 | train_loss: 0.00046, val_loss: 0.00269, lr: 1.83E-05, _patience: 4\n",
            "Epoch: 24 | train_loss: 0.00043, val_loss: 0.00245, lr: 1.83E-05, _patience: 3\n",
            "Epoch: 25 | train_loss: 0.00035, val_loss: 0.00236, lr: 1.83E-05, _patience: 2\n",
            "Epoch: 26 | train_loss: 0.00035, val_loss: 0.00240, lr: 1.83E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 02:01:49,360]\u001b[0m Trial 30 finished with value: 0.667001578430888 and parameters: {'embedding_dim': 361, 'num_filters': 262, 'hidden_dim': 437, 'dropout_p': 0.41034286882129384, 'lr': 0.00018292032112495122}. Best is trial 23 with value: 0.6893605235149695.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00863, val_loss: 0.00508, lr: 4.12E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00479, val_loss: 0.00408, lr: 4.12E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00364, val_loss: 0.00337, lr: 4.12E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00289, val_loss: 0.00283, lr: 4.12E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00233, val_loss: 0.00261, lr: 4.12E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00191, val_loss: 0.00243, lr: 4.12E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00154, val_loss: 0.00235, lr: 4.12E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00129, val_loss: 0.00231, lr: 4.12E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00105, val_loss: 0.00240, lr: 4.12E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00089, val_loss: 0.00244, lr: 4.12E-04, _patience: 8\n",
            "Epoch: 11 | train_loss: 0.00074, val_loss: 0.00256, lr: 4.12E-04, _patience: 7\n",
            "Epoch: 12 | train_loss: 0.00062, val_loss: 0.00265, lr: 4.12E-04, _patience: 6\n",
            "Epoch: 13 | train_loss: 0.00054, val_loss: 0.00267, lr: 4.12E-04, _patience: 5\n",
            "Epoch: 14 | train_loss: 0.00046, val_loss: 0.00274, lr: 4.12E-05, _patience: 4\n",
            "Epoch: 15 | train_loss: 0.00037, val_loss: 0.00256, lr: 4.12E-05, _patience: 3\n",
            "Epoch: 16 | train_loss: 0.00030, val_loss: 0.00251, lr: 4.12E-05, _patience: 2\n",
            "Epoch: 17 | train_loss: 0.00029, val_loss: 0.00251, lr: 4.12E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 02:02:43,113]\u001b[0m Trial 31 finished with value: 0.6679073636059011 and parameters: {'embedding_dim': 246, 'num_filters': 415, 'hidden_dim': 475, 'dropout_p': 0.3630162670340257, 'lr': 0.00041166830654573163}. Best is trial 23 with value: 0.6893605235149695.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00897, val_loss: 0.00531, lr: 4.50E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00508, val_loss: 0.00384, lr: 4.50E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00385, val_loss: 0.00327, lr: 4.50E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00311, val_loss: 0.00286, lr: 4.50E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00256, val_loss: 0.00259, lr: 4.50E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00205, val_loss: 0.00252, lr: 4.50E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00181, val_loss: 0.00235, lr: 4.50E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00147, val_loss: 0.00235, lr: 4.50E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00121, val_loss: 0.00238, lr: 4.50E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00108, val_loss: 0.00246, lr: 4.50E-04, _patience: 8\n",
            "Epoch: 11 | train_loss: 0.00089, val_loss: 0.00239, lr: 4.50E-04, _patience: 7\n",
            "Epoch: 12 | train_loss: 0.00083, val_loss: 0.00237, lr: 4.50E-04, _patience: 6\n",
            "Epoch: 13 | train_loss: 0.00074, val_loss: 0.00238, lr: 4.50E-04, _patience: 5\n",
            "Epoch: 14 | train_loss: 0.00064, val_loss: 0.00257, lr: 4.50E-05, _patience: 4\n",
            "Epoch: 15 | train_loss: 0.00055, val_loss: 0.00251, lr: 4.50E-05, _patience: 3\n",
            "Epoch: 16 | train_loss: 0.00045, val_loss: 0.00251, lr: 4.50E-05, _patience: 2\n",
            "Epoch: 17 | train_loss: 0.00043, val_loss: 0.00248, lr: 4.50E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 02:03:44,765]\u001b[0m Trial 32 finished with value: 0.6833612795071888 and parameters: {'embedding_dim': 262, 'num_filters': 490, 'hidden_dim': 176, 'dropout_p': 0.3716395513513812, 'lr': 0.0004504747122905832}. Best is trial 23 with value: 0.6893605235149695.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00868, val_loss: 0.00518, lr: 3.66E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00479, val_loss: 0.00406, lr: 3.66E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00369, val_loss: 0.00340, lr: 3.66E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00299, val_loss: 0.00287, lr: 3.66E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00239, val_loss: 0.00258, lr: 3.66E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00199, val_loss: 0.00243, lr: 3.66E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00167, val_loss: 0.00234, lr: 3.66E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00137, val_loss: 0.00230, lr: 3.66E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00112, val_loss: 0.00229, lr: 3.66E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00094, val_loss: 0.00236, lr: 3.66E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00078, val_loss: 0.00242, lr: 3.66E-04, _patience: 8\n",
            "Epoch: 12 | train_loss: 0.00065, val_loss: 0.00248, lr: 3.66E-04, _patience: 7\n",
            "Epoch: 13 | train_loss: 0.00059, val_loss: 0.00256, lr: 3.66E-04, _patience: 6\n",
            "Epoch: 14 | train_loss: 0.00052, val_loss: 0.00276, lr: 3.66E-04, _patience: 5\n",
            "Epoch: 15 | train_loss: 0.00047, val_loss: 0.00287, lr: 3.66E-05, _patience: 4\n",
            "Epoch: 16 | train_loss: 0.00038, val_loss: 0.00253, lr: 3.66E-05, _patience: 3\n",
            "Epoch: 17 | train_loss: 0.00029, val_loss: 0.00242, lr: 3.66E-05, _patience: 2\n",
            "Epoch: 18 | train_loss: 0.00029, val_loss: 0.00246, lr: 3.66E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 02:04:39,192]\u001b[0m Trial 33 finished with value: 0.6667343823883983 and parameters: {'embedding_dim': 208, 'num_filters': 460, 'hidden_dim': 495, 'dropout_p': 0.336836212053763, 'lr': 0.00036558196062431693}. Best is trial 23 with value: 0.6893605235149695.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00737, val_loss: 0.00514, lr: 2.50E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00465, val_loss: 0.00396, lr: 2.50E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00385, val_loss: 0.00353, lr: 2.50E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00323, val_loss: 0.00314, lr: 2.50E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00271, val_loss: 0.00282, lr: 2.50E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00233, val_loss: 0.00262, lr: 2.50E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00205, val_loss: 0.00250, lr: 2.50E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00175, val_loss: 0.00241, lr: 2.50E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00153, val_loss: 0.00233, lr: 2.50E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00130, val_loss: 0.00230, lr: 2.50E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00115, val_loss: 0.00229, lr: 2.50E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00101, val_loss: 0.00225, lr: 2.50E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00089, val_loss: 0.00227, lr: 2.50E-04, _patience: 9\n",
            "Epoch: 14 | train_loss: 0.00080, val_loss: 0.00237, lr: 2.50E-04, _patience: 8\n",
            "Epoch: 15 | train_loss: 0.00070, val_loss: 0.00246, lr: 2.50E-04, _patience: 7\n",
            "Epoch: 16 | train_loss: 0.00061, val_loss: 0.00257, lr: 2.50E-04, _patience: 6\n",
            "Epoch: 17 | train_loss: 0.00056, val_loss: 0.00267, lr: 2.50E-04, _patience: 5\n",
            "Epoch: 18 | train_loss: 0.00051, val_loss: 0.00263, lr: 2.50E-05, _patience: 4\n",
            "Epoch: 19 | train_loss: 0.00043, val_loss: 0.00240, lr: 2.50E-05, _patience: 3\n",
            "Epoch: 20 | train_loss: 0.00036, val_loss: 0.00238, lr: 2.50E-05, _patience: 2\n",
            "Epoch: 21 | train_loss: 0.00035, val_loss: 0.00239, lr: 2.50E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 02:05:53,956]\u001b[0m Trial 34 finished with value: 0.6645582930196803 and parameters: {'embedding_dim': 301, 'num_filters': 414, 'hidden_dim': 441, 'dropout_p': 0.454128690583519, 'lr': 0.0002498598625596354}. Best is trial 23 with value: 0.6893605235149695.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00889, val_loss: 0.00538, lr: 3.56E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00497, val_loss: 0.00395, lr: 3.56E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00368, val_loss: 0.00341, lr: 3.56E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00301, val_loss: 0.00289, lr: 3.56E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00246, val_loss: 0.00262, lr: 3.56E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00199, val_loss: 0.00246, lr: 3.56E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00167, val_loss: 0.00236, lr: 3.56E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00136, val_loss: 0.00227, lr: 3.56E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00114, val_loss: 0.00226, lr: 3.56E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00096, val_loss: 0.00227, lr: 3.56E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00083, val_loss: 0.00241, lr: 3.56E-04, _patience: 8\n",
            "Epoch: 12 | train_loss: 0.00068, val_loss: 0.00245, lr: 3.56E-04, _patience: 7\n",
            "Epoch: 13 | train_loss: 0.00061, val_loss: 0.00253, lr: 3.56E-04, _patience: 6\n",
            "Epoch: 14 | train_loss: 0.00052, val_loss: 0.00260, lr: 3.56E-04, _patience: 5\n",
            "Epoch: 15 | train_loss: 0.00047, val_loss: 0.00262, lr: 3.56E-05, _patience: 4\n",
            "Epoch: 16 | train_loss: 0.00040, val_loss: 0.00254, lr: 3.56E-05, _patience: 3\n",
            "Epoch: 17 | train_loss: 0.00033, val_loss: 0.00243, lr: 3.56E-05, _patience: 2\n",
            "Epoch: 18 | train_loss: 0.00031, val_loss: 0.00246, lr: 3.56E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 02:06:59,971]\u001b[0m Trial 35 finished with value: 0.6759572363932831 and parameters: {'embedding_dim': 270, 'num_filters': 489, 'hidden_dim': 385, 'dropout_p': 0.389991661901649, 'lr': 0.00035554349847071885}. Best is trial 23 with value: 0.6893605235149695.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00865, val_loss: 0.00472, lr: 4.36E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00480, val_loss: 0.00407, lr: 4.36E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00369, val_loss: 0.00333, lr: 4.36E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00292, val_loss: 0.00286, lr: 4.36E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00242, val_loss: 0.00258, lr: 4.36E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00195, val_loss: 0.00240, lr: 4.36E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00162, val_loss: 0.00228, lr: 4.36E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00134, val_loss: 0.00234, lr: 4.36E-04, _patience: 9\n",
            "Epoch: 9 | train_loss: 0.00110, val_loss: 0.00240, lr: 4.36E-04, _patience: 8\n",
            "Epoch: 10 | train_loss: 0.00095, val_loss: 0.00254, lr: 4.36E-04, _patience: 7\n",
            "Epoch: 11 | train_loss: 0.00080, val_loss: 0.00243, lr: 4.36E-04, _patience: 6\n",
            "Epoch: 12 | train_loss: 0.00066, val_loss: 0.00284, lr: 4.36E-04, _patience: 5\n",
            "Epoch: 13 | train_loss: 0.00061, val_loss: 0.00268, lr: 4.36E-05, _patience: 4\n",
            "Epoch: 14 | train_loss: 0.00047, val_loss: 0.00254, lr: 4.36E-05, _patience: 3\n",
            "Epoch: 15 | train_loss: 0.00039, val_loss: 0.00251, lr: 4.36E-05, _patience: 2\n",
            "Epoch: 16 | train_loss: 0.00037, val_loss: 0.00248, lr: 4.36E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 02:07:55,902]\u001b[0m Trial 36 finished with value: 0.6723790436288055 and parameters: {'embedding_dim': 347, 'num_filters': 364, 'hidden_dim': 465, 'dropout_p': 0.5154961752966003, 'lr': 0.00043597679421147813}. Best is trial 23 with value: 0.6893605235149695.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00673, val_loss: 0.00517, lr: 2.02E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00474, val_loss: 0.00403, lr: 2.02E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00405, val_loss: 0.00376, lr: 2.02E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00357, val_loss: 0.00346, lr: 2.02E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00318, val_loss: 0.00311, lr: 2.02E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00284, val_loss: 0.00281, lr: 2.02E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00250, val_loss: 0.00260, lr: 2.02E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00223, val_loss: 0.00248, lr: 2.02E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00200, val_loss: 0.00240, lr: 2.02E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00181, val_loss: 0.00231, lr: 2.02E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00161, val_loss: 0.00227, lr: 2.02E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00151, val_loss: 0.00221, lr: 2.02E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00134, val_loss: 0.00222, lr: 2.02E-04, _patience: 9\n",
            "Epoch: 14 | train_loss: 0.00126, val_loss: 0.00215, lr: 2.02E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00113, val_loss: 0.00222, lr: 2.02E-04, _patience: 9\n",
            "Epoch: 16 | train_loss: 0.00102, val_loss: 0.00217, lr: 2.02E-04, _patience: 8\n",
            "Epoch: 17 | train_loss: 0.00093, val_loss: 0.00220, lr: 2.02E-04, _patience: 7\n",
            "Epoch: 18 | train_loss: 0.00083, val_loss: 0.00220, lr: 2.02E-04, _patience: 6\n",
            "Epoch: 19 | train_loss: 0.00080, val_loss: 0.00225, lr: 2.02E-04, _patience: 5\n",
            "Epoch: 20 | train_loss: 0.00078, val_loss: 0.00230, lr: 2.02E-05, _patience: 4\n",
            "Epoch: 21 | train_loss: 0.00067, val_loss: 0.00223, lr: 2.02E-05, _patience: 3\n",
            "Epoch: 22 | train_loss: 0.00058, val_loss: 0.00222, lr: 2.02E-05, _patience: 2\n",
            "Epoch: 23 | train_loss: 0.00054, val_loss: 0.00219, lr: 2.02E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 02:09:04,218]\u001b[0m Trial 37 finished with value: 0.6767903152732834 and parameters: {'embedding_dim': 216, 'num_filters': 439, 'hidden_dim': 320, 'dropout_p': 0.42297490917480796, 'lr': 0.00020227149215172236}. Best is trial 23 with value: 0.6893605235149695.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00736, val_loss: 0.00536, lr: 2.33E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00505, val_loss: 0.00395, lr: 2.33E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00421, val_loss: 0.00369, lr: 2.33E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00366, val_loss: 0.00333, lr: 2.33E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00314, val_loss: 0.00296, lr: 2.33E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00279, val_loss: 0.00275, lr: 2.33E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00248, val_loss: 0.00257, lr: 2.33E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00220, val_loss: 0.00249, lr: 2.33E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00204, val_loss: 0.00241, lr: 2.33E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00178, val_loss: 0.00234, lr: 2.33E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00161, val_loss: 0.00232, lr: 2.33E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00144, val_loss: 0.00238, lr: 2.33E-04, _patience: 9\n",
            "Epoch: 13 | train_loss: 0.00132, val_loss: 0.00230, lr: 2.33E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00114, val_loss: 0.00231, lr: 2.33E-04, _patience: 9\n",
            "Epoch: 15 | train_loss: 0.00103, val_loss: 0.00233, lr: 2.33E-04, _patience: 8\n",
            "Epoch: 16 | train_loss: 0.00093, val_loss: 0.00230, lr: 2.33E-04, _patience: 7\n",
            "Epoch: 17 | train_loss: 0.00085, val_loss: 0.00231, lr: 2.33E-04, _patience: 6\n",
            "Epoch: 18 | train_loss: 0.00074, val_loss: 0.00235, lr: 2.33E-04, _patience: 5\n",
            "Epoch: 19 | train_loss: 0.00069, val_loss: 0.00258, lr: 2.33E-05, _patience: 4\n",
            "Epoch: 20 | train_loss: 0.00062, val_loss: 0.00229, lr: 2.33E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00057, val_loss: 0.00231, lr: 2.33E-05, _patience: 9\n",
            "Epoch: 22 | train_loss: 0.00052, val_loss: 0.00232, lr: 2.33E-05, _patience: 8\n",
            "Epoch: 23 | train_loss: 0.00050, val_loss: 0.00234, lr: 2.33E-05, _patience: 7\n",
            "Epoch: 24 | train_loss: 0.00051, val_loss: 0.00231, lr: 2.33E-05, _patience: 6\n",
            "Epoch: 25 | train_loss: 0.00048, val_loss: 0.00232, lr: 2.33E-05, _patience: 5\n",
            "Epoch: 26 | train_loss: 0.00049, val_loss: 0.00234, lr: 2.33E-06, _patience: 4\n",
            "Epoch: 27 | train_loss: 0.00047, val_loss: 0.00233, lr: 2.33E-06, _patience: 3\n",
            "Epoch: 28 | train_loss: 0.00047, val_loss: 0.00233, lr: 2.33E-06, _patience: 2\n",
            "Epoch: 29 | train_loss: 0.00046, val_loss: 0.00232, lr: 2.33E-06, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 02:10:31,564]\u001b[0m Trial 38 finished with value: 0.6675077310794176 and parameters: {'embedding_dim': 301, 'num_filters': 335, 'hidden_dim': 421, 'dropout_p': 0.5727492035754438, 'lr': 0.0002334774066911049}. Best is trial 23 with value: 0.6893605235149695.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00763, val_loss: 0.00471, lr: 2.84E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00451, val_loss: 0.00371, lr: 2.84E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00335, val_loss: 0.00305, lr: 2.84E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00263, val_loss: 0.00268, lr: 2.84E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00217, val_loss: 0.00246, lr: 2.84E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00180, val_loss: 0.00229, lr: 2.84E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00145, val_loss: 0.00228, lr: 2.84E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00118, val_loss: 0.00221, lr: 2.84E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00100, val_loss: 0.00223, lr: 2.84E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00086, val_loss: 0.00225, lr: 2.84E-04, _patience: 8\n",
            "Epoch: 11 | train_loss: 0.00074, val_loss: 0.00230, lr: 2.84E-04, _patience: 7\n",
            "Epoch: 12 | train_loss: 0.00068, val_loss: 0.00235, lr: 2.84E-04, _patience: 6\n",
            "Epoch: 13 | train_loss: 0.00059, val_loss: 0.00235, lr: 2.84E-04, _patience: 5\n",
            "Epoch: 14 | train_loss: 0.00054, val_loss: 0.00255, lr: 2.84E-05, _patience: 4\n",
            "Epoch: 15 | train_loss: 0.00045, val_loss: 0.00242, lr: 2.84E-05, _patience: 3\n",
            "Epoch: 16 | train_loss: 0.00036, val_loss: 0.00244, lr: 2.84E-05, _patience: 2\n",
            "Epoch: 17 | train_loss: 0.00032, val_loss: 0.00241, lr: 2.84E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 02:11:49,138]\u001b[0m Trial 39 finished with value: 0.6911921640685477 and parameters: {'embedding_dim': 407, 'num_filters': 510, 'hidden_dim': 334, 'dropout_p': 0.3455200387912171, 'lr': 0.00028381065170221184}. Best is trial 39 with value: 0.6911921640685477.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00690, val_loss: 0.00537, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00436, val_loss: 0.00378, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00355, val_loss: 0.00345, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00303, val_loss: 0.00299, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00256, val_loss: 0.00273, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00219, val_loss: 0.00259, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00191, val_loss: 0.00250, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00167, val_loss: 0.00242, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00149, val_loss: 0.00236, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00131, val_loss: 0.00233, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00116, val_loss: 0.00237, lr: 1.72E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00103, val_loss: 0.00232, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00092, val_loss: 0.00239, lr: 1.72E-04, _patience: 9\n",
            "Epoch: 14 | train_loss: 0.00083, val_loss: 0.00231, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00069, val_loss: 0.00252, lr: 1.72E-04, _patience: 9\n",
            "Epoch: 16 | train_loss: 0.00064, val_loss: 0.00250, lr: 1.72E-04, _patience: 8\n",
            "Epoch: 17 | train_loss: 0.00055, val_loss: 0.00253, lr: 1.72E-04, _patience: 7\n",
            "Epoch: 18 | train_loss: 0.00051, val_loss: 0.00258, lr: 1.72E-04, _patience: 6\n",
            "Epoch: 19 | train_loss: 0.00048, val_loss: 0.00270, lr: 1.72E-04, _patience: 5\n",
            "Epoch: 20 | train_loss: 0.00042, val_loss: 0.00270, lr: 1.72E-05, _patience: 4\n",
            "Epoch: 21 | train_loss: 0.00040, val_loss: 0.00240, lr: 1.72E-05, _patience: 3\n",
            "Epoch: 22 | train_loss: 0.00033, val_loss: 0.00239, lr: 1.72E-05, _patience: 2\n",
            "Epoch: 23 | train_loss: 0.00031, val_loss: 0.00243, lr: 1.72E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 02:13:32,089]\u001b[0m Trial 40 finished with value: 0.6872144231049917 and parameters: {'embedding_dim': 422, 'num_filters': 496, 'hidden_dim': 323, 'dropout_p': 0.3334063796286489, 'lr': 0.00017247917135335329}. Best is trial 39 with value: 0.6911921640685477.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00674, val_loss: 0.00533, lr: 1.57E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00436, val_loss: 0.00376, lr: 1.57E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00358, val_loss: 0.00346, lr: 1.57E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00301, val_loss: 0.00305, lr: 1.57E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00256, val_loss: 0.00279, lr: 1.57E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00227, val_loss: 0.00264, lr: 1.57E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00200, val_loss: 0.00247, lr: 1.57E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00173, val_loss: 0.00243, lr: 1.57E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00152, val_loss: 0.00233, lr: 1.57E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00134, val_loss: 0.00229, lr: 1.57E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00121, val_loss: 0.00227, lr: 1.57E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00110, val_loss: 0.00222, lr: 1.57E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00096, val_loss: 0.00226, lr: 1.57E-04, _patience: 9\n",
            "Epoch: 14 | train_loss: 0.00088, val_loss: 0.00234, lr: 1.57E-04, _patience: 8\n",
            "Epoch: 15 | train_loss: 0.00080, val_loss: 0.00234, lr: 1.57E-04, _patience: 7\n",
            "Epoch: 16 | train_loss: 0.00069, val_loss: 0.00242, lr: 1.57E-04, _patience: 6\n",
            "Epoch: 17 | train_loss: 0.00062, val_loss: 0.00238, lr: 1.57E-04, _patience: 5\n",
            "Epoch: 18 | train_loss: 0.00059, val_loss: 0.00241, lr: 1.57E-05, _patience: 4\n",
            "Epoch: 19 | train_loss: 0.00051, val_loss: 0.00235, lr: 1.57E-05, _patience: 3\n",
            "Epoch: 20 | train_loss: 0.00045, val_loss: 0.00233, lr: 1.57E-05, _patience: 2\n",
            "Epoch: 21 | train_loss: 0.00043, val_loss: 0.00230, lr: 1.57E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 02:15:11,013]\u001b[0m Trial 41 finished with value: 0.6775864392956321 and parameters: {'embedding_dim': 440, 'num_filters': 512, 'hidden_dim': 323, 'dropout_p': 0.334420287064763, 'lr': 0.00015653552494189412}. Best is trial 39 with value: 0.6911921640685477.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00687, val_loss: 0.00557, lr: 1.73E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00458, val_loss: 0.00382, lr: 1.73E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00373, val_loss: 0.00353, lr: 1.73E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00320, val_loss: 0.00306, lr: 1.73E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00274, val_loss: 0.00279, lr: 1.73E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00241, val_loss: 0.00259, lr: 1.73E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00205, val_loss: 0.00249, lr: 1.73E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00184, val_loss: 0.00238, lr: 1.73E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00164, val_loss: 0.00232, lr: 1.73E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00142, val_loss: 0.00230, lr: 1.73E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00131, val_loss: 0.00233, lr: 1.73E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00114, val_loss: 0.00235, lr: 1.73E-04, _patience: 8\n",
            "Epoch: 13 | train_loss: 0.00102, val_loss: 0.00234, lr: 1.73E-04, _patience: 7\n",
            "Epoch: 14 | train_loss: 0.00095, val_loss: 0.00233, lr: 1.73E-04, _patience: 6\n",
            "Epoch: 15 | train_loss: 0.00087, val_loss: 0.00231, lr: 1.73E-04, _patience: 5\n",
            "Epoch: 16 | train_loss: 0.00079, val_loss: 0.00244, lr: 1.73E-05, _patience: 4\n",
            "Epoch: 17 | train_loss: 0.00070, val_loss: 0.00226, lr: 1.73E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00061, val_loss: 0.00224, lr: 1.73E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00060, val_loss: 0.00221, lr: 1.73E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00058, val_loss: 0.00222, lr: 1.73E-05, _patience: 9\n",
            "Epoch: 21 | train_loss: 0.00054, val_loss: 0.00224, lr: 1.73E-05, _patience: 8\n",
            "Epoch: 22 | train_loss: 0.00054, val_loss: 0.00223, lr: 1.73E-05, _patience: 7\n",
            "Epoch: 23 | train_loss: 0.00054, val_loss: 0.00220, lr: 1.73E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00052, val_loss: 0.00223, lr: 1.73E-05, _patience: 9\n",
            "Epoch: 25 | train_loss: 0.00053, val_loss: 0.00223, lr: 1.73E-05, _patience: 8\n",
            "Epoch: 26 | train_loss: 0.00052, val_loss: 0.00224, lr: 1.73E-05, _patience: 7\n",
            "Epoch: 27 | train_loss: 0.00051, val_loss: 0.00223, lr: 1.73E-05, _patience: 6\n",
            "Epoch: 28 | train_loss: 0.00051, val_loss: 0.00223, lr: 1.73E-05, _patience: 5\n",
            "Epoch: 29 | train_loss: 0.00051, val_loss: 0.00222, lr: 1.73E-06, _patience: 4\n",
            "Epoch: 30 | train_loss: 0.00050, val_loss: 0.00223, lr: 1.73E-06, _patience: 3\n",
            "Epoch: 31 | train_loss: 0.00048, val_loss: 0.00223, lr: 1.73E-06, _patience: 2\n",
            "Epoch: 32 | train_loss: 0.00048, val_loss: 0.00223, lr: 1.73E-06, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 02:17:29,279]\u001b[0m Trial 42 finished with value: 0.6800139643269503 and parameters: {'embedding_dim': 411, 'num_filters': 490, 'hidden_dim': 278, 'dropout_p': 0.3578822324444334, 'lr': 0.00017252414522322019}. Best is trial 39 with value: 0.6911921640685477.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00648, val_loss: 0.00546, lr: 1.39E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00435, val_loss: 0.00382, lr: 1.39E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00361, val_loss: 0.00354, lr: 1.39E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00314, val_loss: 0.00310, lr: 1.39E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00272, val_loss: 0.00285, lr: 1.39E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00236, val_loss: 0.00263, lr: 1.39E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00203, val_loss: 0.00252, lr: 1.39E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00186, val_loss: 0.00242, lr: 1.39E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00163, val_loss: 0.00239, lr: 1.39E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00147, val_loss: 0.00230, lr: 1.39E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00131, val_loss: 0.00235, lr: 1.39E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00118, val_loss: 0.00235, lr: 1.39E-04, _patience: 8\n",
            "Epoch: 13 | train_loss: 0.00108, val_loss: 0.00239, lr: 1.39E-04, _patience: 7\n",
            "Epoch: 14 | train_loss: 0.00100, val_loss: 0.00226, lr: 1.39E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00088, val_loss: 0.00228, lr: 1.39E-04, _patience: 9\n",
            "Epoch: 16 | train_loss: 0.00081, val_loss: 0.00233, lr: 1.39E-04, _patience: 8\n",
            "Epoch: 17 | train_loss: 0.00073, val_loss: 0.00234, lr: 1.39E-04, _patience: 7\n",
            "Epoch: 18 | train_loss: 0.00068, val_loss: 0.00230, lr: 1.39E-04, _patience: 6\n",
            "Epoch: 19 | train_loss: 0.00060, val_loss: 0.00238, lr: 1.39E-04, _patience: 5\n",
            "Epoch: 20 | train_loss: 0.00053, val_loss: 0.00225, lr: 1.39E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00048, val_loss: 0.00223, lr: 1.39E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00044, val_loss: 0.00229, lr: 1.39E-04, _patience: 9\n",
            "Epoch: 23 | train_loss: 0.00040, val_loss: 0.00243, lr: 1.39E-04, _patience: 8\n",
            "Epoch: 24 | train_loss: 0.00037, val_loss: 0.00235, lr: 1.39E-04, _patience: 7\n",
            "Epoch: 25 | train_loss: 0.00035, val_loss: 0.00241, lr: 1.39E-04, _patience: 6\n",
            "Epoch: 26 | train_loss: 0.00031, val_loss: 0.00262, lr: 1.39E-04, _patience: 5\n",
            "Epoch: 27 | train_loss: 0.00032, val_loss: 0.00250, lr: 1.39E-05, _patience: 4\n",
            "Epoch: 28 | train_loss: 0.00027, val_loss: 0.00244, lr: 1.39E-05, _patience: 3\n",
            "Epoch: 29 | train_loss: 0.00025, val_loss: 0.00245, lr: 1.39E-05, _patience: 2\n",
            "Epoch: 30 | train_loss: 0.00025, val_loss: 0.00246, lr: 1.39E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 02:19:43,708]\u001b[0m Trial 43 finished with value: 0.6681759892980845 and parameters: {'embedding_dim': 465, 'num_filters': 455, 'hidden_dim': 299, 'dropout_p': 0.324743395619151, 'lr': 0.00013947514801406982}. Best is trial 39 with value: 0.6911921640685477.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00970, val_loss: 0.00576, lr: 2.91E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00559, val_loss: 0.00394, lr: 2.91E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00434, val_loss: 0.00347, lr: 2.91E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00358, val_loss: 0.00312, lr: 2.91E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00318, val_loss: 0.00278, lr: 2.91E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00280, val_loss: 0.00259, lr: 2.91E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00246, val_loss: 0.00247, lr: 2.91E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00221, val_loss: 0.00238, lr: 2.91E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00195, val_loss: 0.00228, lr: 2.91E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00178, val_loss: 0.00222, lr: 2.91E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00156, val_loss: 0.00231, lr: 2.91E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00132, val_loss: 0.00217, lr: 2.91E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00118, val_loss: 0.00213, lr: 2.91E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00106, val_loss: 0.00221, lr: 2.91E-04, _patience: 9\n",
            "Epoch: 15 | train_loss: 0.00101, val_loss: 0.00222, lr: 2.91E-04, _patience: 8\n",
            "Epoch: 16 | train_loss: 0.00092, val_loss: 0.00228, lr: 2.91E-04, _patience: 7\n",
            "Epoch: 17 | train_loss: 0.00083, val_loss: 0.00243, lr: 2.91E-04, _patience: 6\n",
            "Epoch: 18 | train_loss: 0.00074, val_loss: 0.00251, lr: 2.91E-04, _patience: 5\n",
            "Epoch: 19 | train_loss: 0.00070, val_loss: 0.00237, lr: 2.91E-05, _patience: 4\n",
            "Epoch: 20 | train_loss: 0.00064, val_loss: 0.00274, lr: 2.91E-05, _patience: 3\n",
            "Epoch: 21 | train_loss: 0.00054, val_loss: 0.00243, lr: 2.91E-05, _patience: 2\n",
            "Epoch: 22 | train_loss: 0.00050, val_loss: 0.00251, lr: 2.91E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 02:21:24,331]\u001b[0m Trial 44 finished with value: 0.6817510048213098 and parameters: {'embedding_dim': 396, 'num_filters': 489, 'hidden_dim': 339, 'dropout_p': 0.6707874722911259, 'lr': 0.00029145359287980455}. Best is trial 39 with value: 0.6911921640685477.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00653, val_loss: 0.00575, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00479, val_loss: 0.00389, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00403, val_loss: 0.00367, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00362, val_loss: 0.00343, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00329, val_loss: 0.00319, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00294, val_loss: 0.00298, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00273, val_loss: 0.00280, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00245, val_loss: 0.00265, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00231, val_loss: 0.00255, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00208, val_loss: 0.00244, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00191, val_loss: 0.00240, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00177, val_loss: 0.00233, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00166, val_loss: 0.00229, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00153, val_loss: 0.00225, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00141, val_loss: 0.00220, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00129, val_loss: 0.00219, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00122, val_loss: 0.00218, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00112, val_loss: 0.00215, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00108, val_loss: 0.00216, lr: 1.00E-04, _patience: 9\n",
            "Epoch: 20 | train_loss: 0.00099, val_loss: 0.00221, lr: 1.00E-04, _patience: 8\n",
            "Epoch: 21 | train_loss: 0.00093, val_loss: 0.00221, lr: 1.00E-04, _patience: 7\n",
            "Epoch: 22 | train_loss: 0.00088, val_loss: 0.00223, lr: 1.00E-04, _patience: 6\n",
            "Epoch: 23 | train_loss: 0.00082, val_loss: 0.00230, lr: 1.00E-04, _patience: 5\n",
            "Epoch: 24 | train_loss: 0.00075, val_loss: 0.00228, lr: 1.00E-05, _patience: 4\n",
            "Epoch: 25 | train_loss: 0.00070, val_loss: 0.00222, lr: 1.00E-05, _patience: 3\n",
            "Epoch: 26 | train_loss: 0.00063, val_loss: 0.00221, lr: 1.00E-05, _patience: 2\n",
            "Epoch: 27 | train_loss: 0.00063, val_loss: 0.00221, lr: 1.00E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 02:23:30,085]\u001b[0m Trial 45 finished with value: 0.6797041869613061 and parameters: {'embedding_dim': 442, 'num_filters': 508, 'hidden_dim': 258, 'dropout_p': 0.41207090925279083, 'lr': 0.00010034570989433325}. Best is trial 39 with value: 0.6911921640685477.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00743, val_loss: 0.00499, lr: 2.57E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00452, val_loss: 0.00367, lr: 2.57E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00353, val_loss: 0.00315, lr: 2.57E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00288, val_loss: 0.00278, lr: 2.57E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00240, val_loss: 0.00255, lr: 2.57E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00197, val_loss: 0.00235, lr: 2.57E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00168, val_loss: 0.00237, lr: 2.57E-04, _patience: 9\n",
            "Epoch: 8 | train_loss: 0.00145, val_loss: 0.00224, lr: 2.57E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00126, val_loss: 0.00225, lr: 2.57E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00107, val_loss: 0.00227, lr: 2.57E-04, _patience: 8\n",
            "Epoch: 11 | train_loss: 0.00094, val_loss: 0.00246, lr: 2.57E-04, _patience: 7\n",
            "Epoch: 12 | train_loss: 0.00086, val_loss: 0.00232, lr: 2.57E-04, _patience: 6\n",
            "Epoch: 13 | train_loss: 0.00072, val_loss: 0.00245, lr: 2.57E-04, _patience: 5\n",
            "Epoch: 14 | train_loss: 0.00070, val_loss: 0.00256, lr: 2.57E-05, _patience: 4\n",
            "Epoch: 15 | train_loss: 0.00061, val_loss: 0.00238, lr: 2.57E-05, _patience: 3\n",
            "Epoch: 16 | train_loss: 0.00048, val_loss: 0.00235, lr: 2.57E-05, _patience: 2\n",
            "Epoch: 17 | train_loss: 0.00046, val_loss: 0.00236, lr: 2.57E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 02:24:47,025]\u001b[0m Trial 46 finished with value: 0.6682188148851675 and parameters: {'embedding_dim': 469, 'num_filters': 441, 'hidden_dim': 278, 'dropout_p': 0.3878453021896208, 'lr': 0.00025700347863230643}. Best is trial 39 with value: 0.6911921640685477.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00733, val_loss: 0.00564, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00506, val_loss: 0.00388, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00402, val_loss: 0.00361, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00356, val_loss: 0.00315, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00302, val_loss: 0.00288, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00267, val_loss: 0.00265, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00236, val_loss: 0.00256, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00212, val_loss: 0.00245, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00185, val_loss: 0.00236, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00171, val_loss: 0.00231, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00153, val_loss: 0.00223, lr: 1.92E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00137, val_loss: 0.00229, lr: 1.92E-04, _patience: 9\n",
            "Epoch: 13 | train_loss: 0.00125, val_loss: 0.00227, lr: 1.92E-04, _patience: 8\n",
            "Epoch: 14 | train_loss: 0.00116, val_loss: 0.00227, lr: 1.92E-04, _patience: 7\n",
            "Epoch: 15 | train_loss: 0.00107, val_loss: 0.00223, lr: 1.92E-04, _patience: 6\n",
            "Epoch: 16 | train_loss: 0.00098, val_loss: 0.00230, lr: 1.92E-04, _patience: 5\n",
            "Epoch: 17 | train_loss: 0.00089, val_loss: 0.00231, lr: 1.92E-05, _patience: 4\n",
            "Epoch: 18 | train_loss: 0.00081, val_loss: 0.00233, lr: 1.92E-05, _patience: 3\n",
            "Epoch: 19 | train_loss: 0.00072, val_loss: 0.00224, lr: 1.92E-05, _patience: 2\n",
            "Epoch: 20 | train_loss: 0.00069, val_loss: 0.00226, lr: 1.92E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 02:26:12,666]\u001b[0m Trial 47 finished with value: 0.657470871060554 and parameters: {'embedding_dim': 375, 'num_filters': 463, 'hidden_dim': 219, 'dropout_p': 0.4436243605638399, 'lr': 0.00019199048654475534}. Best is trial 39 with value: 0.6911921640685477.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00752, val_loss: 0.00551, lr: 2.32E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00459, val_loss: 0.00366, lr: 2.32E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00375, val_loss: 0.00338, lr: 2.32E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00309, val_loss: 0.00297, lr: 2.32E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00263, val_loss: 0.00274, lr: 2.32E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00224, val_loss: 0.00257, lr: 2.32E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00188, val_loss: 0.00251, lr: 2.32E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00171, val_loss: 0.00239, lr: 2.32E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00147, val_loss: 0.00239, lr: 2.32E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00132, val_loss: 0.00225, lr: 2.32E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00114, val_loss: 0.00229, lr: 2.32E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00102, val_loss: 0.00230, lr: 2.32E-04, _patience: 8\n",
            "Epoch: 13 | train_loss: 0.00089, val_loss: 0.00229, lr: 2.32E-04, _patience: 7\n",
            "Epoch: 14 | train_loss: 0.00082, val_loss: 0.00247, lr: 2.32E-04, _patience: 6\n",
            "Epoch: 15 | train_loss: 0.00078, val_loss: 0.00244, lr: 2.32E-04, _patience: 5\n",
            "Epoch: 16 | train_loss: 0.00069, val_loss: 0.00247, lr: 2.32E-05, _patience: 4\n",
            "Epoch: 17 | train_loss: 0.00061, val_loss: 0.00242, lr: 2.32E-05, _patience: 3\n",
            "Epoch: 18 | train_loss: 0.00050, val_loss: 0.00236, lr: 2.32E-05, _patience: 2\n",
            "Epoch: 19 | train_loss: 0.00049, val_loss: 0.00232, lr: 2.32E-05, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 02:27:38,946]\u001b[0m Trial 48 finished with value: 0.670257710368399 and parameters: {'embedding_dim': 413, 'num_filters': 512, 'hidden_dim': 182, 'dropout_p': 0.3509363167214768, 'lr': 0.00023231176297708252}. Best is trial 39 with value: 0.6911921640685477.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.00624, val_loss: 0.00504, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00419, val_loss: 0.00392, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00365, val_loss: 0.00362, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00322, val_loss: 0.00320, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00281, val_loss: 0.00291, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00248, val_loss: 0.00268, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00219, val_loss: 0.00250, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00192, val_loss: 0.00242, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00174, val_loss: 0.00235, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00157, val_loss: 0.00231, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00141, val_loss: 0.00224, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00124, val_loss: 0.00224, lr: 1.72E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00114, val_loss: 0.00226, lr: 1.72E-04, _patience: 9\n",
            "Epoch: 14 | train_loss: 0.00103, val_loss: 0.00227, lr: 1.72E-04, _patience: 8\n",
            "Epoch: 15 | train_loss: 0.00090, val_loss: 0.00229, lr: 1.72E-04, _patience: 7\n",
            "Epoch: 16 | train_loss: 0.00083, val_loss: 0.00227, lr: 1.72E-04, _patience: 6\n",
            "Epoch: 17 | train_loss: 0.00074, val_loss: 0.00233, lr: 1.72E-04, _patience: 5\n",
            "Epoch: 18 | train_loss: 0.00067, val_loss: 0.00234, lr: 1.72E-05, _patience: 4\n",
            "Epoch: 19 | train_loss: 0.00060, val_loss: 0.00225, lr: 1.72E-05, _patience: 3\n",
            "Epoch: 20 | train_loss: 0.00054, val_loss: 0.00225, lr: 1.72E-05, _patience: 2\n",
            "Epoch: 21 | train_loss: 0.00054, val_loss: 0.00224, lr: 1.72E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00052, val_loss: 0.00225, lr: 1.72E-05, _patience: 9\n",
            "Epoch: 23 | train_loss: 0.00051, val_loss: 0.00226, lr: 1.72E-05, _patience: 8\n",
            "Epoch: 24 | train_loss: 0.00051, val_loss: 0.00226, lr: 1.72E-05, _patience: 7\n",
            "Epoch: 25 | train_loss: 0.00051, val_loss: 0.00226, lr: 1.72E-05, _patience: 6\n",
            "Epoch: 26 | train_loss: 0.00048, val_loss: 0.00227, lr: 1.72E-05, _patience: 5\n",
            "Epoch: 27 | train_loss: 0.00050, val_loss: 0.00226, lr: 1.72E-06, _patience: 4\n",
            "Epoch: 28 | train_loss: 0.00048, val_loss: 0.00226, lr: 1.72E-06, _patience: 3\n",
            "Epoch: 29 | train_loss: 0.00049, val_loss: 0.00226, lr: 1.72E-06, _patience: 2\n",
            "Epoch: 30 | train_loss: 0.00050, val_loss: 0.00226, lr: 1.72E-06, _patience: 1\n",
            "Stopping Early!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-09-02 02:28:53,014]\u001b[0m Trial 49 finished with value: 0.6630354636692574 and parameters: {'embedding_dim': 433, 'num_filters': 212, 'hidden_dim': 379, 'dropout_p': 0.301335143495687, 'lr': 0.00017175757149907504}. Best is trial 39 with value: 0.6911921640685477.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc4wrDtRYhAh"
      },
      "source": [
        "from pyngrok import ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imq0tzFJEiSy",
        "outputId": "344e212a-d2d7-4707-a800-eb6c1e0f0f36"
      },
      "source": [
        "# MLFlow dashboard\n",
        "get_ipython().system_raw(\"mlflow server -h 0.0.0.0 -p 5000 --backend-store-uri $PWD/experiments/ &\")\n",
        "ngrok.kill()\n",
        "ngrok.set_auth_token(\"\")\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLflow Tracking UI: https://9d79-35-239-89-63.ngrok.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "m8JTXTiwIs5D",
        "outputId": "97dd9815-fa0f-4b80-ad8f-e5f0d1eca640"
      },
      "source": [
        "# All trials\n",
        "trials_df = study.trials_dataframe()\n",
        "trials_df = trials_df.sort_values([\"value\"], ascending=False)  # sort by metric\n",
        "trials_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>value</th>\n",
              "      <th>datetime_start</th>\n",
              "      <th>datetime_complete</th>\n",
              "      <th>duration</th>\n",
              "      <th>params_dropout_p</th>\n",
              "      <th>params_embedding_dim</th>\n",
              "      <th>params_hidden_dim</th>\n",
              "      <th>params_lr</th>\n",
              "      <th>params_num_filters</th>\n",
              "      <th>user_attrs_f1</th>\n",
              "      <th>user_attrs_precision</th>\n",
              "      <th>user_attrs_recall</th>\n",
              "      <th>user_attrs_threshold</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>39</td>\n",
              "      <td>0.691192</td>\n",
              "      <td>2021-09-02 02:10:31.581366</td>\n",
              "      <td>2021-09-02 02:11:49.137872</td>\n",
              "      <td>0 days 00:01:17.556506</td>\n",
              "      <td>0.345520</td>\n",
              "      <td>407</td>\n",
              "      <td>334</td>\n",
              "      <td>0.000284</td>\n",
              "      <td>510</td>\n",
              "      <td>0.691192</td>\n",
              "      <td>0.835250</td>\n",
              "      <td>0.607539</td>\n",
              "      <td>0.281473</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>0.689361</td>\n",
              "      <td>2021-09-02 01:53:21.974442</td>\n",
              "      <td>2021-09-02 01:54:24.107666</td>\n",
              "      <td>0 days 00:01:02.133224</td>\n",
              "      <td>0.392532</td>\n",
              "      <td>231</td>\n",
              "      <td>471</td>\n",
              "      <td>0.000318</td>\n",
              "      <td>476</td>\n",
              "      <td>0.689361</td>\n",
              "      <td>0.846572</td>\n",
              "      <td>0.600887</td>\n",
              "      <td>0.337744</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.687850</td>\n",
              "      <td>2021-09-02 01:19:13.448726</td>\n",
              "      <td>2021-09-02 01:20:30.698038</td>\n",
              "      <td>0 days 00:01:17.249312</td>\n",
              "      <td>0.466795</td>\n",
              "      <td>182</td>\n",
              "      <td>496</td>\n",
              "      <td>0.000194</td>\n",
              "      <td>486</td>\n",
              "      <td>0.687850</td>\n",
              "      <td>0.851291</td>\n",
              "      <td>0.594235</td>\n",
              "      <td>0.326300</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>40</td>\n",
              "      <td>0.687214</td>\n",
              "      <td>2021-09-02 02:11:49.155965</td>\n",
              "      <td>2021-09-02 02:13:32.089228</td>\n",
              "      <td>0 days 00:01:42.933263</td>\n",
              "      <td>0.333406</td>\n",
              "      <td>422</td>\n",
              "      <td>323</td>\n",
              "      <td>0.000172</td>\n",
              "      <td>496</td>\n",
              "      <td>0.687214</td>\n",
              "      <td>0.820720</td>\n",
              "      <td>0.614191</td>\n",
              "      <td>0.275450</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>0.687146</td>\n",
              "      <td>2021-09-02 01:56:15.237041</td>\n",
              "      <td>2021-09-02 01:57:10.125590</td>\n",
              "      <td>0 days 00:00:54.888549</td>\n",
              "      <td>0.364982</td>\n",
              "      <td>240</td>\n",
              "      <td>485</td>\n",
              "      <td>0.000425</td>\n",
              "      <td>504</td>\n",
              "      <td>0.687146</td>\n",
              "      <td>0.838968</td>\n",
              "      <td>0.600887</td>\n",
              "      <td>0.317778</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    number     value  ... user_attrs_threshold     state\n",
              "39      39  0.691192  ...             0.281473  COMPLETE\n",
              "23      23  0.689361  ...             0.337744  COMPLETE\n",
              "1        1  0.687850  ...             0.326300  COMPLETE\n",
              "40      40  0.687214  ...             0.275450  COMPLETE\n",
              "26      26  0.687146  ...             0.317778  COMPLETE\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUh5RVU4IwG9",
        "outputId": "031ff1ed-716a-4422-f88d-230d82baa7be"
      },
      "source": [
        "# Best trial\n",
        "print (f\"Best value (val loss): {study.best_trial.value}\")\n",
        "print (f\"Best hyperparameters: {study.best_trial.params}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best value (val loss): 0.6911921640685477\n",
            "Best hyperparameters: {'embedding_dim': 407, 'num_filters': 510, 'hidden_dim': 334, 'dropout_p': 0.3455200387912171, 'lr': 0.00028381065170221184}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRpOtrm5Iyy4",
        "outputId": "156b84ee-e2f4-4a1a-9891-b6dcdc65d2ae"
      },
      "source": [
        "# Save best parameters\n",
        "params = {**args.__dict__, **study.best_trial.params}\n",
        "params[\"threshold\"] = study.best_trial.user_attrs[\"threshold\"]\n",
        "print (json.dumps(params, indent=2, cls=NumpyEncoder))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"char_level\": true,\n",
            "  \"filter_sizes\": [\n",
            "    1,\n",
            "    2,\n",
            "    3,\n",
            "    4,\n",
            "    5,\n",
            "    6,\n",
            "    7,\n",
            "    8,\n",
            "    9,\n",
            "    10\n",
            "  ],\n",
            "  \"batch_size\": 64,\n",
            "  \"embedding_dim\": 407,\n",
            "  \"num_filters\": 510,\n",
            "  \"hidden_dim\": 334,\n",
            "  \"dropout_p\": 0.3455200387912171,\n",
            "  \"lr\": 0.00028381065170221184,\n",
            "  \"num_epochs\": 100,\n",
            "  \"patience\": 10,\n",
            "  \"threshold\": 0.2814725935459137\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVPTPVlrI2m4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}